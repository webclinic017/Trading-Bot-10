{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "import random\n",
    "from collections import deque\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, BatchNormalization, Flatten, Activation\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ModelCheckpoint\n",
    "import time\n",
    "import statistics\n",
    "from sklearn import preprocessing\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = \"TNA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDB(ticker):\n",
    "    tick = ticker\n",
    "    # Load data\n",
    "    data = yf.Ticker(tick)\n",
    "    df = data.history(period=\"5y\", interval=\"1d\")\n",
    "#     df = data.history(start=\"2018-12-01\", end=\"2020-03-01\")\n",
    "#     start=\"2017-01-01\", end=\"2017-04-30\"\n",
    "    \n",
    "    # add data points\n",
    "    df['close_per1'] = df.ta.percent_return(1)*100\n",
    "    df['sma10'] = df.ta.sma(length=10)\n",
    "    df['williams'] = df.ta.willr()\n",
    "\n",
    "\n",
    "    df = df[[\n",
    "            'open','close','sma10','williams','close_per1'\n",
    "            ]]\n",
    "\n",
    "    df = df.dropna()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.448871370564073\n",
      "                 open      close      sma10   williams  close_per1\n",
      "date                                                              \n",
      "2017-01-20  49.030236  49.208237  50.167484 -76.465377    1.478528\n",
      "2017-01-23  48.812673  48.649502  49.949428 -85.270668   -1.135450\n",
      "2017-01-24  49.163738  50.775665  50.048319 -47.116217    4.370371\n",
      "2017-01-25  52.031586  52.328259  50.155616 -16.128967    3.057751\n",
      "2017-01-26  52.348033  51.715126  50.177867 -19.549763   -1.171704\n",
      "2017-01-27  51.764582  51.111900  50.261431 -32.036748   -1.166440\n",
      "2017-01-30  50.043873  49.079685  50.032003 -74.028611   -3.976012\n",
      "2017-01-31  48.535789  49.989487  50.109634 -55.214640    1.853723\n",
      "2017-02-01  51.097063  49.999374  50.134851 -55.010170    0.019780\n",
      "2017-02-02  50.103211  49.475250  50.233249 -65.848640   -1.048261\n",
      "2017-02-03  50.810277  51.720074  50.484432 -19.427478    4.537265\n",
      "2017-02-06  51.240454  50.587772  50.678259 -42.842568   -2.189288\n",
      "2017-02-07  50.661942  49.959816  50.596674 -55.828207   -1.241321\n",
      "2017-02-08  49.267576  49.687862  50.332635 -61.451990   -0.544345\n",
      "2017-02-09  49.979596  51.779415  50.339064 -18.200344    4.209384\n",
      "                 open      close      sma10   williams  close_per1\n",
      "date                                                              \n",
      "2021-12-09  86.341345  82.374039  82.408015 -70.782914   -6.827178\n",
      "2021-12-10  84.112855  81.654526  81.936335 -73.345198   -0.873471\n",
      "2021-12-13  80.675193  78.236847  81.176851 -83.441834   -4.185535\n",
      "2021-12-14  76.468044  76.148262  80.718162 -91.491213   -2.669567\n",
      "2021-12-15  76.068325  79.835762  81.178849 -59.977382    4.842527\n",
      "2021-12-16  81.624546  74.869133  80.525293 -88.072366   -6.221058\n",
      "2021-12-17  73.769880  76.877769  80.581255 -71.094656    2.682863\n",
      "2021-12-20  73.570020  73.599998  79.847753 -81.521746   -4.263614\n",
      "2021-12-21  75.709999  79.949997  79.195628 -48.631940    8.627715\n",
      "2021-12-22  79.529999  82.230003  78.577634 -36.822650    2.851790\n",
      "2021-12-23  83.099998  84.199997  78.760229 -26.619072    2.395711\n",
      "2021-12-27  84.500000  86.599998  79.254777 -14.188268    2.850358\n",
      "2021-12-28  86.199997  85.029999  79.934092 -22.320079   -1.812933\n",
      "2021-12-29  84.889999  85.260002  80.845266 -17.004946    0.270497\n",
      "2021-12-30  85.180000  87.417297  81.603419  -5.247014    2.530255\n"
     ]
    }
   ],
   "source": [
    "data = getDB(ticker)\n",
    "print(data['close_per1'].std())\n",
    "print(data.head(15))\n",
    "print(data.tail(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_data(ticker):\n",
    "    df = getDB(ticker)\n",
    "\n",
    "    df['CP_ol'] = 0\n",
    "    df['CO_il'] = 0\n",
    "    df['SMA10_il'] = 0\n",
    "    df['W_il'] = 0\n",
    "    \n",
    "    value = df['close_per1'].std()\n",
    "    \n",
    "    # setting the outputs in the df\n",
    "    for i in range(len(df)):\n",
    "        if df.iloc[i]['close_per1'] > value:\n",
    "            df.iloc[i, df.columns.get_loc('CP_ol')] = 2\n",
    "        elif df.iloc[i]['close_per1'] < -value:\n",
    "            df.iloc[i, df.columns.get_loc('CP_ol')] = 1\n",
    "        else:\n",
    "            df.iloc[i, df.columns.get_loc('CP_ol')] = 0\n",
    "    \n",
    "    # setting the inputs in the df\n",
    "    for i in range(len(df)-1):\n",
    "        try:\n",
    "            if df.iloc[i]['close'] < df.iloc[i+1]['open']:\n",
    "                df.iloc[i+1, df.columns.get_loc('CO_il')] = 1\n",
    "            else:\n",
    "                df.iloc[i+1, df.columns.get_loc('CO_il')] = 0\n",
    "        except:\n",
    "            df.iloc[i+1, df.columns.get_loc('CO_il')] = np.nan\n",
    "            \n",
    "    \n",
    "    # setting the inputs in the df\n",
    "    for i in range(len(df)):\n",
    "        try:\n",
    "            if df.iloc[i]['close'] > df.iloc[i]['sma10']:\n",
    "                df.iloc[i, df.columns.get_loc('SMA10_il')] = 1\n",
    "            else:\n",
    "                df.iloc[i, df.columns.get_loc('SMA10_il')] = 0\n",
    "        except:\n",
    "            df.iloc[i, df.columns.get_loc('SMA10_il')] = np.nan\n",
    "            \n",
    "    \n",
    "    # setting the inputs in the df\n",
    "    for i in range(len(df)):\n",
    "        if df.iloc[i]['williams'] > -30: # overbought\n",
    "            df.iloc[i, df.columns.get_loc('W_il')] = -1\n",
    "        elif df.iloc[i]['williams'] < -70: # oversold\n",
    "            df.iloc[i, df.columns.get_loc('W_il')] = 1\n",
    "        else:\n",
    "            df.iloc[i, df.columns.get_loc('W_il')] = 0 # neutral\n",
    "    \n",
    "    \n",
    "    # deleting data that is not normalized\n",
    "    del df['open']\n",
    "    del df['close']\n",
    "    del df['sma10']\n",
    "    del df['williams']\n",
    "#     del df['close_per1']\n",
    "    \n",
    "    # reformating\n",
    "    df = df[[\n",
    "            'W_il','SMA10_il','CO_il','CP_ol','close_per1'\n",
    "            ]]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 open      close      sma10   williams  close_per1\n",
      "date                                                              \n",
      "2017-01-20  49.030236  49.208237  50.167484 -76.465377    1.478528\n",
      "2017-01-23  48.812673  48.649502  49.949428 -85.270668   -1.135450\n",
      "2017-01-24  49.163738  50.775665  50.048319 -47.116217    4.370371\n",
      "2017-01-25  52.031586  52.328259  50.155616 -16.128967    3.057751\n",
      "2017-01-26  52.348033  51.715126  50.177867 -19.549763   -1.171704\n",
      "                 open      close      sma10   williams  close_per1\n",
      "date                                                              \n",
      "2021-12-23  83.099998  84.199997  78.760229 -26.619072    2.395711\n",
      "2021-12-27  84.500000  86.599998  79.254777 -14.188268    2.850358\n",
      "2021-12-28  86.199997  85.029999  79.934092 -22.320079   -1.812933\n",
      "2021-12-29  84.889999  85.260002  80.845266 -17.004946    0.270497\n",
      "2021-12-30  85.180000  87.417297  81.603419  -5.247014    2.530255\n"
     ]
    }
   ],
   "source": [
    "df = set_data(ticker)\n",
    "print(data.head())\n",
    "print(data.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_train(tickers, SEQ_LEN, SHIFT):\n",
    "    Sequential_data = []\n",
    "    for ticker in tickers:\n",
    "        df = set_data(ticker)[0:-SHIFT]\n",
    "        \n",
    "        del df['close_per1']\n",
    "        \n",
    "        df.head()\n",
    "\n",
    "        sequential_data = []  # this is a list that will CONTAIN the sequences\n",
    "        prev_days = deque(maxlen=SEQ_LEN)  # These will be our actual sequences. They are made with deque, which keeps the maximum length by popping out older values as new ones come in\n",
    "        \n",
    "        for i in df.values:  # iterate over the values\n",
    "            prev_days.append([n for n in i[:-1]])  # store all but the target\n",
    "            if len(prev_days) == SEQ_LEN:  # make sure we have 60 sequences!\n",
    "                sequential_data.append([np.array(prev_days), i[-1]])  # append those bad boys!\n",
    "        \n",
    "        \n",
    "        random.shuffle(sequential_data)  # shuffle for good measure.\n",
    "        \n",
    "        buy = []; notbuy = []; maybe = []\n",
    "        \n",
    "        for seq, target in sequential_data:  # iterate over the sequential data\n",
    "            if target == 0:\n",
    "                maybe.append([seq, target])\n",
    "            elif target == 1:\n",
    "                notbuy.append([seq, target]) \n",
    "            elif target == 2:\n",
    "                buy.append([seq, target])  \n",
    "        \n",
    "        # suffle data\n",
    "        random.shuffle(buy)\n",
    "        random.shuffle(notbuy)\n",
    "        random.shuffle(maybe)\n",
    "        \n",
    "        lower = min(len(buy), len(notbuy), len(maybe))  # what's the shorter length?\n",
    "        \n",
    "        # make sure lists are only up to the shortest length.\n",
    "        buy = buy[:lower]  \n",
    "        notbuy = notbuy[:lower]\n",
    "        maybe = maybe[:lower]\n",
    "        \n",
    "        sequential_data = buy+notbuy+maybe # add them together\n",
    "        random.shuffle(sequential_data)  # another shuffle, so the model doesn't get confused with all 1 class then the other.\n",
    "    \n",
    "        Sequential_data = Sequential_data + sequential_data\n",
    "        \n",
    "    random.shuffle(Sequential_data)\n",
    "    X = []; y = []\n",
    "    for seq, target in Sequential_data:  # going over our new sequential data\n",
    "        X.append(seq)  # X is the sequences\n",
    "        y.append(target)  # y is the targets/labels (buys vs sell/notbuy)\n",
    "\n",
    "    return np.array(X).astype(\"float64\"), np.array(y).astype(\"uint8\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_test(tickers, SEQ_LEN, SHIFT):\n",
    "    Sequential_data = []\n",
    "    for ticker in tickers:\n",
    "        df = set_data(ticker)[-SHIFT:]\n",
    "        \n",
    "        del df['close_per1']\n",
    "        df.head()\n",
    "\n",
    "        sequential_data = []  # this is a list that will CONTAIN the sequences\n",
    "        prev_days = deque(maxlen=SEQ_LEN)  # These will be our actual sequences. They are made with deque, which keeps the maximum length by popping out older values as new ones come in\n",
    "        \n",
    "        for i in df.values:  # iterate over the values\n",
    "            prev_days.append([n for n in i[:-1]])  # store all but the target\n",
    "            if len(prev_days) == SEQ_LEN:  # make sure we have 60 sequences!\n",
    "                sequential_data.append([np.array(prev_days), i[-1]])  # append those bad boys!\n",
    "        \n",
    "        \n",
    "        random.shuffle(sequential_data)  # shuffle for good measure.\n",
    "        \n",
    "        buy = []; notbuy = []; maybe = []\n",
    "        \n",
    "        for seq, target in sequential_data:  # iterate over the sequential data\n",
    "            if target == 0:\n",
    "                maybe.append([seq, target])\n",
    "            elif target == 1:\n",
    "                notbuy.append([seq, target]) \n",
    "            elif target == 2:\n",
    "                buy.append([seq, target])  \n",
    "        \n",
    "        # suffle data\n",
    "        random.shuffle(buy)\n",
    "        random.shuffle(notbuy)\n",
    "        random.shuffle(maybe)\n",
    "        \n",
    "        lower = min(len(buy), len(notbuy), len(maybe))  # what's the shorter length?\n",
    "        \n",
    "        # make sure lists are only up to the shortest length.\n",
    "        buy = buy[:lower]  \n",
    "        notbuy = notbuy[:lower]\n",
    "        maybe = maybe[:lower]\n",
    "        \n",
    "        sequential_data = buy+notbuy+maybe # add them together\n",
    "        random.shuffle(sequential_data)  # another shuffle, so the model doesn't get confused with all 1 class then the other.\n",
    "    \n",
    "        Sequential_data = Sequential_data + sequential_data\n",
    "        \n",
    "    random.shuffle(Sequential_data)\n",
    "    X = []; y = []\n",
    "    for seq, target in Sequential_data:  # going over our new sequential data\n",
    "        X.append(seq)  # X is the sequences\n",
    "        y.append(target)  # y is the targets/labels (buys vs sell/notbuy)\n",
    "\n",
    "    return np.array(X).astype(\"float64\"), np.array(y).astype(\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 2  # how long of a preceeding sequence to collect for RNN\n",
    "# FUTURE_PERIOD_PREDICT = 3  # how far into the future are we trying to predict?\n",
    "SHIFT = 150  # how far to shift the data so it can be back testest\n",
    "BATCH_SIZE = 64 # how many batches? Try smaller batch if you're getting OOM (out of memory) errors.\n",
    "EPOCHS = 500 # how many passes through our data\n",
    "\n",
    "\n",
    "tickers_train = [ticker]\n",
    "tickers_test = [ticker]\n",
    "\n",
    "train_x, train_y = process_train(tickers_train, SEQ_LEN,SHIFT)\n",
    "validation_x, validation_y = process_test(tickers_test, SEQ_LEN, SHIFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.  1.]\n",
      " [-1.  1.  1.]]\n",
      "training data length: 315\n",
      "validation data length: 42\n"
     ]
    }
   ],
   "source": [
    "print(train_x[0])\n",
    "print('training data length: %d' % (len(train_x)))\n",
    "print('validation data length: %d' % (len(validation_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "length of train data:  315\n",
      "length of validation data:  42\n",
      "\n",
      "Epoch 1/500\n",
      "5/5 [==============================] - 3s 158ms/step - loss: 1.6161 - accuracy: 0.2571 - val_loss: 1.0989 - val_accuracy: 0.2857\n",
      "Epoch 2/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.5932 - accuracy: 0.2540 - val_loss: 1.0988 - val_accuracy: 0.3095\n",
      "Epoch 3/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.5795 - accuracy: 0.2508 - val_loss: 1.0987 - val_accuracy: 0.3095\n",
      "Epoch 4/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.5406 - accuracy: 0.2635 - val_loss: 1.0987 - val_accuracy: 0.3095\n",
      "Epoch 5/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.5274 - accuracy: 0.2857 - val_loss: 1.0986 - val_accuracy: 0.3095\n",
      "Epoch 6/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.4943 - accuracy: 0.2730 - val_loss: 1.0985 - val_accuracy: 0.2857\n",
      "Epoch 7/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.4849 - accuracy: 0.2984 - val_loss: 1.0984 - val_accuracy: 0.3333\n",
      "Epoch 8/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.4623 - accuracy: 0.2921 - val_loss: 1.0983 - val_accuracy: 0.3333\n",
      "Epoch 9/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.4371 - accuracy: 0.2921 - val_loss: 1.0982 - val_accuracy: 0.3333\n",
      "Epoch 10/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.4296 - accuracy: 0.3111 - val_loss: 1.0981 - val_accuracy: 0.3333\n",
      "Epoch 11/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.4014 - accuracy: 0.3079 - val_loss: 1.0980 - val_accuracy: 0.3333\n",
      "Epoch 12/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.3904 - accuracy: 0.3206 - val_loss: 1.0978 - val_accuracy: 0.2857\n",
      "Epoch 13/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.3647 - accuracy: 0.3206 - val_loss: 1.0977 - val_accuracy: 0.2857\n",
      "Epoch 14/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.3480 - accuracy: 0.3302 - val_loss: 1.0975 - val_accuracy: 0.2381\n",
      "Epoch 15/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.3422 - accuracy: 0.3429 - val_loss: 1.0974 - val_accuracy: 0.2381\n",
      "Epoch 16/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.3192 - accuracy: 0.3587 - val_loss: 1.0972 - val_accuracy: 0.2857\n",
      "Epoch 17/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.3054 - accuracy: 0.3492 - val_loss: 1.0970 - val_accuracy: 0.2857\n",
      "Epoch 18/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.2912 - accuracy: 0.3492 - val_loss: 1.0968 - val_accuracy: 0.2857\n",
      "Epoch 19/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.2788 - accuracy: 0.3365 - val_loss: 1.0967 - val_accuracy: 0.2857\n",
      "Epoch 20/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.2617 - accuracy: 0.3492 - val_loss: 1.0964 - val_accuracy: 0.2857\n",
      "Epoch 21/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.2550 - accuracy: 0.3460 - val_loss: 1.0962 - val_accuracy: 0.3810\n",
      "Epoch 22/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.2414 - accuracy: 0.3302 - val_loss: 1.0960 - val_accuracy: 0.3810\n",
      "Epoch 23/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.2322 - accuracy: 0.3333 - val_loss: 1.0957 - val_accuracy: 0.3810\n",
      "Epoch 24/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.2159 - accuracy: 0.3365 - val_loss: 1.0955 - val_accuracy: 0.3810\n",
      "Epoch 25/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.2018 - accuracy: 0.3492 - val_loss: 1.0952 - val_accuracy: 0.3810\n",
      "Epoch 26/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.1990 - accuracy: 0.3365 - val_loss: 1.0950 - val_accuracy: 0.4048\n",
      "Epoch 27/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.1916 - accuracy: 0.3556 - val_loss: 1.0947 - val_accuracy: 0.4048\n",
      "Epoch 28/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.1810 - accuracy: 0.3365 - val_loss: 1.0944 - val_accuracy: 0.4286\n",
      "Epoch 29/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.1776 - accuracy: 0.3397 - val_loss: 1.0940 - val_accuracy: 0.4286\n",
      "Epoch 30/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.1584 - accuracy: 0.3302 - val_loss: 1.0937 - val_accuracy: 0.4286\n",
      "Epoch 31/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.1537 - accuracy: 0.3270 - val_loss: 1.0934 - val_accuracy: 0.4286\n",
      "Epoch 32/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.1469 - accuracy: 0.3111 - val_loss: 1.0930 - val_accuracy: 0.4286\n",
      "Epoch 33/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.1352 - accuracy: 0.3270 - val_loss: 1.0926 - val_accuracy: 0.4286\n",
      "Epoch 34/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.1342 - accuracy: 0.3365 - val_loss: 1.0922 - val_accuracy: 0.4286\n",
      "Epoch 35/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.1263 - accuracy: 0.3429 - val_loss: 1.0918 - val_accuracy: 0.4286\n",
      "Epoch 36/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.1152 - accuracy: 0.3429 - val_loss: 1.0914 - val_accuracy: 0.4286\n",
      "Epoch 37/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.1109 - accuracy: 0.3429 - val_loss: 1.0910 - val_accuracy: 0.4524\n",
      "Epoch 38/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.1040 - accuracy: 0.3587 - val_loss: 1.0905 - val_accuracy: 0.4524\n",
      "Epoch 39/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.1009 - accuracy: 0.3429 - val_loss: 1.0900 - val_accuracy: 0.4524\n",
      "Epoch 40/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0990 - accuracy: 0.3619 - val_loss: 1.0895 - val_accuracy: 0.4524\n",
      "Epoch 41/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0933 - accuracy: 0.3937 - val_loss: 1.0890 - val_accuracy: 0.4524\n",
      "Epoch 42/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0787 - accuracy: 0.4063 - val_loss: 1.0885 - val_accuracy: 0.4286\n",
      "Epoch 43/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0809 - accuracy: 0.3968 - val_loss: 1.0880 - val_accuracy: 0.4048\n",
      "Epoch 44/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0766 - accuracy: 0.4095 - val_loss: 1.0874 - val_accuracy: 0.4048\n",
      "Epoch 45/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0725 - accuracy: 0.3873 - val_loss: 1.0868 - val_accuracy: 0.4048\n",
      "Epoch 46/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0641 - accuracy: 0.4222 - val_loss: 1.0862 - val_accuracy: 0.4048\n",
      "Epoch 47/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0743 - accuracy: 0.3937 - val_loss: 1.0856 - val_accuracy: 0.4048\n",
      "Epoch 48/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0565 - accuracy: 0.4349 - val_loss: 1.0850 - val_accuracy: 0.4048\n",
      "Epoch 49/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0560 - accuracy: 0.4159 - val_loss: 1.0844 - val_accuracy: 0.4048\n",
      "Epoch 50/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0551 - accuracy: 0.4317 - val_loss: 1.0838 - val_accuracy: 0.4048\n",
      "Epoch 51/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0482 - accuracy: 0.4603 - val_loss: 1.0831 - val_accuracy: 0.4048\n",
      "Epoch 52/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0498 - accuracy: 0.4444 - val_loss: 1.0824 - val_accuracy: 0.4048\n",
      "Epoch 53/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0487 - accuracy: 0.4444 - val_loss: 1.0817 - val_accuracy: 0.4048\n",
      "Epoch 54/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0399 - accuracy: 0.4667 - val_loss: 1.0810 - val_accuracy: 0.4048\n",
      "Epoch 55/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0357 - accuracy: 0.4698 - val_loss: 1.0802 - val_accuracy: 0.4048\n",
      "Epoch 56/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0394 - accuracy: 0.4508 - val_loss: 1.0795 - val_accuracy: 0.4048\n",
      "Epoch 57/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0285 - accuracy: 0.4952 - val_loss: 1.0787 - val_accuracy: 0.4048\n",
      "Epoch 58/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0235 - accuracy: 0.4921 - val_loss: 1.0780 - val_accuracy: 0.4286\n",
      "Epoch 59/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 11ms/step - loss: 1.0289 - accuracy: 0.4762 - val_loss: 1.0771 - val_accuracy: 0.4286\n",
      "Epoch 60/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0217 - accuracy: 0.5206 - val_loss: 1.0763 - val_accuracy: 0.4286\n",
      "Epoch 61/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0213 - accuracy: 0.4889 - val_loss: 1.0755 - val_accuracy: 0.4286\n",
      "Epoch 62/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0190 - accuracy: 0.4921 - val_loss: 1.0747 - val_accuracy: 0.4286\n",
      "Epoch 63/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0165 - accuracy: 0.4952 - val_loss: 1.0738 - val_accuracy: 0.4286\n",
      "Epoch 64/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0138 - accuracy: 0.5143 - val_loss: 1.0730 - val_accuracy: 0.4286\n",
      "Epoch 65/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0137 - accuracy: 0.5111 - val_loss: 1.0721 - val_accuracy: 0.4286\n",
      "Epoch 66/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0075 - accuracy: 0.5016 - val_loss: 1.0712 - val_accuracy: 0.4286\n",
      "Epoch 67/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0075 - accuracy: 0.5048 - val_loss: 1.0703 - val_accuracy: 0.4286\n",
      "Epoch 68/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0062 - accuracy: 0.5175 - val_loss: 1.0694 - val_accuracy: 0.4524\n",
      "Epoch 69/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9985 - accuracy: 0.5238 - val_loss: 1.0685 - val_accuracy: 0.4524\n",
      "Epoch 70/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0001 - accuracy: 0.5048 - val_loss: 1.0675 - val_accuracy: 0.4524\n",
      "Epoch 71/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0032 - accuracy: 0.5111 - val_loss: 1.0666 - val_accuracy: 0.4524\n",
      "Epoch 72/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9969 - accuracy: 0.5175 - val_loss: 1.0656 - val_accuracy: 0.4524\n",
      "Epoch 73/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9957 - accuracy: 0.5270 - val_loss: 1.0646 - val_accuracy: 0.4524\n",
      "Epoch 74/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0017 - accuracy: 0.5111 - val_loss: 1.0636 - val_accuracy: 0.4524\n",
      "Epoch 75/500\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.9906 - accuracy: 0.5333 - val_loss: 1.0626 - val_accuracy: 0.4524\n",
      "Epoch 76/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9944 - accuracy: 0.5111 - val_loss: 1.0615 - val_accuracy: 0.4524\n",
      "Epoch 77/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9914 - accuracy: 0.5016 - val_loss: 1.0605 - val_accuracy: 0.4524\n",
      "Epoch 78/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9815 - accuracy: 0.5460 - val_loss: 1.0594 - val_accuracy: 0.4524\n",
      "Epoch 79/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9926 - accuracy: 0.5333 - val_loss: 1.0584 - val_accuracy: 0.4524\n",
      "Epoch 80/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9854 - accuracy: 0.5143 - val_loss: 1.0574 - val_accuracy: 0.4524\n",
      "Epoch 81/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9822 - accuracy: 0.5460 - val_loss: 1.0562 - val_accuracy: 0.4524\n",
      "Epoch 82/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9803 - accuracy: 0.5429 - val_loss: 1.0551 - val_accuracy: 0.4524\n",
      "Epoch 83/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9823 - accuracy: 0.5460 - val_loss: 1.0540 - val_accuracy: 0.4524\n",
      "Epoch 84/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9843 - accuracy: 0.5397 - val_loss: 1.0528 - val_accuracy: 0.4524\n",
      "Epoch 85/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9777 - accuracy: 0.5365 - val_loss: 1.0516 - val_accuracy: 0.4524\n",
      "Epoch 86/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9749 - accuracy: 0.5270 - val_loss: 1.0505 - val_accuracy: 0.4524\n",
      "Epoch 87/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9798 - accuracy: 0.5556 - val_loss: 1.0493 - val_accuracy: 0.4524\n",
      "Epoch 88/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9775 - accuracy: 0.5333 - val_loss: 1.0482 - val_accuracy: 0.4762\n",
      "Epoch 89/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9710 - accuracy: 0.5397 - val_loss: 1.0470 - val_accuracy: 0.4762\n",
      "Epoch 90/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9761 - accuracy: 0.5143 - val_loss: 1.0459 - val_accuracy: 0.4762\n",
      "Epoch 91/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9706 - accuracy: 0.5429 - val_loss: 1.0447 - val_accuracy: 0.4762\n",
      "Epoch 92/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9852 - accuracy: 0.5365 - val_loss: 1.0435 - val_accuracy: 0.4762\n",
      "Epoch 93/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9744 - accuracy: 0.5429 - val_loss: 1.0422 - val_accuracy: 0.4762\n",
      "Epoch 94/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9744 - accuracy: 0.5238 - val_loss: 1.0410 - val_accuracy: 0.4762\n",
      "Epoch 95/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9658 - accuracy: 0.5238 - val_loss: 1.0397 - val_accuracy: 0.4524\n",
      "Epoch 96/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9626 - accuracy: 0.5429 - val_loss: 1.0386 - val_accuracy: 0.4524\n",
      "Epoch 97/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9688 - accuracy: 0.5429 - val_loss: 1.0372 - val_accuracy: 0.4524\n",
      "Epoch 98/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9640 - accuracy: 0.5365 - val_loss: 1.0360 - val_accuracy: 0.4524\n",
      "Epoch 99/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9629 - accuracy: 0.5302 - val_loss: 1.0346 - val_accuracy: 0.4524\n",
      "Epoch 100/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9630 - accuracy: 0.5302 - val_loss: 1.0333 - val_accuracy: 0.4524\n",
      "Epoch 101/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9600 - accuracy: 0.5333 - val_loss: 1.0320 - val_accuracy: 0.4524\n",
      "Epoch 102/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9618 - accuracy: 0.5492 - val_loss: 1.0308 - val_accuracy: 0.4762\n",
      "Epoch 103/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9608 - accuracy: 0.5429 - val_loss: 1.0294 - val_accuracy: 0.4762\n",
      "Epoch 104/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9596 - accuracy: 0.5492 - val_loss: 1.0280 - val_accuracy: 0.4762\n",
      "Epoch 105/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9562 - accuracy: 0.5365 - val_loss: 1.0266 - val_accuracy: 0.4762\n",
      "Epoch 106/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9627 - accuracy: 0.5206 - val_loss: 1.0252 - val_accuracy: 0.4762\n",
      "Epoch 107/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9589 - accuracy: 0.5397 - val_loss: 1.0239 - val_accuracy: 0.4762\n",
      "Epoch 108/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9610 - accuracy: 0.5206 - val_loss: 1.0224 - val_accuracy: 0.4762\n",
      "Epoch 109/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9536 - accuracy: 0.5619 - val_loss: 1.0210 - val_accuracy: 0.4762\n",
      "Epoch 110/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9550 - accuracy: 0.5206 - val_loss: 1.0195 - val_accuracy: 0.4762\n",
      "Epoch 111/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9518 - accuracy: 0.5302 - val_loss: 1.0181 - val_accuracy: 0.5000\n",
      "Epoch 112/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9566 - accuracy: 0.5397 - val_loss: 1.0166 - val_accuracy: 0.5000\n",
      "Epoch 113/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9509 - accuracy: 0.5587 - val_loss: 1.0152 - val_accuracy: 0.5000\n",
      "Epoch 114/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9540 - accuracy: 0.5460 - val_loss: 1.0138 - val_accuracy: 0.5000\n",
      "Epoch 115/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9518 - accuracy: 0.5524 - val_loss: 1.0123 - val_accuracy: 0.5000\n",
      "Epoch 116/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9518 - accuracy: 0.5397 - val_loss: 1.0108 - val_accuracy: 0.5000\n",
      "Epoch 117/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 7ms/step - loss: 0.9490 - accuracy: 0.5556 - val_loss: 1.0093 - val_accuracy: 0.5000\n",
      "Epoch 118/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9455 - accuracy: 0.5524 - val_loss: 1.0077 - val_accuracy: 0.5000\n",
      "Epoch 119/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9460 - accuracy: 0.5460 - val_loss: 1.0062 - val_accuracy: 0.5714\n",
      "Epoch 120/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9467 - accuracy: 0.5587 - val_loss: 1.0048 - val_accuracy: 0.5714\n",
      "Epoch 121/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9442 - accuracy: 0.5619 - val_loss: 1.0033 - val_accuracy: 0.5714\n",
      "Epoch 122/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9417 - accuracy: 0.5587 - val_loss: 1.0018 - val_accuracy: 0.5714\n",
      "Epoch 123/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9420 - accuracy: 0.5841 - val_loss: 1.0001 - val_accuracy: 0.5714\n",
      "Epoch 124/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9389 - accuracy: 0.5556 - val_loss: 0.9986 - val_accuracy: 0.5714\n",
      "Epoch 125/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9459 - accuracy: 0.5302 - val_loss: 0.9971 - val_accuracy: 0.5714\n",
      "Epoch 126/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9339 - accuracy: 0.5810 - val_loss: 0.9955 - val_accuracy: 0.5714\n",
      "Epoch 127/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9409 - accuracy: 0.5778 - val_loss: 0.9939 - val_accuracy: 0.5714\n",
      "Epoch 128/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9361 - accuracy: 0.5810 - val_loss: 0.9923 - val_accuracy: 0.5714\n",
      "Epoch 129/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9399 - accuracy: 0.5460 - val_loss: 0.9908 - val_accuracy: 0.5714\n",
      "Epoch 130/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9362 - accuracy: 0.5651 - val_loss: 0.9892 - val_accuracy: 0.5714\n",
      "Epoch 131/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9369 - accuracy: 0.5587 - val_loss: 0.9877 - val_accuracy: 0.5714\n",
      "Epoch 132/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9376 - accuracy: 0.5556 - val_loss: 0.9862 - val_accuracy: 0.5714\n",
      "Epoch 133/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9388 - accuracy: 0.5587 - val_loss: 0.9847 - val_accuracy: 0.5714\n",
      "Epoch 134/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9274 - accuracy: 0.5937 - val_loss: 0.9832 - val_accuracy: 0.5714\n",
      "Epoch 135/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9394 - accuracy: 0.5683 - val_loss: 0.9818 - val_accuracy: 0.5714\n",
      "Epoch 136/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9312 - accuracy: 0.5460 - val_loss: 0.9802 - val_accuracy: 0.5714\n",
      "Epoch 137/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9339 - accuracy: 0.5683 - val_loss: 0.9786 - val_accuracy: 0.6190\n",
      "Epoch 138/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9254 - accuracy: 0.5778 - val_loss: 0.9771 - val_accuracy: 0.6190\n",
      "Epoch 139/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9310 - accuracy: 0.5810 - val_loss: 0.9754 - val_accuracy: 0.6190\n",
      "Epoch 140/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9343 - accuracy: 0.5460 - val_loss: 0.9740 - val_accuracy: 0.6190\n",
      "Epoch 141/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9252 - accuracy: 0.5683 - val_loss: 0.9725 - val_accuracy: 0.6190\n",
      "Epoch 142/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9285 - accuracy: 0.5651 - val_loss: 0.9711 - val_accuracy: 0.6190\n",
      "Epoch 143/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9285 - accuracy: 0.5810 - val_loss: 0.9697 - val_accuracy: 0.6190\n",
      "Epoch 144/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9242 - accuracy: 0.5778 - val_loss: 0.9682 - val_accuracy: 0.6190\n",
      "Epoch 145/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9227 - accuracy: 0.5587 - val_loss: 0.9668 - val_accuracy: 0.6190\n",
      "Epoch 146/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9187 - accuracy: 0.5746 - val_loss: 0.9656 - val_accuracy: 0.6190\n",
      "Epoch 147/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9206 - accuracy: 0.5937 - val_loss: 0.9642 - val_accuracy: 0.6190\n",
      "Epoch 148/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9215 - accuracy: 0.5746 - val_loss: 0.9629 - val_accuracy: 0.6190\n",
      "Epoch 149/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9262 - accuracy: 0.5714 - val_loss: 0.9616 - val_accuracy: 0.6190\n",
      "Epoch 150/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9107 - accuracy: 0.5905 - val_loss: 0.9603 - val_accuracy: 0.6190\n",
      "Epoch 151/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9161 - accuracy: 0.5619 - val_loss: 0.9588 - val_accuracy: 0.6190\n",
      "Epoch 152/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9133 - accuracy: 0.5778 - val_loss: 0.9576 - val_accuracy: 0.6190\n",
      "Epoch 153/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9135 - accuracy: 0.5937 - val_loss: 0.9563 - val_accuracy: 0.6190\n",
      "Epoch 154/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9168 - accuracy: 0.5778 - val_loss: 0.9550 - val_accuracy: 0.6667\n",
      "Epoch 155/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9168 - accuracy: 0.5587 - val_loss: 0.9537 - val_accuracy: 0.6667\n",
      "Epoch 156/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9160 - accuracy: 0.5841 - val_loss: 0.9526 - val_accuracy: 0.6667\n",
      "Epoch 157/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9075 - accuracy: 0.5937 - val_loss: 0.9513 - val_accuracy: 0.6667\n",
      "Epoch 158/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9145 - accuracy: 0.5937 - val_loss: 0.9501 - val_accuracy: 0.6667\n",
      "Epoch 159/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9104 - accuracy: 0.5841 - val_loss: 0.9489 - val_accuracy: 0.6667\n",
      "Epoch 160/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9092 - accuracy: 0.5968 - val_loss: 0.9478 - val_accuracy: 0.6667\n",
      "Epoch 161/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9057 - accuracy: 0.5905 - val_loss: 0.9468 - val_accuracy: 0.6667\n",
      "Epoch 162/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8992 - accuracy: 0.6000 - val_loss: 0.9457 - val_accuracy: 0.6667\n",
      "Epoch 163/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9148 - accuracy: 0.5810 - val_loss: 0.9446 - val_accuracy: 0.6667\n",
      "Epoch 164/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9058 - accuracy: 0.5905 - val_loss: 0.9433 - val_accuracy: 0.6667\n",
      "Epoch 165/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9059 - accuracy: 0.5905 - val_loss: 0.9421 - val_accuracy: 0.6667\n",
      "Epoch 166/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9089 - accuracy: 0.5778 - val_loss: 0.9408 - val_accuracy: 0.6667\n",
      "Epoch 167/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9044 - accuracy: 0.5905 - val_loss: 0.9395 - val_accuracy: 0.6667\n",
      "Epoch 168/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9016 - accuracy: 0.5968 - val_loss: 0.9385 - val_accuracy: 0.6667\n",
      "Epoch 169/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9015 - accuracy: 0.5905 - val_loss: 0.9373 - val_accuracy: 0.6667\n",
      "Epoch 170/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8969 - accuracy: 0.6000 - val_loss: 0.9363 - val_accuracy: 0.6667\n",
      "Epoch 171/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8971 - accuracy: 0.5905 - val_loss: 0.9353 - val_accuracy: 0.6667\n",
      "Epoch 172/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9010 - accuracy: 0.5968 - val_loss: 0.9341 - val_accuracy: 0.6667\n",
      "Epoch 173/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9023 - accuracy: 0.5810 - val_loss: 0.9331 - val_accuracy: 0.6667\n",
      "Epoch 174/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9002 - accuracy: 0.6000 - val_loss: 0.9319 - val_accuracy: 0.6667\n",
      "Epoch 175/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9046 - accuracy: 0.5873 - val_loss: 0.9310 - val_accuracy: 0.6667\n",
      "Epoch 176/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8958 - accuracy: 0.6095 - val_loss: 0.9299 - val_accuracy: 0.6667\n",
      "Epoch 177/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8952 - accuracy: 0.5937 - val_loss: 0.9289 - val_accuracy: 0.6667\n",
      "Epoch 178/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8898 - accuracy: 0.6032 - val_loss: 0.9281 - val_accuracy: 0.6667\n",
      "Epoch 179/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8895 - accuracy: 0.6000 - val_loss: 0.9272 - val_accuracy: 0.6667\n",
      "Epoch 180/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8856 - accuracy: 0.6000 - val_loss: 0.9261 - val_accuracy: 0.6667\n",
      "Epoch 181/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9084 - accuracy: 0.6032 - val_loss: 0.9251 - val_accuracy: 0.6667\n",
      "Epoch 182/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8908 - accuracy: 0.6000 - val_loss: 0.9242 - val_accuracy: 0.6667\n",
      "Epoch 183/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8845 - accuracy: 0.6095 - val_loss: 0.9232 - val_accuracy: 0.6667\n",
      "Epoch 184/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8862 - accuracy: 0.5968 - val_loss: 0.9222 - val_accuracy: 0.6667\n",
      "Epoch 185/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8799 - accuracy: 0.6095 - val_loss: 0.9215 - val_accuracy: 0.6667\n",
      "Epoch 186/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8822 - accuracy: 0.6000 - val_loss: 0.9204 - val_accuracy: 0.6667\n",
      "Epoch 187/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8880 - accuracy: 0.5937 - val_loss: 0.9197 - val_accuracy: 0.6667\n",
      "Epoch 188/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8800 - accuracy: 0.6032 - val_loss: 0.9188 - val_accuracy: 0.6667\n",
      "Epoch 189/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8853 - accuracy: 0.6063 - val_loss: 0.9181 - val_accuracy: 0.6667\n",
      "Epoch 190/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8898 - accuracy: 0.6032 - val_loss: 0.9172 - val_accuracy: 0.6667\n",
      "Epoch 191/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8892 - accuracy: 0.6127 - val_loss: 0.9164 - val_accuracy: 0.6667\n",
      "Epoch 192/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8787 - accuracy: 0.5968 - val_loss: 0.9155 - val_accuracy: 0.6667\n",
      "Epoch 193/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8763 - accuracy: 0.6000 - val_loss: 0.9145 - val_accuracy: 0.7143\n",
      "Epoch 194/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8792 - accuracy: 0.6032 - val_loss: 0.9136 - val_accuracy: 0.7143\n",
      "Epoch 195/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8782 - accuracy: 0.6032 - val_loss: 0.9128 - val_accuracy: 0.7143\n",
      "Epoch 196/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8735 - accuracy: 0.6095 - val_loss: 0.9119 - val_accuracy: 0.7143\n",
      "Epoch 197/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8761 - accuracy: 0.5937 - val_loss: 0.9109 - val_accuracy: 0.7143\n",
      "Epoch 198/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8728 - accuracy: 0.6095 - val_loss: 0.9100 - val_accuracy: 0.7143\n",
      "Epoch 199/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8780 - accuracy: 0.5937 - val_loss: 0.9094 - val_accuracy: 0.7143\n",
      "Epoch 200/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8811 - accuracy: 0.6000 - val_loss: 0.9083 - val_accuracy: 0.7143\n",
      "Epoch 201/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8775 - accuracy: 0.6286 - val_loss: 0.9073 - val_accuracy: 0.7143\n",
      "Epoch 202/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8736 - accuracy: 0.6032 - val_loss: 0.9065 - val_accuracy: 0.7143\n",
      "Epoch 203/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8699 - accuracy: 0.6000 - val_loss: 0.9058 - val_accuracy: 0.7143\n",
      "Epoch 204/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8738 - accuracy: 0.6032 - val_loss: 0.9051 - val_accuracy: 0.7143\n",
      "Epoch 205/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8740 - accuracy: 0.5968 - val_loss: 0.9041 - val_accuracy: 0.7143\n",
      "Epoch 206/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8647 - accuracy: 0.6254 - val_loss: 0.9032 - val_accuracy: 0.7143\n",
      "Epoch 207/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8655 - accuracy: 0.6000 - val_loss: 0.9023 - val_accuracy: 0.7143\n",
      "Epoch 208/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8627 - accuracy: 0.6159 - val_loss: 0.9016 - val_accuracy: 0.7143\n",
      "Epoch 209/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8678 - accuracy: 0.6127 - val_loss: 0.9008 - val_accuracy: 0.7143\n",
      "Epoch 210/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8657 - accuracy: 0.5937 - val_loss: 0.9001 - val_accuracy: 0.7143\n",
      "Epoch 211/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8644 - accuracy: 0.6127 - val_loss: 0.8991 - val_accuracy: 0.7143\n",
      "Epoch 212/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8592 - accuracy: 0.6349 - val_loss: 0.8981 - val_accuracy: 0.7143\n",
      "Epoch 213/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8649 - accuracy: 0.6032 - val_loss: 0.8973 - val_accuracy: 0.7143\n",
      "Epoch 214/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8613 - accuracy: 0.6159 - val_loss: 0.8963 - val_accuracy: 0.7143\n",
      "Epoch 215/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8634 - accuracy: 0.6159 - val_loss: 0.8955 - val_accuracy: 0.7143\n",
      "Epoch 216/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8633 - accuracy: 0.6254 - val_loss: 0.8946 - val_accuracy: 0.7143\n",
      "Epoch 217/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8623 - accuracy: 0.6254 - val_loss: 0.8937 - val_accuracy: 0.7143\n",
      "Epoch 218/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8631 - accuracy: 0.6127 - val_loss: 0.8929 - val_accuracy: 0.7143\n",
      "Epoch 219/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8566 - accuracy: 0.6254 - val_loss: 0.8919 - val_accuracy: 0.7143\n",
      "Epoch 220/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8598 - accuracy: 0.6032 - val_loss: 0.8912 - val_accuracy: 0.7143\n",
      "Epoch 221/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8605 - accuracy: 0.6190 - val_loss: 0.8907 - val_accuracy: 0.7143\n",
      "Epoch 222/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8579 - accuracy: 0.6032 - val_loss: 0.8900 - val_accuracy: 0.7143\n",
      "Epoch 223/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8624 - accuracy: 0.6159 - val_loss: 0.8891 - val_accuracy: 0.7143\n",
      "Epoch 224/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8499 - accuracy: 0.6190 - val_loss: 0.8883 - val_accuracy: 0.7143\n",
      "Epoch 225/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8537 - accuracy: 0.6317 - val_loss: 0.8873 - val_accuracy: 0.7143\n",
      "Epoch 226/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8579 - accuracy: 0.6222 - val_loss: 0.8865 - val_accuracy: 0.7143\n",
      "Epoch 227/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8571 - accuracy: 0.6190 - val_loss: 0.8858 - val_accuracy: 0.7143\n",
      "Epoch 228/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8488 - accuracy: 0.6349 - val_loss: 0.8852 - val_accuracy: 0.7143\n",
      "Epoch 229/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8489 - accuracy: 0.6063 - val_loss: 0.8844 - val_accuracy: 0.7143\n",
      "Epoch 230/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8498 - accuracy: 0.6190 - val_loss: 0.8834 - val_accuracy: 0.7143\n",
      "Epoch 231/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8484 - accuracy: 0.6286 - val_loss: 0.8826 - val_accuracy: 0.7143\n",
      "Epoch 232/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8425 - accuracy: 0.6254 - val_loss: 0.8819 - val_accuracy: 0.7143\n",
      "Epoch 233/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8393 - accuracy: 0.6159 - val_loss: 0.8812 - val_accuracy: 0.7143\n",
      "Epoch 234/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8492 - accuracy: 0.6444 - val_loss: 0.8804 - val_accuracy: 0.7143\n",
      "Epoch 235/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8492 - accuracy: 0.6095 - val_loss: 0.8795 - val_accuracy: 0.7143\n",
      "Epoch 236/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8404 - accuracy: 0.6317 - val_loss: 0.8786 - val_accuracy: 0.7143\n",
      "Epoch 237/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8491 - accuracy: 0.6222 - val_loss: 0.8778 - val_accuracy: 0.7143\n",
      "Epoch 238/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8510 - accuracy: 0.6286 - val_loss: 0.8772 - val_accuracy: 0.7143\n",
      "Epoch 239/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8479 - accuracy: 0.6159 - val_loss: 0.8764 - val_accuracy: 0.7143\n",
      "Epoch 240/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8449 - accuracy: 0.6190 - val_loss: 0.8755 - val_accuracy: 0.7143\n",
      "Epoch 241/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8379 - accuracy: 0.6159 - val_loss: 0.8747 - val_accuracy: 0.7143\n",
      "Epoch 242/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8376 - accuracy: 0.6476 - val_loss: 0.8739 - val_accuracy: 0.7143\n",
      "Epoch 243/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8398 - accuracy: 0.6381 - val_loss: 0.8731 - val_accuracy: 0.7143\n",
      "Epoch 244/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8380 - accuracy: 0.6063 - val_loss: 0.8724 - val_accuracy: 0.7143\n",
      "Epoch 245/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8373 - accuracy: 0.6317 - val_loss: 0.8717 - val_accuracy: 0.7143\n",
      "Epoch 246/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8349 - accuracy: 0.6476 - val_loss: 0.8709 - val_accuracy: 0.7143\n",
      "Epoch 247/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8334 - accuracy: 0.6254 - val_loss: 0.8703 - val_accuracy: 0.7143\n",
      "Epoch 248/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8321 - accuracy: 0.6222 - val_loss: 0.8696 - val_accuracy: 0.7143\n",
      "Epoch 249/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8363 - accuracy: 0.6254 - val_loss: 0.8688 - val_accuracy: 0.7143\n",
      "Epoch 250/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8330 - accuracy: 0.6349 - val_loss: 0.8680 - val_accuracy: 0.7143\n",
      "Epoch 251/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8331 - accuracy: 0.6317 - val_loss: 0.8674 - val_accuracy: 0.7143\n",
      "Epoch 252/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8255 - accuracy: 0.6476 - val_loss: 0.8665 - val_accuracy: 0.7143\n",
      "Epoch 253/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8300 - accuracy: 0.6444 - val_loss: 0.8657 - val_accuracy: 0.7143\n",
      "Epoch 254/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8275 - accuracy: 0.6413 - val_loss: 0.8651 - val_accuracy: 0.7143\n",
      "Epoch 255/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8294 - accuracy: 0.6190 - val_loss: 0.8642 - val_accuracy: 0.6667\n",
      "Epoch 256/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8309 - accuracy: 0.6413 - val_loss: 0.8634 - val_accuracy: 0.6667\n",
      "Epoch 257/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8333 - accuracy: 0.6317 - val_loss: 0.8625 - val_accuracy: 0.6667\n",
      "Epoch 258/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8233 - accuracy: 0.6444 - val_loss: 0.8617 - val_accuracy: 0.6667\n",
      "Epoch 259/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8264 - accuracy: 0.6444 - val_loss: 0.8611 - val_accuracy: 0.6667\n",
      "Epoch 260/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8241 - accuracy: 0.6349 - val_loss: 0.8603 - val_accuracy: 0.6667\n",
      "Epoch 261/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.8238 - accuracy: 0.6222 - val_loss: 0.8595 - val_accuracy: 0.6667\n",
      "Epoch 262/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8274 - accuracy: 0.6381 - val_loss: 0.8588 - val_accuracy: 0.6667\n",
      "Epoch 263/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8209 - accuracy: 0.6413 - val_loss: 0.8582 - val_accuracy: 0.6667\n",
      "Epoch 264/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8263 - accuracy: 0.6286 - val_loss: 0.8576 - val_accuracy: 0.6667\n",
      "Epoch 265/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8247 - accuracy: 0.6032 - val_loss: 0.8570 - val_accuracy: 0.6667\n",
      "Epoch 266/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8325 - accuracy: 0.6444 - val_loss: 0.8562 - val_accuracy: 0.6667\n",
      "Epoch 267/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8214 - accuracy: 0.6286 - val_loss: 0.8556 - val_accuracy: 0.6667\n",
      "Epoch 268/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8209 - accuracy: 0.6381 - val_loss: 0.8549 - val_accuracy: 0.6667\n",
      "Epoch 269/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8222 - accuracy: 0.6254 - val_loss: 0.8542 - val_accuracy: 0.6667\n",
      "Epoch 270/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8143 - accuracy: 0.6444 - val_loss: 0.8535 - val_accuracy: 0.6667\n",
      "Epoch 271/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8126 - accuracy: 0.6317 - val_loss: 0.8528 - val_accuracy: 0.6667\n",
      "Epoch 272/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8201 - accuracy: 0.6286 - val_loss: 0.8524 - val_accuracy: 0.6667\n",
      "Epoch 273/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8199 - accuracy: 0.6317 - val_loss: 0.8519 - val_accuracy: 0.6667\n",
      "Epoch 274/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8115 - accuracy: 0.6540 - val_loss: 0.8511 - val_accuracy: 0.6667\n",
      "Epoch 275/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8113 - accuracy: 0.6381 - val_loss: 0.8505 - val_accuracy: 0.6667\n",
      "Epoch 276/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8094 - accuracy: 0.6508 - val_loss: 0.8500 - val_accuracy: 0.6667\n",
      "Epoch 277/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8169 - accuracy: 0.6286 - val_loss: 0.8490 - val_accuracy: 0.6667\n",
      "Epoch 278/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8159 - accuracy: 0.6413 - val_loss: 0.8484 - val_accuracy: 0.6667\n",
      "Epoch 279/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8073 - accuracy: 0.6381 - val_loss: 0.8477 - val_accuracy: 0.6667\n",
      "Epoch 280/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8153 - accuracy: 0.6349 - val_loss: 0.8468 - val_accuracy: 0.6667\n",
      "Epoch 281/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8183 - accuracy: 0.6540 - val_loss: 0.8462 - val_accuracy: 0.6667\n",
      "Epoch 282/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8130 - accuracy: 0.6413 - val_loss: 0.8457 - val_accuracy: 0.6667\n",
      "Epoch 283/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8076 - accuracy: 0.6508 - val_loss: 0.8452 - val_accuracy: 0.6667\n",
      "Epoch 284/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8093 - accuracy: 0.6349 - val_loss: 0.8443 - val_accuracy: 0.6667\n",
      "Epoch 285/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8102 - accuracy: 0.6381 - val_loss: 0.8435 - val_accuracy: 0.6667\n",
      "Epoch 286/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8053 - accuracy: 0.6508 - val_loss: 0.8427 - val_accuracy: 0.6667\n",
      "Epoch 287/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8110 - accuracy: 0.6317 - val_loss: 0.8422 - val_accuracy: 0.6667\n",
      "Epoch 288/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8040 - accuracy: 0.6476 - val_loss: 0.8415 - val_accuracy: 0.6667\n",
      "Epoch 289/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8081 - accuracy: 0.6571 - val_loss: 0.8412 - val_accuracy: 0.6667\n",
      "Epoch 290/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8088 - accuracy: 0.6476 - val_loss: 0.8407 - val_accuracy: 0.6667\n",
      "Epoch 291/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8016 - accuracy: 0.6413 - val_loss: 0.8400 - val_accuracy: 0.6667\n",
      "Epoch 292/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8074 - accuracy: 0.6190 - val_loss: 0.8394 - val_accuracy: 0.6667\n",
      "Epoch 293/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8026 - accuracy: 0.6317 - val_loss: 0.8387 - val_accuracy: 0.6667\n",
      "Epoch 294/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8059 - accuracy: 0.6286 - val_loss: 0.8384 - val_accuracy: 0.6667\n",
      "Epoch 295/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7975 - accuracy: 0.6476 - val_loss: 0.8381 - val_accuracy: 0.6667\n",
      "Epoch 296/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8098 - accuracy: 0.6381 - val_loss: 0.8374 - val_accuracy: 0.6667\n",
      "Epoch 297/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8071 - accuracy: 0.6349 - val_loss: 0.8366 - val_accuracy: 0.6667\n",
      "Epoch 298/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7950 - accuracy: 0.6571 - val_loss: 0.8361 - val_accuracy: 0.6667\n",
      "Epoch 299/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8021 - accuracy: 0.6381 - val_loss: 0.8355 - val_accuracy: 0.6667\n",
      "Epoch 300/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7951 - accuracy: 0.6381 - val_loss: 0.8349 - val_accuracy: 0.6667\n",
      "Epoch 301/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7991 - accuracy: 0.6381 - val_loss: 0.8341 - val_accuracy: 0.6667\n",
      "Epoch 302/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7986 - accuracy: 0.6444 - val_loss: 0.8332 - val_accuracy: 0.6667\n",
      "Epoch 303/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7993 - accuracy: 0.6349 - val_loss: 0.8326 - val_accuracy: 0.6667\n",
      "Epoch 304/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7915 - accuracy: 0.6540 - val_loss: 0.8320 - val_accuracy: 0.6667\n",
      "Epoch 305/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7895 - accuracy: 0.6667 - val_loss: 0.8316 - val_accuracy: 0.6667\n",
      "Epoch 306/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7955 - accuracy: 0.6444 - val_loss: 0.8310 - val_accuracy: 0.6667\n",
      "Epoch 307/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7973 - accuracy: 0.6508 - val_loss: 0.8304 - val_accuracy: 0.6667\n",
      "Epoch 308/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7932 - accuracy: 0.6476 - val_loss: 0.8296 - val_accuracy: 0.6667\n",
      "Epoch 309/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7923 - accuracy: 0.6381 - val_loss: 0.8290 - val_accuracy: 0.6667\n",
      "Epoch 310/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7900 - accuracy: 0.6508 - val_loss: 0.8286 - val_accuracy: 0.6667\n",
      "Epoch 311/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7903 - accuracy: 0.6540 - val_loss: 0.8281 - val_accuracy: 0.6667\n",
      "Epoch 312/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7933 - accuracy: 0.6381 - val_loss: 0.8276 - val_accuracy: 0.6667\n",
      "Epoch 313/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7895 - accuracy: 0.6508 - val_loss: 0.8269 - val_accuracy: 0.6667\n",
      "Epoch 314/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7877 - accuracy: 0.6476 - val_loss: 0.8264 - val_accuracy: 0.6667\n",
      "Epoch 315/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7900 - accuracy: 0.6381 - val_loss: 0.8257 - val_accuracy: 0.6667\n",
      "Epoch 316/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7862 - accuracy: 0.6635 - val_loss: 0.8249 - val_accuracy: 0.6667\n",
      "Epoch 317/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7929 - accuracy: 0.6444 - val_loss: 0.8243 - val_accuracy: 0.6667\n",
      "Epoch 318/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7936 - accuracy: 0.6508 - val_loss: 0.8236 - val_accuracy: 0.6667\n",
      "Epoch 319/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7920 - accuracy: 0.6444 - val_loss: 0.8231 - val_accuracy: 0.6667\n",
      "Epoch 320/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7930 - accuracy: 0.6413 - val_loss: 0.8227 - val_accuracy: 0.6667\n",
      "Epoch 321/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7853 - accuracy: 0.6508 - val_loss: 0.8220 - val_accuracy: 0.6667\n",
      "Epoch 322/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7852 - accuracy: 0.6476 - val_loss: 0.8217 - val_accuracy: 0.6667\n",
      "Epoch 323/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7856 - accuracy: 0.6540 - val_loss: 0.8213 - val_accuracy: 0.6667\n",
      "Epoch 324/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7848 - accuracy: 0.6476 - val_loss: 0.8206 - val_accuracy: 0.6667\n",
      "Epoch 325/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7755 - accuracy: 0.6635 - val_loss: 0.8200 - val_accuracy: 0.6667\n",
      "Epoch 326/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7813 - accuracy: 0.6444 - val_loss: 0.8196 - val_accuracy: 0.6667\n",
      "Epoch 327/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7791 - accuracy: 0.6413 - val_loss: 0.8189 - val_accuracy: 0.6667\n",
      "Epoch 328/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7774 - accuracy: 0.6508 - val_loss: 0.8183 - val_accuracy: 0.6667\n",
      "Epoch 329/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7828 - accuracy: 0.6317 - val_loss: 0.8177 - val_accuracy: 0.6667\n",
      "Epoch 330/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7848 - accuracy: 0.6794 - val_loss: 0.8174 - val_accuracy: 0.6667\n",
      "Epoch 331/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7781 - accuracy: 0.6444 - val_loss: 0.8165 - val_accuracy: 0.6667\n",
      "Epoch 332/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7890 - accuracy: 0.6413 - val_loss: 0.8161 - val_accuracy: 0.6667\n",
      "Epoch 333/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7730 - accuracy: 0.6571 - val_loss: 0.8160 - val_accuracy: 0.6667\n",
      "Epoch 334/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7793 - accuracy: 0.6571 - val_loss: 0.8155 - val_accuracy: 0.6667\n",
      "Epoch 335/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7732 - accuracy: 0.6571 - val_loss: 0.8151 - val_accuracy: 0.6667\n",
      "Epoch 336/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7726 - accuracy: 0.6444 - val_loss: 0.8145 - val_accuracy: 0.6667\n",
      "Epoch 337/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7778 - accuracy: 0.6413 - val_loss: 0.8140 - val_accuracy: 0.6667\n",
      "Epoch 338/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7741 - accuracy: 0.6540 - val_loss: 0.8135 - val_accuracy: 0.6667\n",
      "Epoch 339/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7671 - accuracy: 0.6698 - val_loss: 0.8132 - val_accuracy: 0.6667\n",
      "Epoch 340/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7764 - accuracy: 0.6444 - val_loss: 0.8126 - val_accuracy: 0.6667\n",
      "Epoch 341/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7745 - accuracy: 0.6476 - val_loss: 0.8121 - val_accuracy: 0.6429\n",
      "Epoch 342/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7679 - accuracy: 0.6571 - val_loss: 0.8115 - val_accuracy: 0.6429\n",
      "Epoch 343/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7765 - accuracy: 0.6476 - val_loss: 0.8110 - val_accuracy: 0.6667\n",
      "Epoch 344/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7831 - accuracy: 0.6540 - val_loss: 0.8105 - val_accuracy: 0.6429\n",
      "Epoch 345/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7717 - accuracy: 0.6540 - val_loss: 0.8100 - val_accuracy: 0.6429\n",
      "Epoch 346/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7692 - accuracy: 0.6730 - val_loss: 0.8096 - val_accuracy: 0.6429\n",
      "Epoch 347/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7794 - accuracy: 0.6476 - val_loss: 0.8089 - val_accuracy: 0.6429\n",
      "Epoch 348/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7737 - accuracy: 0.6508 - val_loss: 0.8084 - val_accuracy: 0.6429\n",
      "Epoch 349/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7685 - accuracy: 0.6571 - val_loss: 0.8080 - val_accuracy: 0.6429\n",
      "Epoch 350/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7790 - accuracy: 0.6540 - val_loss: 0.8076 - val_accuracy: 0.6429\n",
      "Epoch 351/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7701 - accuracy: 0.6476 - val_loss: 0.8071 - val_accuracy: 0.6429\n",
      "Epoch 352/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7627 - accuracy: 0.6508 - val_loss: 0.8067 - val_accuracy: 0.5714\n",
      "Epoch 353/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7639 - accuracy: 0.6571 - val_loss: 0.8061 - val_accuracy: 0.5714\n",
      "Epoch 354/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7668 - accuracy: 0.6476 - val_loss: 0.8056 - val_accuracy: 0.5714\n",
      "Epoch 355/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7640 - accuracy: 0.6571 - val_loss: 0.8051 - val_accuracy: 0.5714\n",
      "Epoch 356/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7783 - accuracy: 0.6508 - val_loss: 0.8044 - val_accuracy: 0.5714\n",
      "Epoch 357/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7624 - accuracy: 0.6571 - val_loss: 0.8040 - val_accuracy: 0.5714\n",
      "Epoch 358/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7761 - accuracy: 0.6444 - val_loss: 0.8036 - val_accuracy: 0.5714\n",
      "Epoch 359/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7668 - accuracy: 0.6571 - val_loss: 0.8029 - val_accuracy: 0.5714\n",
      "Epoch 360/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7611 - accuracy: 0.6603 - val_loss: 0.8024 - val_accuracy: 0.5714\n",
      "Epoch 361/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7667 - accuracy: 0.6571 - val_loss: 0.8018 - val_accuracy: 0.5714\n",
      "Epoch 362/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7609 - accuracy: 0.6571 - val_loss: 0.8013 - val_accuracy: 0.5714\n",
      "Epoch 363/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7593 - accuracy: 0.6476 - val_loss: 0.8008 - val_accuracy: 0.5714\n",
      "Epoch 364/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7553 - accuracy: 0.6635 - val_loss: 0.8001 - val_accuracy: 0.5714\n",
      "Epoch 365/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7606 - accuracy: 0.6413 - val_loss: 0.7995 - val_accuracy: 0.5714\n",
      "Epoch 366/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7613 - accuracy: 0.6667 - val_loss: 0.7990 - val_accuracy: 0.5714\n",
      "Epoch 367/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7616 - accuracy: 0.6603 - val_loss: 0.7983 - val_accuracy: 0.5714\n",
      "Epoch 368/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7562 - accuracy: 0.6667 - val_loss: 0.7978 - val_accuracy: 0.5714\n",
      "Epoch 369/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7588 - accuracy: 0.6667 - val_loss: 0.7971 - val_accuracy: 0.5714\n",
      "Epoch 370/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7611 - accuracy: 0.6603 - val_loss: 0.7966 - val_accuracy: 0.5714\n",
      "Epoch 371/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7561 - accuracy: 0.6476 - val_loss: 0.7963 - val_accuracy: 0.5714\n",
      "Epoch 372/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7596 - accuracy: 0.6603 - val_loss: 0.7960 - val_accuracy: 0.5714\n",
      "Epoch 373/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7691 - accuracy: 0.6349 - val_loss: 0.7956 - val_accuracy: 0.5714\n",
      "Epoch 374/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7547 - accuracy: 0.6571 - val_loss: 0.7953 - val_accuracy: 0.5714\n",
      "Epoch 375/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7523 - accuracy: 0.6603 - val_loss: 0.7949 - val_accuracy: 0.5714\n",
      "Epoch 376/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7589 - accuracy: 0.6444 - val_loss: 0.7946 - val_accuracy: 0.5714\n",
      "Epoch 377/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7566 - accuracy: 0.6635 - val_loss: 0.7944 - val_accuracy: 0.5714\n",
      "Epoch 378/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7479 - accuracy: 0.6667 - val_loss: 0.7939 - val_accuracy: 0.5714\n",
      "Epoch 379/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7683 - accuracy: 0.6571 - val_loss: 0.7934 - val_accuracy: 0.5714\n",
      "Epoch 380/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7744 - accuracy: 0.6476 - val_loss: 0.7928 - val_accuracy: 0.5714\n",
      "Epoch 381/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7630 - accuracy: 0.6698 - val_loss: 0.7924 - val_accuracy: 0.5714\n",
      "Epoch 382/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7518 - accuracy: 0.6635 - val_loss: 0.7920 - val_accuracy: 0.5714\n",
      "Epoch 383/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7482 - accuracy: 0.6444 - val_loss: 0.7917 - val_accuracy: 0.5714\n",
      "Epoch 384/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7648 - accuracy: 0.6444 - val_loss: 0.7912 - val_accuracy: 0.5714\n",
      "Epoch 385/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7709 - accuracy: 0.6508 - val_loss: 0.7908 - val_accuracy: 0.5714\n",
      "Epoch 386/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7565 - accuracy: 0.6413 - val_loss: 0.7903 - val_accuracy: 0.5714\n",
      "Epoch 387/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7491 - accuracy: 0.6413 - val_loss: 0.7901 - val_accuracy: 0.5714\n",
      "Epoch 388/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7623 - accuracy: 0.6571 - val_loss: 0.7899 - val_accuracy: 0.5714\n",
      "Epoch 389/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7516 - accuracy: 0.6476 - val_loss: 0.7897 - val_accuracy: 0.5714\n",
      "Epoch 390/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7499 - accuracy: 0.6794 - val_loss: 0.7893 - val_accuracy: 0.5714\n",
      "Epoch 391/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7508 - accuracy: 0.6571 - val_loss: 0.7891 - val_accuracy: 0.5714\n",
      "Epoch 392/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7472 - accuracy: 0.6794 - val_loss: 0.7889 - val_accuracy: 0.5714\n",
      "Epoch 393/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7480 - accuracy: 0.6603 - val_loss: 0.7884 - val_accuracy: 0.5714\n",
      "Epoch 394/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7484 - accuracy: 0.6603 - val_loss: 0.7879 - val_accuracy: 0.5714\n",
      "Epoch 395/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7472 - accuracy: 0.6635 - val_loss: 0.7874 - val_accuracy: 0.5714\n",
      "Epoch 396/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7565 - accuracy: 0.6508 - val_loss: 0.7869 - val_accuracy: 0.5714\n",
      "Epoch 397/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7542 - accuracy: 0.6698 - val_loss: 0.7863 - val_accuracy: 0.5714\n",
      "Epoch 398/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7549 - accuracy: 0.6444 - val_loss: 0.7860 - val_accuracy: 0.5714\n",
      "Epoch 399/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7410 - accuracy: 0.6603 - val_loss: 0.7856 - val_accuracy: 0.5714\n",
      "Epoch 400/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7513 - accuracy: 0.6603 - val_loss: 0.7852 - val_accuracy: 0.5714\n",
      "Epoch 401/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7423 - accuracy: 0.6540 - val_loss: 0.7849 - val_accuracy: 0.5714\n",
      "Epoch 402/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7384 - accuracy: 0.6889 - val_loss: 0.7843 - val_accuracy: 0.5714\n",
      "Epoch 403/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7496 - accuracy: 0.6730 - val_loss: 0.7842 - val_accuracy: 0.5714\n",
      "Epoch 404/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7492 - accuracy: 0.6730 - val_loss: 0.7841 - val_accuracy: 0.5714\n",
      "Epoch 405/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7393 - accuracy: 0.6603 - val_loss: 0.7835 - val_accuracy: 0.5714\n",
      "Epoch 406/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7392 - accuracy: 0.6794 - val_loss: 0.7830 - val_accuracy: 0.5714\n",
      "Epoch 407/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7515 - accuracy: 0.6698 - val_loss: 0.7825 - val_accuracy: 0.5714\n",
      "Epoch 408/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7379 - accuracy: 0.6635 - val_loss: 0.7820 - val_accuracy: 0.5714\n",
      "Epoch 409/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7474 - accuracy: 0.6476 - val_loss: 0.7817 - val_accuracy: 0.5714\n",
      "Epoch 410/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7401 - accuracy: 0.6603 - val_loss: 0.7817 - val_accuracy: 0.5714\n",
      "Epoch 411/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7445 - accuracy: 0.6540 - val_loss: 0.7813 - val_accuracy: 0.5714\n",
      "Epoch 412/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7390 - accuracy: 0.6571 - val_loss: 0.7812 - val_accuracy: 0.5714\n",
      "Epoch 413/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7404 - accuracy: 0.6571 - val_loss: 0.7805 - val_accuracy: 0.5714\n",
      "Epoch 414/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7364 - accuracy: 0.6667 - val_loss: 0.7799 - val_accuracy: 0.5714\n",
      "Epoch 415/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7361 - accuracy: 0.6635 - val_loss: 0.7796 - val_accuracy: 0.5714\n",
      "Epoch 416/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7443 - accuracy: 0.6698 - val_loss: 0.7792 - val_accuracy: 0.5714\n",
      "Epoch 417/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7337 - accuracy: 0.6571 - val_loss: 0.7789 - val_accuracy: 0.5714\n",
      "Epoch 418/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7422 - accuracy: 0.6571 - val_loss: 0.7788 - val_accuracy: 0.5714\n",
      "Epoch 419/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7324 - accuracy: 0.6698 - val_loss: 0.7784 - val_accuracy: 0.5714\n",
      "Epoch 420/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7357 - accuracy: 0.6540 - val_loss: 0.7780 - val_accuracy: 0.5714\n",
      "Epoch 421/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7336 - accuracy: 0.6762 - val_loss: 0.7778 - val_accuracy: 0.5714\n",
      "Epoch 422/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7275 - accuracy: 0.6571 - val_loss: 0.7774 - val_accuracy: 0.5714\n",
      "Epoch 423/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7364 - accuracy: 0.6730 - val_loss: 0.7771 - val_accuracy: 0.5714\n",
      "Epoch 424/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7293 - accuracy: 0.6762 - val_loss: 0.7768 - val_accuracy: 0.5714\n",
      "Epoch 425/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7339 - accuracy: 0.6635 - val_loss: 0.7763 - val_accuracy: 0.5714\n",
      "Epoch 426/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7380 - accuracy: 0.6730 - val_loss: 0.7759 - val_accuracy: 0.5714\n",
      "Epoch 427/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7249 - accuracy: 0.6857 - val_loss: 0.7758 - val_accuracy: 0.5714\n",
      "Epoch 428/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7406 - accuracy: 0.6540 - val_loss: 0.7754 - val_accuracy: 0.5714\n",
      "Epoch 429/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7309 - accuracy: 0.6667 - val_loss: 0.7751 - val_accuracy: 0.5714\n",
      "Epoch 430/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7324 - accuracy: 0.6698 - val_loss: 0.7749 - val_accuracy: 0.5714\n",
      "Epoch 431/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7323 - accuracy: 0.6540 - val_loss: 0.7747 - val_accuracy: 0.5714\n",
      "Epoch 432/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7469 - accuracy: 0.6508 - val_loss: 0.7746 - val_accuracy: 0.5952\n",
      "Epoch 433/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7361 - accuracy: 0.6635 - val_loss: 0.7741 - val_accuracy: 0.5714\n",
      "Epoch 434/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7327 - accuracy: 0.6667 - val_loss: 0.7737 - val_accuracy: 0.5714\n",
      "Epoch 435/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7373 - accuracy: 0.6635 - val_loss: 0.7733 - val_accuracy: 0.5714\n",
      "Epoch 436/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7349 - accuracy: 0.6698 - val_loss: 0.7732 - val_accuracy: 0.5714\n",
      "Epoch 437/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7352 - accuracy: 0.6667 - val_loss: 0.7730 - val_accuracy: 0.5714\n",
      "Epoch 438/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7405 - accuracy: 0.6476 - val_loss: 0.7725 - val_accuracy: 0.5952\n",
      "Epoch 439/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7223 - accuracy: 0.6635 - val_loss: 0.7721 - val_accuracy: 0.5952\n",
      "Epoch 440/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7266 - accuracy: 0.6667 - val_loss: 0.7719 - val_accuracy: 0.5952\n",
      "Epoch 441/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7373 - accuracy: 0.6698 - val_loss: 0.7716 - val_accuracy: 0.5952\n",
      "Epoch 442/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7287 - accuracy: 0.6635 - val_loss: 0.7713 - val_accuracy: 0.5952\n",
      "Epoch 443/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7309 - accuracy: 0.6667 - val_loss: 0.7709 - val_accuracy: 0.5952\n",
      "Epoch 444/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7372 - accuracy: 0.6603 - val_loss: 0.7706 - val_accuracy: 0.5952\n",
      "Epoch 445/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7330 - accuracy: 0.6508 - val_loss: 0.7700 - val_accuracy: 0.5952\n",
      "Epoch 446/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7263 - accuracy: 0.6603 - val_loss: 0.7697 - val_accuracy: 0.5952\n",
      "Epoch 447/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7349 - accuracy: 0.6667 - val_loss: 0.7694 - val_accuracy: 0.5952\n",
      "Epoch 448/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7375 - accuracy: 0.6571 - val_loss: 0.7692 - val_accuracy: 0.5952\n",
      "Epoch 449/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7247 - accuracy: 0.6667 - val_loss: 0.7688 - val_accuracy: 0.5952\n",
      "Epoch 450/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7348 - accuracy: 0.6571 - val_loss: 0.7684 - val_accuracy: 0.5952\n",
      "Epoch 451/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7298 - accuracy: 0.6762 - val_loss: 0.7681 - val_accuracy: 0.5952\n",
      "Epoch 452/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7407 - accuracy: 0.6444 - val_loss: 0.7678 - val_accuracy: 0.5952\n",
      "Epoch 453/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7311 - accuracy: 0.6730 - val_loss: 0.7673 - val_accuracy: 0.5952\n",
      "Epoch 454/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7315 - accuracy: 0.6730 - val_loss: 0.7668 - val_accuracy: 0.5952\n",
      "Epoch 455/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7213 - accuracy: 0.6794 - val_loss: 0.7669 - val_accuracy: 0.5952\n",
      "Epoch 456/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7282 - accuracy: 0.6762 - val_loss: 0.7667 - val_accuracy: 0.5952\n",
      "Epoch 457/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7285 - accuracy: 0.6603 - val_loss: 0.7662 - val_accuracy: 0.5952\n",
      "Epoch 458/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7220 - accuracy: 0.6762 - val_loss: 0.7660 - val_accuracy: 0.5952\n",
      "Epoch 459/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7303 - accuracy: 0.6571 - val_loss: 0.7657 - val_accuracy: 0.5952\n",
      "Epoch 460/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7292 - accuracy: 0.6667 - val_loss: 0.7654 - val_accuracy: 0.5952\n",
      "Epoch 461/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7333 - accuracy: 0.6571 - val_loss: 0.7652 - val_accuracy: 0.5952\n",
      "Epoch 462/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7262 - accuracy: 0.6762 - val_loss: 0.7648 - val_accuracy: 0.5952\n",
      "Epoch 463/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7298 - accuracy: 0.6698 - val_loss: 0.7645 - val_accuracy: 0.5952\n",
      "Epoch 464/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7265 - accuracy: 0.6667 - val_loss: 0.7644 - val_accuracy: 0.5952\n",
      "Epoch 465/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7312 - accuracy: 0.6571 - val_loss: 0.7641 - val_accuracy: 0.5952\n",
      "Epoch 466/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7174 - accuracy: 0.6698 - val_loss: 0.7637 - val_accuracy: 0.5952\n",
      "Epoch 467/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7298 - accuracy: 0.6730 - val_loss: 0.7633 - val_accuracy: 0.5952\n",
      "Epoch 468/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7243 - accuracy: 0.6635 - val_loss: 0.7633 - val_accuracy: 0.5952\n",
      "Epoch 469/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7247 - accuracy: 0.6794 - val_loss: 0.7628 - val_accuracy: 0.5952\n",
      "Epoch 470/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7338 - accuracy: 0.6667 - val_loss: 0.7627 - val_accuracy: 0.5952\n",
      "Epoch 471/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7311 - accuracy: 0.6571 - val_loss: 0.7623 - val_accuracy: 0.5952\n",
      "Epoch 472/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7193 - accuracy: 0.6667 - val_loss: 0.7621 - val_accuracy: 0.5952\n",
      "Epoch 473/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7141 - accuracy: 0.6635 - val_loss: 0.7617 - val_accuracy: 0.5952\n",
      "Epoch 474/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7211 - accuracy: 0.6698 - val_loss: 0.7612 - val_accuracy: 0.5952\n",
      "Epoch 475/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7226 - accuracy: 0.6667 - val_loss: 0.7609 - val_accuracy: 0.5952\n",
      "Epoch 476/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7359 - accuracy: 0.6571 - val_loss: 0.7607 - val_accuracy: 0.5952\n",
      "Epoch 477/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7156 - accuracy: 0.6889 - val_loss: 0.7603 - val_accuracy: 0.5952\n",
      "Epoch 478/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7143 - accuracy: 0.6825 - val_loss: 0.7599 - val_accuracy: 0.5952\n",
      "Epoch 479/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7145 - accuracy: 0.6730 - val_loss: 0.7595 - val_accuracy: 0.5952\n",
      "Epoch 480/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7241 - accuracy: 0.6698 - val_loss: 0.7594 - val_accuracy: 0.5952\n",
      "Epoch 481/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7141 - accuracy: 0.6730 - val_loss: 0.7594 - val_accuracy: 0.5952\n",
      "Epoch 482/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7263 - accuracy: 0.6540 - val_loss: 0.7592 - val_accuracy: 0.5952\n",
      "Epoch 483/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7246 - accuracy: 0.6794 - val_loss: 0.7591 - val_accuracy: 0.5952\n",
      "Epoch 484/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7328 - accuracy: 0.6444 - val_loss: 0.7589 - val_accuracy: 0.5952\n",
      "Epoch 485/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7155 - accuracy: 0.6794 - val_loss: 0.7586 - val_accuracy: 0.5952\n",
      "Epoch 486/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7217 - accuracy: 0.6667 - val_loss: 0.7585 - val_accuracy: 0.5952\n",
      "Epoch 487/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7279 - accuracy: 0.6635 - val_loss: 0.7582 - val_accuracy: 0.5952\n",
      "Epoch 488/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7094 - accuracy: 0.6603 - val_loss: 0.7579 - val_accuracy: 0.5952\n",
      "Epoch 489/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7261 - accuracy: 0.6635 - val_loss: 0.7579 - val_accuracy: 0.5952\n",
      "Epoch 490/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7156 - accuracy: 0.6603 - val_loss: 0.7576 - val_accuracy: 0.5952\n",
      "Epoch 491/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7348 - accuracy: 0.6667 - val_loss: 0.7575 - val_accuracy: 0.5952\n",
      "Epoch 492/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7173 - accuracy: 0.6635 - val_loss: 0.7573 - val_accuracy: 0.5952\n",
      "Epoch 493/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7211 - accuracy: 0.6698 - val_loss: 0.7572 - val_accuracy: 0.5952\n",
      "Epoch 494/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7303 - accuracy: 0.6540 - val_loss: 0.7570 - val_accuracy: 0.5952\n",
      "Epoch 495/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7147 - accuracy: 0.6857 - val_loss: 0.7567 - val_accuracy: 0.5952\n",
      "Epoch 496/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7329 - accuracy: 0.6603 - val_loss: 0.7564 - val_accuracy: 0.5952\n",
      "Epoch 497/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7215 - accuracy: 0.6730 - val_loss: 0.7560 - val_accuracy: 0.5952\n",
      "Epoch 498/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7188 - accuracy: 0.6540 - val_loss: 0.7559 - val_accuracy: 0.5952\n",
      "Epoch 499/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7079 - accuracy: 0.6857 - val_loss: 0.7559 - val_accuracy: 0.5952\n",
      "Epoch 500/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7207 - accuracy: 0.6635 - val_loss: 0.7558 - val_accuracy: 0.5952\n",
      "\n",
      "\n",
      "Test loss: 0.7557585835456848\n",
      "Test accuracy: 0.5952380895614624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Building the RNN ##\n",
    "print()\n",
    "print(\"length of train data: \", len(train_x))\n",
    "print(\"length of validation data: \", len(validation_x))\n",
    "print()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(train_x.shape[1:]), activation='tanh', return_sequences=True))\n",
    "# model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(LSTM(64, activation='tanh'))\n",
    "# model.add(Dropout(0.3))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(64, activation='tanh'))\n",
    "# model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.000015, decay=1e-6)\n",
    "# opt = tf.keras.optimizers.Adam(learning_rate=0.0001, decay=1e-6)\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=opt,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_x, train_y,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(validation_x, validation_y)\n",
    ")\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "# Score model\n",
    "score = model.evaluate(validation_x, validation_y, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.7557585835456848\n",
      "Test accuracy: 0.5952380895614624\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(10,7))\n",
    "plt.xlabel('epoch')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_test_buys(tickers, SEQ_LEN, SHIFT):\n",
    "    Sequential_data = []\n",
    "    for ticker in tickers:\n",
    "        df = set_data(ticker)[-SHIFT:]\n",
    "\n",
    "        sequential_data = []  # this is a list that will CONTAIN the sequences\n",
    "        prev_days = deque(maxlen=SEQ_LEN)  # These will be our actual sequences. They are made with deque, which keeps the maximum length by popping out older values as new ones come in\n",
    "        \n",
    "        for i in df.values:  # iterate over the values\n",
    "            prev_days.append([n for n in i[:-2]])  # store all but the target\n",
    "            if len(prev_days) == SEQ_LEN:  # make sure we have 60 sequences!\n",
    "                sequential_data.append([np.array(prev_days), i[-2], i[-1]])  # append those bad boys!\n",
    "        \n",
    "        Sequential_data = Sequential_data + sequential_data\n",
    "        \n",
    "    X = []; y = []; z = []\n",
    "    for seq, target, actual in Sequential_data:  # going over our new sequential data\n",
    "        X.append(seq)  # X is the sequences\n",
    "        y.append(target)  # y is the targets/labels (buys vs sell/notbuy)\n",
    "        z.append(actual)\n",
    "\n",
    "    return np.array(X).astype(\"float64\"), np.array(y).astype(\"uint8\"), np.array(z).astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = set_data(ticker)\n",
    "\n",
    "sequential_data = []  # this is a list that will CONTAIN the sequences\n",
    "prev_days = deque(maxlen=SEQ_LEN)  # These will be our actual sequences. They are made with deque, which keeps the maximum length by popping out older values as new ones come in\n",
    "\n",
    "for i in df.values:  # iterate over the values\n",
    "    prev_days.append([n for n in i[:-2]])  # store all but the target\n",
    "    if len(prev_days) == SEQ_LEN:  # make sure we have 60 sequences!\n",
    "        sequential_data.append([np.array(prev_days), i[-2], i[-1]])  # append those bad boys!\n",
    "\n",
    "        \n",
    "buy = []; notbuy = []; maybe = []\n",
    "\n",
    "for seq, target, actual in sequential_data:  # iterate over the sequential data\n",
    "    if target == 0:\n",
    "        maybe.append([seq, target, actual])\n",
    "    elif target == 1:\n",
    "        notbuy.append([seq, target, actual]) \n",
    "    elif target == 2:\n",
    "        buy.append([seq, target, actual])  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_trading_days = 100\n",
    "test_x, test_y, test_z = process_test_buys(tickers_test, SEQ_LEN, last_trading_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []; total = 0\n",
    "for i, j in zip(output, test_z):\n",
    "    if np.argmax(i) == 2:\n",
    "        total += 1\n",
    "#         results.append([i,j])\n",
    "        results.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trading period: 2 percent, over 34 trades.\n",
      "Average daily return: 2 percent, over 34 trades.\n",
      "You started with $5000 and finished with $11174 after 34 trades.\n"
     ]
    }
   ],
   "source": [
    "print('Trading period: %d percent, over %d trades.' % (np.sum(results)/len(results), len(results)))\n",
    "print('Average daily return: %d percent, over %d trades.' % (np.sum(results)/len(results), len(results)))\n",
    "start = 5000\n",
    "finish = start\n",
    "for i in results:\n",
    "    finish = finish + (i/100) * finish\n",
    "    \n",
    "print('You started with $%d and finished with $%d after %d trades.' % (start, finish, len(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.4082912116520685, -0.772769021589037, 5.025056559514063, 5.726489588815231, 2.945719141125891, 8.35394753164409, -1.2505481437498966, 2.017374950722206, 0.6445998637189643, 4.458672335756675, 5.388521343106012, 4.3221755332707, 4.776841940851462, 4.736963722489929, 1.7171922475946566, 4.332835651170441, -0.9142991318043636, 1.9584132644258512, -2.2327137641667827, 6.005465774391272, 0.657241209325643, 4.243112701059504, 0.9386188953442121, 2.4476563509958416, 0.23331953432994545, -1.2791909238900834, -0.6247845791248041, -6.820156418592194, 6.840351822165136, -0.8734705143035981, 4.842526804934022, 8.627715496969547, 2.3957114324287376, 2.850358210053372]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []; total = 0\n",
    "for i, j in zip(output, test_z):\n",
    "    if i[2] > 0.6:\n",
    "        total += 1\n",
    "#         results.append([i,j])\n",
    "        results.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trading period: 5 percent, over 12 trades.\n",
      "Average daily return: 5 percent, over 12 trades.\n",
      "You started with $5000 and finished with $9015 after 12 trades.\n"
     ]
    }
   ],
   "source": [
    "print('Trading period: %d percent, over %d trades.' % (np.sum(results)/len(results), len(results)))\n",
    "print('Average daily return: %d percent, over %d trades.' % (np.sum(results)/len(results), len(results)))\n",
    "start = 5000\n",
    "finish = start\n",
    "for i in results:\n",
    "    finish = finish + (i/100) * finish\n",
    "    \n",
    "print('You started with $%d and finished with $%d after %d trades.' % (start, finish, len(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.025056559514063, 5.726489588815231, 2.945719141125891, 4.458672335756675, 5.388521343106012, 4.776841940851462, 4.736963722489929, 1.7171922475946566, 4.332835651170441, 6.005465774391272, 6.840351822165136, 8.627715496969547]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

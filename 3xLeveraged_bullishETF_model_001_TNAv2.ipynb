{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "import random\n",
    "from collections import deque\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, BatchNormalization, Flatten, Activation\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ModelCheckpoint\n",
    "import time\n",
    "import statistics\n",
    "from sklearn import preprocessing\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = \"TNA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDB(ticker):\n",
    "    tick = ticker\n",
    "    # Load data\n",
    "    data = yf.Ticker(tick)\n",
    "    df = data.history(period=\"5y\", interval=\"1d\")\n",
    "#     df = data.history(start=\"2018-12-01\", end=\"2020-03-01\")\n",
    "#     start=\"2017-01-01\", end=\"2017-04-30\"\n",
    "    \n",
    "    # add data points\n",
    "    df['close_per1'] = df.ta.percent_return(1)*100\n",
    "    df['sma10'] = df.ta.sma(length=10)\n",
    "    df['williams'] = df.ta.willr()\n",
    "\n",
    "\n",
    "    df = df[[\n",
    "            'open','close','sma10','williams','close_per1'\n",
    "            ]]\n",
    "\n",
    "    df = df.dropna()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.4499947493182095\n",
      "                 open      close      sma10   williams  close_per1\n",
      "date                                                              \n",
      "2017-01-23  48.812677  48.649506  49.949430 -85.270667   -1.135450\n",
      "2017-01-24  49.163742  50.775669  50.048322 -47.116216    4.370370\n",
      "2017-01-25  52.031586  52.328259  50.155619 -16.129040    3.057743\n",
      "2017-01-26  52.348029  51.715122  50.177868 -19.549857   -1.171712\n",
      "2017-01-27  51.764578  51.111897  50.261431 -32.036851   -1.166440\n",
      "                 open      close      sma10   williams  close_per1\n",
      "date                                                              \n",
      "2021-12-23  83.099998  84.199997  78.760229 -26.619072    2.395711\n",
      "2021-12-27  84.500000  86.599998  79.254777 -14.188268    2.850358\n",
      "2021-12-28  86.199997  85.029999  79.934092 -22.320079   -1.812933\n",
      "2021-12-29  84.889999  85.260002  80.845266 -17.004946    0.270497\n",
      "2021-12-30  85.180000  85.139999  81.375690 -17.658998   -0.140749\n"
     ]
    }
   ],
   "source": [
    "data = getDB(ticker)\n",
    "print(data['close_per1'].std())\n",
    "print(data.head(5))\n",
    "print(data.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_data(ticker):\n",
    "    df = getDB(ticker)\n",
    "\n",
    "    df['CP_ol'] = 0\n",
    "    df['CO_il'] = 0\n",
    "    df['SMA10_il'] = 0\n",
    "    df['W_il'] = 0\n",
    "    \n",
    "    value = df['close_per1'].std()\n",
    "    \n",
    "    # setting the outputs in the df\n",
    "    for i in range(len(df)):\n",
    "        if df.iloc[i]['close_per1'] > value:\n",
    "            df.iloc[i, df.columns.get_loc('CP_ol')] = 2\n",
    "        elif df.iloc[i]['close_per1'] < -value:\n",
    "            df.iloc[i, df.columns.get_loc('CP_ol')] = 1\n",
    "        else:\n",
    "            df.iloc[i, df.columns.get_loc('CP_ol')] = 0\n",
    "    \n",
    "    # setting the inputs in the df\n",
    "    for i in range(len(df)-1):\n",
    "        try:\n",
    "            if df.iloc[i]['close'] < df.iloc[i+1]['open']:\n",
    "                df.iloc[i+1, df.columns.get_loc('CO_il')] = 1\n",
    "            else:\n",
    "                df.iloc[i+1, df.columns.get_loc('CO_il')] = 0\n",
    "        except:\n",
    "            df.iloc[i+1, df.columns.get_loc('CO_il')] = np.nan\n",
    "            \n",
    "    \n",
    "    # setting the inputs in the df\n",
    "    for i in range(len(df)):\n",
    "        try:\n",
    "            if df.iloc[i]['close'] > df.iloc[i]['sma10']:\n",
    "                df.iloc[i, df.columns.get_loc('SMA10_il')] = 1\n",
    "            else:\n",
    "                df.iloc[i, df.columns.get_loc('SMA10_il')] = 0\n",
    "        except:\n",
    "            df.iloc[i, df.columns.get_loc('SMA10_il')] = np.nan\n",
    "            \n",
    "    \n",
    "    # setting the inputs in the df\n",
    "    for i in range(len(df)):\n",
    "        if df.iloc[i]['williams'] > -30: # overbought\n",
    "            df.iloc[i, df.columns.get_loc('W_il')] = -1\n",
    "        elif df.iloc[i]['williams'] < -70: # oversold\n",
    "            df.iloc[i, df.columns.get_loc('W_il')] = 1\n",
    "        else:\n",
    "            df.iloc[i, df.columns.get_loc('W_il')] = 0 # neutral\n",
    "    \n",
    "    \n",
    "    # deleting data that is not normalized\n",
    "    del df['open']\n",
    "    del df['close']\n",
    "    del df['sma10']\n",
    "    del df['williams']\n",
    "#     del df['close_per1']\n",
    "    \n",
    "    # reformating\n",
    "    df = df[[\n",
    "            'W_il','SMA10_il','CO_il','CP_ol','close_per1'\n",
    "            ]]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 open      close      sma10   williams  close_per1\n",
      "date                                                              \n",
      "2017-01-23  48.812677  48.649506  49.949430 -85.270657   -1.135450\n",
      "2017-01-24  49.163742  50.775669  50.048321 -47.116180    4.370370\n",
      "2017-01-25  52.031578  52.328251  50.155617 -16.129058    3.057728\n",
      "2017-01-26  52.348029  51.715122  50.177867 -19.549730   -1.171697\n",
      "2017-01-27  51.764578  51.111897  50.261431 -32.036743   -1.166440\n",
      "                 open      close      sma10   williams  close_per1\n",
      "date                                                              \n",
      "2021-12-23  83.099998  84.199997  78.760229 -26.619072    2.395711\n",
      "2021-12-27  84.500000  86.599998  79.254777 -14.188268    2.850358\n",
      "2021-12-28  86.199997  85.029999  79.934092 -22.320079   -1.812933\n",
      "2021-12-29  84.889999  85.260002  80.845266 -17.004946    0.270497\n",
      "2021-12-30  85.180000  85.139999  81.375690 -17.658998   -0.140749\n"
     ]
    }
   ],
   "source": [
    "df = set_data(ticker)\n",
    "print(data.head(5))\n",
    "print(data.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_train(tickers, SEQ_LEN, SHIFT):\n",
    "    Sequential_data = []\n",
    "    for ticker in tickers:\n",
    "        df = set_data(ticker)[0:-SHIFT]\n",
    "        \n",
    "        del df['close_per1']\n",
    "        \n",
    "        df.head()\n",
    "\n",
    "        sequential_data = []  # this is a list that will CONTAIN the sequences\n",
    "        prev_days = deque(maxlen=SEQ_LEN)  # These will be our actual sequences. They are made with deque, which keeps the maximum length by popping out older values as new ones come in\n",
    "        \n",
    "        for i in df.values:  # iterate over the values\n",
    "            prev_days.append([n for n in i[:-1]])  # store all but the target\n",
    "            if len(prev_days) == SEQ_LEN:  # make sure we have 60 sequences!\n",
    "                sequential_data.append([np.array(prev_days), i[-1]])  # append those bad boys!\n",
    "        \n",
    "        \n",
    "        random.shuffle(sequential_data)  # shuffle for good measure.\n",
    "        \n",
    "        buy = []; notbuy = []; maybe = []\n",
    "        \n",
    "        for seq, target in sequential_data:  # iterate over the sequential data\n",
    "            if target == 0:\n",
    "                maybe.append([seq, target])\n",
    "            elif target == 1:\n",
    "                notbuy.append([seq, target]) \n",
    "            elif target == 2:\n",
    "                buy.append([seq, target])  \n",
    "        \n",
    "        # suffle data\n",
    "        random.shuffle(buy)\n",
    "        random.shuffle(notbuy)\n",
    "        random.shuffle(maybe)\n",
    "        \n",
    "        lower = min(len(buy), len(notbuy), len(maybe))  # what's the shorter length?\n",
    "        \n",
    "        # make sure lists are only up to the shortest length.\n",
    "        buy = buy[:lower]  \n",
    "        notbuy = notbuy[:lower]\n",
    "        maybe = maybe[:lower]\n",
    "        \n",
    "        sequential_data = buy+notbuy+maybe # add them together\n",
    "        random.shuffle(sequential_data)  # another shuffle, so the model doesn't get confused with all 1 class then the other.\n",
    "    \n",
    "        Sequential_data = Sequential_data + sequential_data\n",
    "        \n",
    "    random.shuffle(Sequential_data)\n",
    "    X = []; y = []\n",
    "    for seq, target in Sequential_data:  # going over our new sequential data\n",
    "        X.append(seq)  # X is the sequences\n",
    "        y.append(target)  # y is the targets/labels (buys vs sell/notbuy)\n",
    "\n",
    "    return np.array(X).astype(\"float64\"), np.array(y).astype(\"uint8\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_test(tickers, SEQ_LEN, SHIFT):\n",
    "    Sequential_data = []\n",
    "    for ticker in tickers:\n",
    "        df = set_data(ticker)[-SHIFT:]\n",
    "        \n",
    "        del df['close_per1']\n",
    "\n",
    "        sequential_data = []  # this is a list that will CONTAIN the sequences\n",
    "        prev_days = deque(maxlen=SEQ_LEN)  # These will be our actual sequences. They are made with deque, which keeps the maximum length by popping out older values as new ones come in\n",
    "        \n",
    "        for i in df.values:  # iterate over the values\n",
    "            prev_days.append([n for n in i[:-1]])  # store all but the target\n",
    "            if len(prev_days) == SEQ_LEN:  # make sure we have 60 sequences!\n",
    "                sequential_data.append([np.array(prev_days), i[-1]])  # append those bad boys!\n",
    "        \n",
    "        \n",
    "        random.shuffle(sequential_data)  # shuffle for good measure.\n",
    "        \n",
    "        buy = []; notbuy = []; maybe = []\n",
    "        \n",
    "        for seq, target in sequential_data:  # iterate over the sequential data\n",
    "            if target == 0:\n",
    "                maybe.append([seq, target])\n",
    "            elif target == 1:\n",
    "                notbuy.append([seq, target]) \n",
    "            elif target == 2:\n",
    "                buy.append([seq, target])  \n",
    "        \n",
    "        # suffle data\n",
    "        random.shuffle(buy)\n",
    "        random.shuffle(notbuy)\n",
    "        random.shuffle(maybe)\n",
    "        \n",
    "        lower = min(len(buy), len(notbuy), len(maybe))  # what's the shorter length?\n",
    "        \n",
    "        # make sure lists are only up to the shortest length.\n",
    "        buy = buy[:lower]  \n",
    "        notbuy = notbuy[:lower]\n",
    "        maybe = maybe[:lower]\n",
    "        \n",
    "        sequential_data = buy+notbuy+maybe # add them together\n",
    "        random.shuffle(sequential_data)  # another shuffle, so the model doesn't get confused with all 1 class then the other.\n",
    "    \n",
    "        Sequential_data = Sequential_data + sequential_data\n",
    "        \n",
    "    random.shuffle(Sequential_data)\n",
    "    X = []; y = []\n",
    "    for seq, target in Sequential_data:  # going over our new sequential data\n",
    "        X.append(seq)  # X is the sequences\n",
    "        y.append(target)  # y is the targets/labels (buys vs sell/notbuy)\n",
    "\n",
    "    return np.array(X).astype(\"float64\"), np.array(y).astype(\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 2  # how long of a preceeding sequence to collect for RNN\n",
    "# FUTURE_PERIOD_PREDICT = 3  # how far into the future are we trying to predict?\n",
    "SHIFT = 150  # how far to shift the data so it can be back testest\n",
    "BATCH_SIZE = 64 # how many batches? Try smaller batch if you're getting OOM (out of memory) errors.\n",
    "EPOCHS = 500 # how many passes through our data\n",
    "\n",
    "\n",
    "tickers_train = [ticker]\n",
    "tickers_test = [ticker]\n",
    "\n",
    "train_x, train_y = process_train(tickers_train, SEQ_LEN,SHIFT)\n",
    "validation_x, validation_y = process_test(tickers_test, SEQ_LEN, SHIFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.  1.  0.]\n",
      " [-1.  1.  1.]]\n",
      "training data length: 315\n",
      "validation data length: 42\n"
     ]
    }
   ],
   "source": [
    "print(train_x[0])\n",
    "print('training data length: %d' % (len(train_x)))\n",
    "print('validation data length: %d' % (len(validation_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "length of train data:  315\n",
      "length of validation data:  42\n",
      "\n",
      "Epoch 1/500\n",
      "5/5 [==============================] - 3s 164ms/step - loss: 1.7422 - accuracy: 0.2667 - val_loss: 1.0995 - val_accuracy: 0.3333\n",
      "Epoch 2/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.7181 - accuracy: 0.2603 - val_loss: 1.0995 - val_accuracy: 0.3333\n",
      "Epoch 3/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.6858 - accuracy: 0.2762 - val_loss: 1.0995 - val_accuracy: 0.3333\n",
      "Epoch 4/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.6455 - accuracy: 0.2984 - val_loss: 1.0995 - val_accuracy: 0.3095\n",
      "Epoch 5/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.6360 - accuracy: 0.2762 - val_loss: 1.0995 - val_accuracy: 0.2619\n",
      "Epoch 6/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.6273 - accuracy: 0.2730 - val_loss: 1.0995 - val_accuracy: 0.2857\n",
      "Epoch 7/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.5977 - accuracy: 0.2762 - val_loss: 1.0994 - val_accuracy: 0.2857\n",
      "Epoch 8/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.5762 - accuracy: 0.2762 - val_loss: 1.0994 - val_accuracy: 0.3095\n",
      "Epoch 9/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.5419 - accuracy: 0.2762 - val_loss: 1.0994 - val_accuracy: 0.3095\n",
      "Epoch 10/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.5354 - accuracy: 0.3175 - val_loss: 1.0994 - val_accuracy: 0.3095\n",
      "Epoch 11/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.5236 - accuracy: 0.2698 - val_loss: 1.0993 - val_accuracy: 0.3095\n",
      "Epoch 12/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.4858 - accuracy: 0.2984 - val_loss: 1.0993 - val_accuracy: 0.2381\n",
      "Epoch 13/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.4734 - accuracy: 0.2794 - val_loss: 1.0993 - val_accuracy: 0.1905\n",
      "Epoch 14/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.4625 - accuracy: 0.2698 - val_loss: 1.0992 - val_accuracy: 0.1905\n",
      "Epoch 15/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.4455 - accuracy: 0.2825 - val_loss: 1.0992 - val_accuracy: 0.1905\n",
      "Epoch 16/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.4168 - accuracy: 0.3048 - val_loss: 1.0992 - val_accuracy: 0.1905\n",
      "Epoch 17/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.4161 - accuracy: 0.3175 - val_loss: 1.0991 - val_accuracy: 0.1905\n",
      "Epoch 18/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.3919 - accuracy: 0.3079 - val_loss: 1.0990 - val_accuracy: 0.1905\n",
      "Epoch 19/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.3670 - accuracy: 0.3143 - val_loss: 1.0990 - val_accuracy: 0.1667\n",
      "Epoch 20/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.3515 - accuracy: 0.3270 - val_loss: 1.0989 - val_accuracy: 0.1667\n",
      "Epoch 21/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.3600 - accuracy: 0.3143 - val_loss: 1.0989 - val_accuracy: 0.1667\n",
      "Epoch 22/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.3280 - accuracy: 0.3206 - val_loss: 1.0988 - val_accuracy: 0.2619\n",
      "Epoch 23/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.3114 - accuracy: 0.3397 - val_loss: 1.0987 - val_accuracy: 0.2619\n",
      "Epoch 24/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.3040 - accuracy: 0.3238 - val_loss: 1.0986 - val_accuracy: 0.2619\n",
      "Epoch 25/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.2914 - accuracy: 0.3333 - val_loss: 1.0985 - val_accuracy: 0.2857\n",
      "Epoch 26/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.2802 - accuracy: 0.3365 - val_loss: 1.0984 - val_accuracy: 0.3333\n",
      "Epoch 27/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.2612 - accuracy: 0.3429 - val_loss: 1.0983 - val_accuracy: 0.3333\n",
      "Epoch 28/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.2500 - accuracy: 0.3333 - val_loss: 1.0981 - val_accuracy: 0.3810\n",
      "Epoch 29/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.2449 - accuracy: 0.3429 - val_loss: 1.0980 - val_accuracy: 0.3810\n",
      "Epoch 30/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.2299 - accuracy: 0.3587 - val_loss: 1.0978 - val_accuracy: 0.3810\n",
      "Epoch 31/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.2158 - accuracy: 0.3492 - val_loss: 1.0977 - val_accuracy: 0.3810\n",
      "Epoch 32/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.2100 - accuracy: 0.3651 - val_loss: 1.0975 - val_accuracy: 0.3810\n",
      "Epoch 33/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.1995 - accuracy: 0.3587 - val_loss: 1.0973 - val_accuracy: 0.3810\n",
      "Epoch 34/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.1930 - accuracy: 0.3619 - val_loss: 1.0971 - val_accuracy: 0.4048\n",
      "Epoch 35/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.1800 - accuracy: 0.3714 - val_loss: 1.0969 - val_accuracy: 0.4286\n",
      "Epoch 36/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.1737 - accuracy: 0.3778 - val_loss: 1.0966 - val_accuracy: 0.4286\n",
      "Epoch 37/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.1545 - accuracy: 0.4032 - val_loss: 1.0963 - val_accuracy: 0.4286\n",
      "Epoch 38/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.1534 - accuracy: 0.4032 - val_loss: 1.0961 - val_accuracy: 0.4048\n",
      "Epoch 39/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.1416 - accuracy: 0.4222 - val_loss: 1.0958 - val_accuracy: 0.4048\n",
      "Epoch 40/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.1332 - accuracy: 0.4286 - val_loss: 1.0955 - val_accuracy: 0.4048\n",
      "Epoch 41/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.1211 - accuracy: 0.4286 - val_loss: 1.0951 - val_accuracy: 0.4048\n",
      "Epoch 42/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.1210 - accuracy: 0.4444 - val_loss: 1.0948 - val_accuracy: 0.4048\n",
      "Epoch 43/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.1140 - accuracy: 0.4381 - val_loss: 1.0944 - val_accuracy: 0.4048\n",
      "Epoch 44/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.1085 - accuracy: 0.4413 - val_loss: 1.0940 - val_accuracy: 0.4048\n",
      "Epoch 45/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.1006 - accuracy: 0.4413 - val_loss: 1.0936 - val_accuracy: 0.4048\n",
      "Epoch 46/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0981 - accuracy: 0.4317 - val_loss: 1.0931 - val_accuracy: 0.4048\n",
      "Epoch 47/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0902 - accuracy: 0.4349 - val_loss: 1.0926 - val_accuracy: 0.4048\n",
      "Epoch 48/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0896 - accuracy: 0.4317 - val_loss: 1.0921 - val_accuracy: 0.4286\n",
      "Epoch 49/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0738 - accuracy: 0.4444 - val_loss: 1.0916 - val_accuracy: 0.4286\n",
      "Epoch 50/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0717 - accuracy: 0.4413 - val_loss: 1.0910 - val_accuracy: 0.4286\n",
      "Epoch 51/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0679 - accuracy: 0.4413 - val_loss: 1.0903 - val_accuracy: 0.4286\n",
      "Epoch 52/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0628 - accuracy: 0.4635 - val_loss: 1.0897 - val_accuracy: 0.4286\n",
      "Epoch 53/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0589 - accuracy: 0.4603 - val_loss: 1.0891 - val_accuracy: 0.4286\n",
      "Epoch 54/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0509 - accuracy: 0.4571 - val_loss: 1.0884 - val_accuracy: 0.4286\n",
      "Epoch 55/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0489 - accuracy: 0.4730 - val_loss: 1.0877 - val_accuracy: 0.4286\n",
      "Epoch 56/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0385 - accuracy: 0.4667 - val_loss: 1.0869 - val_accuracy: 0.4286\n",
      "Epoch 57/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0358 - accuracy: 0.4762 - val_loss: 1.0862 - val_accuracy: 0.4286\n",
      "Epoch 58/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0295 - accuracy: 0.4698 - val_loss: 1.0853 - val_accuracy: 0.4286\n",
      "Epoch 59/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0188 - accuracy: 0.4698 - val_loss: 1.0844 - val_accuracy: 0.4286\n",
      "Epoch 60/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0218 - accuracy: 0.4921 - val_loss: 1.0835 - val_accuracy: 0.4524\n",
      "Epoch 61/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0255 - accuracy: 0.4730 - val_loss: 1.0824 - val_accuracy: 0.4524\n",
      "Epoch 62/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0206 - accuracy: 0.4825 - val_loss: 1.0814 - val_accuracy: 0.4524\n",
      "Epoch 63/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0152 - accuracy: 0.4984 - val_loss: 1.0802 - val_accuracy: 0.4524\n",
      "Epoch 64/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0093 - accuracy: 0.4857 - val_loss: 1.0791 - val_accuracy: 0.4524\n",
      "Epoch 65/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0114 - accuracy: 0.4635 - val_loss: 1.0780 - val_accuracy: 0.4524\n",
      "Epoch 66/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0086 - accuracy: 0.4889 - val_loss: 1.0768 - val_accuracy: 0.4524\n",
      "Epoch 67/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9998 - accuracy: 0.4889 - val_loss: 1.0755 - val_accuracy: 0.4524\n",
      "Epoch 68/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9984 - accuracy: 0.4889 - val_loss: 1.0743 - val_accuracy: 0.4524\n",
      "Epoch 69/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9916 - accuracy: 0.5016 - val_loss: 1.0729 - val_accuracy: 0.4524\n",
      "Epoch 70/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9952 - accuracy: 0.5048 - val_loss: 1.0715 - val_accuracy: 0.4524\n",
      "Epoch 71/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9779 - accuracy: 0.5302 - val_loss: 1.0701 - val_accuracy: 0.4524\n",
      "Epoch 72/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9850 - accuracy: 0.5143 - val_loss: 1.0686 - val_accuracy: 0.4524\n",
      "Epoch 73/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9816 - accuracy: 0.5206 - val_loss: 1.0670 - val_accuracy: 0.4524\n",
      "Epoch 74/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9809 - accuracy: 0.5016 - val_loss: 1.0655 - val_accuracy: 0.4524\n",
      "Epoch 75/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9796 - accuracy: 0.5048 - val_loss: 1.0638 - val_accuracy: 0.4524\n",
      "Epoch 76/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9824 - accuracy: 0.5048 - val_loss: 1.0621 - val_accuracy: 0.4524\n",
      "Epoch 77/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9714 - accuracy: 0.5111 - val_loss: 1.0602 - val_accuracy: 0.4524\n",
      "Epoch 78/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9782 - accuracy: 0.5143 - val_loss: 1.0584 - val_accuracy: 0.4524\n",
      "Epoch 79/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9711 - accuracy: 0.5111 - val_loss: 1.0564 - val_accuracy: 0.4524\n",
      "Epoch 80/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9701 - accuracy: 0.5111 - val_loss: 1.0545 - val_accuracy: 0.4524\n",
      "Epoch 81/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9657 - accuracy: 0.5175 - val_loss: 1.0525 - val_accuracy: 0.5238\n",
      "Epoch 82/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9601 - accuracy: 0.5143 - val_loss: 1.0505 - val_accuracy: 0.5238\n",
      "Epoch 83/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9606 - accuracy: 0.5270 - val_loss: 1.0483 - val_accuracy: 0.5238\n",
      "Epoch 84/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9640 - accuracy: 0.5111 - val_loss: 1.0460 - val_accuracy: 0.5238\n",
      "Epoch 85/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9555 - accuracy: 0.5206 - val_loss: 1.0438 - val_accuracy: 0.5238\n",
      "Epoch 86/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9495 - accuracy: 0.5492 - val_loss: 1.0415 - val_accuracy: 0.5238\n",
      "Epoch 87/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9611 - accuracy: 0.5238 - val_loss: 1.0392 - val_accuracy: 0.5238\n",
      "Epoch 88/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9510 - accuracy: 0.5365 - val_loss: 1.0368 - val_accuracy: 0.5476\n",
      "Epoch 89/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9534 - accuracy: 0.5365 - val_loss: 1.0343 - val_accuracy: 0.5476\n",
      "Epoch 90/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9498 - accuracy: 0.5429 - val_loss: 1.0318 - val_accuracy: 0.5476\n",
      "Epoch 91/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9534 - accuracy: 0.5333 - val_loss: 1.0291 - val_accuracy: 0.5476\n",
      "Epoch 92/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9445 - accuracy: 0.5556 - val_loss: 1.0264 - val_accuracy: 0.5476\n",
      "Epoch 93/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9435 - accuracy: 0.5556 - val_loss: 1.0238 - val_accuracy: 0.5476\n",
      "Epoch 94/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9480 - accuracy: 0.5524 - val_loss: 1.0210 - val_accuracy: 0.5952\n",
      "Epoch 95/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9431 - accuracy: 0.5365 - val_loss: 1.0182 - val_accuracy: 0.5952\n",
      "Epoch 96/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9383 - accuracy: 0.5524 - val_loss: 1.0153 - val_accuracy: 0.6190\n",
      "Epoch 97/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9426 - accuracy: 0.5746 - val_loss: 1.0125 - val_accuracy: 0.6190\n",
      "Epoch 98/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9397 - accuracy: 0.5683 - val_loss: 1.0097 - val_accuracy: 0.6190\n",
      "Epoch 99/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9372 - accuracy: 0.5651 - val_loss: 1.0067 - val_accuracy: 0.6190\n",
      "Epoch 100/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9385 - accuracy: 0.5683 - val_loss: 1.0038 - val_accuracy: 0.6190\n",
      "Epoch 101/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9386 - accuracy: 0.5524 - val_loss: 1.0008 - val_accuracy: 0.6190\n",
      "Epoch 102/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9372 - accuracy: 0.5651 - val_loss: 0.9978 - val_accuracy: 0.6190\n",
      "Epoch 103/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9340 - accuracy: 0.5746 - val_loss: 0.9949 - val_accuracy: 0.6190\n",
      "Epoch 104/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9331 - accuracy: 0.5714 - val_loss: 0.9917 - val_accuracy: 0.6667\n",
      "Epoch 105/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9254 - accuracy: 0.5778 - val_loss: 0.9887 - val_accuracy: 0.6667\n",
      "Epoch 106/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9269 - accuracy: 0.5746 - val_loss: 0.9856 - val_accuracy: 0.6190\n",
      "Epoch 107/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9305 - accuracy: 0.5556 - val_loss: 0.9826 - val_accuracy: 0.6190\n",
      "Epoch 108/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9273 - accuracy: 0.5810 - val_loss: 0.9793 - val_accuracy: 0.6429\n",
      "Epoch 109/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9268 - accuracy: 0.5841 - val_loss: 0.9761 - val_accuracy: 0.6429\n",
      "Epoch 110/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9267 - accuracy: 0.5746 - val_loss: 0.9730 - val_accuracy: 0.6429\n",
      "Epoch 111/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9269 - accuracy: 0.5873 - val_loss: 0.9698 - val_accuracy: 0.6429\n",
      "Epoch 112/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9284 - accuracy: 0.5778 - val_loss: 0.9667 - val_accuracy: 0.6429\n",
      "Epoch 113/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9204 - accuracy: 0.5937 - val_loss: 0.9636 - val_accuracy: 0.6667\n",
      "Epoch 114/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9179 - accuracy: 0.5873 - val_loss: 0.9603 - val_accuracy: 0.6667\n",
      "Epoch 115/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9179 - accuracy: 0.5714 - val_loss: 0.9571 - val_accuracy: 0.6667\n",
      "Epoch 116/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9212 - accuracy: 0.5873 - val_loss: 0.9537 - val_accuracy: 0.6905\n",
      "Epoch 117/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9222 - accuracy: 0.5778 - val_loss: 0.9505 - val_accuracy: 0.6905\n",
      "Epoch 118/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9204 - accuracy: 0.5746 - val_loss: 0.9473 - val_accuracy: 0.6905\n",
      "Epoch 119/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.9052 - accuracy: 0.6000 - val_loss: 0.9442 - val_accuracy: 0.6905\n",
      "Epoch 120/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.9112 - accuracy: 0.5810 - val_loss: 0.9408 - val_accuracy: 0.6905\n",
      "Epoch 121/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.9146 - accuracy: 0.5810 - val_loss: 0.9376 - val_accuracy: 0.6905\n",
      "Epoch 122/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.9113 - accuracy: 0.5746 - val_loss: 0.9344 - val_accuracy: 0.6905\n",
      "Epoch 123/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.9084 - accuracy: 0.5905 - val_loss: 0.9313 - val_accuracy: 0.6905\n",
      "Epoch 124/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.9085 - accuracy: 0.5905 - val_loss: 0.9282 - val_accuracy: 0.6905\n",
      "Epoch 125/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.9089 - accuracy: 0.5873 - val_loss: 0.9251 - val_accuracy: 0.6905\n",
      "Epoch 126/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.9042 - accuracy: 0.6159 - val_loss: 0.9220 - val_accuracy: 0.6905\n",
      "Epoch 127/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.9079 - accuracy: 0.5937 - val_loss: 0.9188 - val_accuracy: 0.6905\n",
      "Epoch 128/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9056 - accuracy: 0.5905 - val_loss: 0.9158 - val_accuracy: 0.6905\n",
      "Epoch 129/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9023 - accuracy: 0.5810 - val_loss: 0.9127 - val_accuracy: 0.6905\n",
      "Epoch 130/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.9024 - accuracy: 0.5905 - val_loss: 0.9097 - val_accuracy: 0.7619\n",
      "Epoch 131/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.9057 - accuracy: 0.5651 - val_loss: 0.9068 - val_accuracy: 0.7619\n",
      "Epoch 132/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.9014 - accuracy: 0.5968 - val_loss: 0.9038 - val_accuracy: 0.7619\n",
      "Epoch 133/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8972 - accuracy: 0.6032 - val_loss: 0.9008 - val_accuracy: 0.7619\n",
      "Epoch 134/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.8992 - accuracy: 0.5905 - val_loss: 0.8981 - val_accuracy: 0.7619\n",
      "Epoch 135/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8985 - accuracy: 0.5937 - val_loss: 0.8954 - val_accuracy: 0.7619\n",
      "Epoch 136/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.8948 - accuracy: 0.6000 - val_loss: 0.8925 - val_accuracy: 0.7619\n",
      "Epoch 137/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8978 - accuracy: 0.5937 - val_loss: 0.8900 - val_accuracy: 0.7619\n",
      "Epoch 138/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8928 - accuracy: 0.6032 - val_loss: 0.8873 - val_accuracy: 0.7619\n",
      "Epoch 139/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8943 - accuracy: 0.6032 - val_loss: 0.8846 - val_accuracy: 0.7619\n",
      "Epoch 140/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8998 - accuracy: 0.5778 - val_loss: 0.8821 - val_accuracy: 0.7619\n",
      "Epoch 141/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8935 - accuracy: 0.6127 - val_loss: 0.8795 - val_accuracy: 0.7619\n",
      "Epoch 142/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8935 - accuracy: 0.5968 - val_loss: 0.8770 - val_accuracy: 0.7619\n",
      "Epoch 143/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8886 - accuracy: 0.6159 - val_loss: 0.8746 - val_accuracy: 0.7619\n",
      "Epoch 144/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8912 - accuracy: 0.6095 - val_loss: 0.8720 - val_accuracy: 0.7619\n",
      "Epoch 145/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8901 - accuracy: 0.6095 - val_loss: 0.8699 - val_accuracy: 0.7619\n",
      "Epoch 146/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8897 - accuracy: 0.5937 - val_loss: 0.8677 - val_accuracy: 0.7619\n",
      "Epoch 147/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8930 - accuracy: 0.6127 - val_loss: 0.8654 - val_accuracy: 0.7619\n",
      "Epoch 148/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8879 - accuracy: 0.6063 - val_loss: 0.8633 - val_accuracy: 0.7381\n",
      "Epoch 149/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8810 - accuracy: 0.6222 - val_loss: 0.8613 - val_accuracy: 0.7381\n",
      "Epoch 150/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8848 - accuracy: 0.6063 - val_loss: 0.8591 - val_accuracy: 0.7381\n",
      "Epoch 151/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8824 - accuracy: 0.6159 - val_loss: 0.8570 - val_accuracy: 0.7381\n",
      "Epoch 152/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8840 - accuracy: 0.6127 - val_loss: 0.8551 - val_accuracy: 0.7381\n",
      "Epoch 153/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8841 - accuracy: 0.5873 - val_loss: 0.8531 - val_accuracy: 0.7381\n",
      "Epoch 154/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8819 - accuracy: 0.6032 - val_loss: 0.8511 - val_accuracy: 0.7381\n",
      "Epoch 155/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8806 - accuracy: 0.6159 - val_loss: 0.8490 - val_accuracy: 0.7381\n",
      "Epoch 156/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8823 - accuracy: 0.6000 - val_loss: 0.8470 - val_accuracy: 0.7381\n",
      "Epoch 157/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8822 - accuracy: 0.6000 - val_loss: 0.8453 - val_accuracy: 0.7381\n",
      "Epoch 158/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.8847 - accuracy: 0.5937 - val_loss: 0.8433 - val_accuracy: 0.7381\n",
      "Epoch 159/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8793 - accuracy: 0.6159 - val_loss: 0.8417 - val_accuracy: 0.7381\n",
      "Epoch 160/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8722 - accuracy: 0.6222 - val_loss: 0.8400 - val_accuracy: 0.7381\n",
      "Epoch 161/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8755 - accuracy: 0.6127 - val_loss: 0.8383 - val_accuracy: 0.7381\n",
      "Epoch 162/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8784 - accuracy: 0.6286 - val_loss: 0.8365 - val_accuracy: 0.6905\n",
      "Epoch 163/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8749 - accuracy: 0.6190 - val_loss: 0.8347 - val_accuracy: 0.6905\n",
      "Epoch 164/500\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.8807 - accuracy: 0.5905 - val_loss: 0.8333 - val_accuracy: 0.6905\n",
      "Epoch 165/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.8694 - accuracy: 0.5968 - val_loss: 0.8319 - val_accuracy: 0.6905\n",
      "Epoch 166/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8728 - accuracy: 0.6127 - val_loss: 0.8301 - val_accuracy: 0.6905\n",
      "Epoch 167/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8656 - accuracy: 0.6095 - val_loss: 0.8287 - val_accuracy: 0.6905\n",
      "Epoch 168/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.8685 - accuracy: 0.6159 - val_loss: 0.8271 - val_accuracy: 0.6905\n",
      "Epoch 169/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8764 - accuracy: 0.6127 - val_loss: 0.8255 - val_accuracy: 0.6905\n",
      "Epoch 170/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8713 - accuracy: 0.5937 - val_loss: 0.8240 - val_accuracy: 0.6905\n",
      "Epoch 171/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8653 - accuracy: 0.6349 - val_loss: 0.8227 - val_accuracy: 0.6905\n",
      "Epoch 172/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8681 - accuracy: 0.6190 - val_loss: 0.8211 - val_accuracy: 0.6905\n",
      "Epoch 173/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8662 - accuracy: 0.6190 - val_loss: 0.8198 - val_accuracy: 0.6905\n",
      "Epoch 174/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8701 - accuracy: 0.6032 - val_loss: 0.8184 - val_accuracy: 0.6905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8627 - accuracy: 0.6127 - val_loss: 0.8172 - val_accuracy: 0.6905\n",
      "Epoch 176/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8609 - accuracy: 0.6159 - val_loss: 0.8158 - val_accuracy: 0.6905\n",
      "Epoch 177/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.8588 - accuracy: 0.6286 - val_loss: 0.8146 - val_accuracy: 0.6905\n",
      "Epoch 178/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8627 - accuracy: 0.6190 - val_loss: 0.8131 - val_accuracy: 0.6905\n",
      "Epoch 179/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8658 - accuracy: 0.6127 - val_loss: 0.8119 - val_accuracy: 0.6905\n",
      "Epoch 180/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8583 - accuracy: 0.6127 - val_loss: 0.8106 - val_accuracy: 0.6905\n",
      "Epoch 181/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8545 - accuracy: 0.6222 - val_loss: 0.8094 - val_accuracy: 0.6905\n",
      "Epoch 182/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8626 - accuracy: 0.6317 - val_loss: 0.8083 - val_accuracy: 0.6905\n",
      "Epoch 183/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8572 - accuracy: 0.6222 - val_loss: 0.8072 - val_accuracy: 0.6905\n",
      "Epoch 184/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8546 - accuracy: 0.6095 - val_loss: 0.8061 - val_accuracy: 0.6905\n",
      "Epoch 185/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8513 - accuracy: 0.6286 - val_loss: 0.8050 - val_accuracy: 0.6905\n",
      "Epoch 186/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8558 - accuracy: 0.6095 - val_loss: 0.8041 - val_accuracy: 0.6905\n",
      "Epoch 187/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8549 - accuracy: 0.6254 - val_loss: 0.8029 - val_accuracy: 0.6905\n",
      "Epoch 188/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8481 - accuracy: 0.6222 - val_loss: 0.8018 - val_accuracy: 0.6905\n",
      "Epoch 189/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8559 - accuracy: 0.6159 - val_loss: 0.8008 - val_accuracy: 0.6905\n",
      "Epoch 190/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8526 - accuracy: 0.6349 - val_loss: 0.7999 - val_accuracy: 0.6905\n",
      "Epoch 191/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8520 - accuracy: 0.6381 - val_loss: 0.7990 - val_accuracy: 0.6905\n",
      "Epoch 192/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.8511 - accuracy: 0.6317 - val_loss: 0.7981 - val_accuracy: 0.6905\n",
      "Epoch 193/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8443 - accuracy: 0.6349 - val_loss: 0.7970 - val_accuracy: 0.6905\n",
      "Epoch 194/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8435 - accuracy: 0.6317 - val_loss: 0.7959 - val_accuracy: 0.6905\n",
      "Epoch 195/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8457 - accuracy: 0.6349 - val_loss: 0.7949 - val_accuracy: 0.6905\n",
      "Epoch 196/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8422 - accuracy: 0.6190 - val_loss: 0.7938 - val_accuracy: 0.6905\n",
      "Epoch 197/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8460 - accuracy: 0.6254 - val_loss: 0.7927 - val_accuracy: 0.6905\n",
      "Epoch 198/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.8466 - accuracy: 0.6317 - val_loss: 0.7915 - val_accuracy: 0.6905\n",
      "Epoch 199/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8381 - accuracy: 0.6190 - val_loss: 0.7905 - val_accuracy: 0.6905\n",
      "Epoch 200/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8433 - accuracy: 0.6222 - val_loss: 0.7896 - val_accuracy: 0.6905\n",
      "Epoch 201/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8365 - accuracy: 0.6413 - val_loss: 0.7888 - val_accuracy: 0.6905\n",
      "Epoch 202/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8494 - accuracy: 0.6190 - val_loss: 0.7877 - val_accuracy: 0.6905\n",
      "Epoch 203/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8415 - accuracy: 0.6222 - val_loss: 0.7869 - val_accuracy: 0.6905\n",
      "Epoch 204/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8425 - accuracy: 0.6190 - val_loss: 0.7860 - val_accuracy: 0.6905\n",
      "Epoch 205/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8392 - accuracy: 0.6381 - val_loss: 0.7850 - val_accuracy: 0.6905\n",
      "Epoch 206/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8355 - accuracy: 0.6349 - val_loss: 0.7844 - val_accuracy: 0.6905\n",
      "Epoch 207/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8408 - accuracy: 0.6222 - val_loss: 0.7836 - val_accuracy: 0.6905\n",
      "Epoch 208/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8435 - accuracy: 0.6032 - val_loss: 0.7827 - val_accuracy: 0.6905\n",
      "Epoch 209/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8458 - accuracy: 0.6159 - val_loss: 0.7818 - val_accuracy: 0.6905\n",
      "Epoch 210/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8424 - accuracy: 0.6286 - val_loss: 0.7813 - val_accuracy: 0.6905\n",
      "Epoch 211/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8239 - accuracy: 0.6381 - val_loss: 0.7805 - val_accuracy: 0.6905\n",
      "Epoch 212/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8371 - accuracy: 0.6254 - val_loss: 0.7798 - val_accuracy: 0.6905\n",
      "Epoch 213/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8357 - accuracy: 0.6413 - val_loss: 0.7791 - val_accuracy: 0.6905\n",
      "Epoch 214/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8355 - accuracy: 0.6317 - val_loss: 0.7783 - val_accuracy: 0.6905\n",
      "Epoch 215/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8303 - accuracy: 0.6381 - val_loss: 0.7775 - val_accuracy: 0.6905\n",
      "Epoch 216/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8301 - accuracy: 0.6317 - val_loss: 0.7770 - val_accuracy: 0.6905\n",
      "Epoch 217/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8296 - accuracy: 0.6381 - val_loss: 0.7762 - val_accuracy: 0.6905\n",
      "Epoch 218/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8345 - accuracy: 0.6286 - val_loss: 0.7753 - val_accuracy: 0.6905\n",
      "Epoch 219/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8369 - accuracy: 0.6286 - val_loss: 0.7743 - val_accuracy: 0.6905\n",
      "Epoch 220/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8317 - accuracy: 0.6349 - val_loss: 0.7737 - val_accuracy: 0.6905\n",
      "Epoch 221/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8244 - accuracy: 0.6381 - val_loss: 0.7730 - val_accuracy: 0.6905\n",
      "Epoch 222/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8271 - accuracy: 0.6381 - val_loss: 0.7724 - val_accuracy: 0.6905\n",
      "Epoch 223/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8269 - accuracy: 0.6254 - val_loss: 0.7718 - val_accuracy: 0.6905\n",
      "Epoch 224/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8239 - accuracy: 0.6444 - val_loss: 0.7712 - val_accuracy: 0.6905\n",
      "Epoch 225/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8259 - accuracy: 0.6286 - val_loss: 0.7705 - val_accuracy: 0.6905\n",
      "Epoch 226/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8202 - accuracy: 0.6381 - val_loss: 0.7698 - val_accuracy: 0.6905\n",
      "Epoch 227/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8231 - accuracy: 0.6476 - val_loss: 0.7692 - val_accuracy: 0.6905\n",
      "Epoch 228/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8250 - accuracy: 0.6413 - val_loss: 0.7684 - val_accuracy: 0.6905\n",
      "Epoch 229/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8231 - accuracy: 0.6413 - val_loss: 0.7677 - val_accuracy: 0.6905\n",
      "Epoch 230/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8137 - accuracy: 0.6381 - val_loss: 0.7670 - val_accuracy: 0.6905\n",
      "Epoch 231/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8147 - accuracy: 0.6476 - val_loss: 0.7664 - val_accuracy: 0.6905\n",
      "Epoch 232/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8136 - accuracy: 0.6476 - val_loss: 0.7657 - val_accuracy: 0.6905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8184 - accuracy: 0.6444 - val_loss: 0.7650 - val_accuracy: 0.6905\n",
      "Epoch 234/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8197 - accuracy: 0.6317 - val_loss: 0.7645 - val_accuracy: 0.6905\n",
      "Epoch 235/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8209 - accuracy: 0.6413 - val_loss: 0.7638 - val_accuracy: 0.6905\n",
      "Epoch 236/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8158 - accuracy: 0.6444 - val_loss: 0.7634 - val_accuracy: 0.6905\n",
      "Epoch 237/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8200 - accuracy: 0.6413 - val_loss: 0.7627 - val_accuracy: 0.6905\n",
      "Epoch 238/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8184 - accuracy: 0.6476 - val_loss: 0.7623 - val_accuracy: 0.6905\n",
      "Epoch 239/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8197 - accuracy: 0.6444 - val_loss: 0.7619 - val_accuracy: 0.6905\n",
      "Epoch 240/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8219 - accuracy: 0.6317 - val_loss: 0.7614 - val_accuracy: 0.6905\n",
      "Epoch 241/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8069 - accuracy: 0.6413 - val_loss: 0.7609 - val_accuracy: 0.6905\n",
      "Epoch 242/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8044 - accuracy: 0.6444 - val_loss: 0.7603 - val_accuracy: 0.6905\n",
      "Epoch 243/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8117 - accuracy: 0.6635 - val_loss: 0.7599 - val_accuracy: 0.6905\n",
      "Epoch 244/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8061 - accuracy: 0.6508 - val_loss: 0.7590 - val_accuracy: 0.6905\n",
      "Epoch 245/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8090 - accuracy: 0.6413 - val_loss: 0.7584 - val_accuracy: 0.6905\n",
      "Epoch 246/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.8048 - accuracy: 0.6317 - val_loss: 0.7580 - val_accuracy: 0.6905\n",
      "Epoch 247/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8118 - accuracy: 0.6349 - val_loss: 0.7572 - val_accuracy: 0.6905\n",
      "Epoch 248/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8146 - accuracy: 0.6413 - val_loss: 0.7564 - val_accuracy: 0.6905\n",
      "Epoch 249/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8101 - accuracy: 0.6444 - val_loss: 0.7559 - val_accuracy: 0.6905\n",
      "Epoch 250/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7992 - accuracy: 0.6540 - val_loss: 0.7551 - val_accuracy: 0.6905\n",
      "Epoch 251/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8104 - accuracy: 0.6381 - val_loss: 0.7548 - val_accuracy: 0.6905\n",
      "Epoch 252/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8009 - accuracy: 0.6476 - val_loss: 0.7541 - val_accuracy: 0.6905\n",
      "Epoch 253/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8049 - accuracy: 0.6508 - val_loss: 0.7536 - val_accuracy: 0.6905\n",
      "Epoch 254/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.8152 - accuracy: 0.6413 - val_loss: 0.7532 - val_accuracy: 0.6905\n",
      "Epoch 255/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8091 - accuracy: 0.6413 - val_loss: 0.7527 - val_accuracy: 0.6905\n",
      "Epoch 256/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8047 - accuracy: 0.6444 - val_loss: 0.7521 - val_accuracy: 0.6905\n",
      "Epoch 257/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7961 - accuracy: 0.6508 - val_loss: 0.7515 - val_accuracy: 0.6905\n",
      "Epoch 258/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8017 - accuracy: 0.6381 - val_loss: 0.7507 - val_accuracy: 0.6905\n",
      "Epoch 259/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8105 - accuracy: 0.6349 - val_loss: 0.7503 - val_accuracy: 0.6905\n",
      "Epoch 260/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7978 - accuracy: 0.6603 - val_loss: 0.7498 - val_accuracy: 0.6905\n",
      "Epoch 261/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8013 - accuracy: 0.6476 - val_loss: 0.7495 - val_accuracy: 0.6905\n",
      "Epoch 262/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8005 - accuracy: 0.6476 - val_loss: 0.7489 - val_accuracy: 0.6905\n",
      "Epoch 263/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7956 - accuracy: 0.6667 - val_loss: 0.7483 - val_accuracy: 0.6905\n",
      "Epoch 264/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7929 - accuracy: 0.6476 - val_loss: 0.7478 - val_accuracy: 0.6905\n",
      "Epoch 265/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8016 - accuracy: 0.6349 - val_loss: 0.7471 - val_accuracy: 0.6905\n",
      "Epoch 266/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8053 - accuracy: 0.6317 - val_loss: 0.7466 - val_accuracy: 0.6905\n",
      "Epoch 267/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7971 - accuracy: 0.6540 - val_loss: 0.7462 - val_accuracy: 0.6905\n",
      "Epoch 268/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7944 - accuracy: 0.6540 - val_loss: 0.7458 - val_accuracy: 0.6905\n",
      "Epoch 269/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7947 - accuracy: 0.6508 - val_loss: 0.7456 - val_accuracy: 0.6905\n",
      "Epoch 270/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7939 - accuracy: 0.6571 - val_loss: 0.7452 - val_accuracy: 0.6905\n",
      "Epoch 271/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7920 - accuracy: 0.6508 - val_loss: 0.7449 - val_accuracy: 0.6905\n",
      "Epoch 272/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7952 - accuracy: 0.6444 - val_loss: 0.7443 - val_accuracy: 0.6905\n",
      "Epoch 273/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7920 - accuracy: 0.6508 - val_loss: 0.7440 - val_accuracy: 0.6905\n",
      "Epoch 274/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7958 - accuracy: 0.6540 - val_loss: 0.7437 - val_accuracy: 0.6905\n",
      "Epoch 275/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7969 - accuracy: 0.6413 - val_loss: 0.7433 - val_accuracy: 0.6905\n",
      "Epoch 276/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7901 - accuracy: 0.6413 - val_loss: 0.7427 - val_accuracy: 0.6905\n",
      "Epoch 277/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7954 - accuracy: 0.6603 - val_loss: 0.7422 - val_accuracy: 0.6905\n",
      "Epoch 278/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7870 - accuracy: 0.6635 - val_loss: 0.7417 - val_accuracy: 0.6905\n",
      "Epoch 279/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8010 - accuracy: 0.6317 - val_loss: 0.7413 - val_accuracy: 0.6905\n",
      "Epoch 280/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7882 - accuracy: 0.6571 - val_loss: 0.7410 - val_accuracy: 0.6905\n",
      "Epoch 281/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7892 - accuracy: 0.6508 - val_loss: 0.7406 - val_accuracy: 0.6905\n",
      "Epoch 282/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.7917 - accuracy: 0.6413 - val_loss: 0.7403 - val_accuracy: 0.6905\n",
      "Epoch 283/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7864 - accuracy: 0.6540 - val_loss: 0.7398 - val_accuracy: 0.6905\n",
      "Epoch 284/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.7899 - accuracy: 0.6476 - val_loss: 0.7392 - val_accuracy: 0.6905\n",
      "Epoch 285/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.7950 - accuracy: 0.6413 - val_loss: 0.7389 - val_accuracy: 0.6905\n",
      "Epoch 286/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7872 - accuracy: 0.6444 - val_loss: 0.7386 - val_accuracy: 0.6905\n",
      "Epoch 287/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7910 - accuracy: 0.6381 - val_loss: 0.7383 - val_accuracy: 0.6905\n",
      "Epoch 288/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7909 - accuracy: 0.6476 - val_loss: 0.7377 - val_accuracy: 0.6905\n",
      "Epoch 289/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7936 - accuracy: 0.6381 - val_loss: 0.7371 - val_accuracy: 0.6905\n",
      "Epoch 290/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7856 - accuracy: 0.6413 - val_loss: 0.7367 - val_accuracy: 0.6905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 291/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7862 - accuracy: 0.6413 - val_loss: 0.7364 - val_accuracy: 0.6905\n",
      "Epoch 292/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7808 - accuracy: 0.6667 - val_loss: 0.7357 - val_accuracy: 0.6905\n",
      "Epoch 293/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7860 - accuracy: 0.6476 - val_loss: 0.7354 - val_accuracy: 0.6905\n",
      "Epoch 294/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7881 - accuracy: 0.6222 - val_loss: 0.7353 - val_accuracy: 0.6905\n",
      "Epoch 295/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7840 - accuracy: 0.6508 - val_loss: 0.7351 - val_accuracy: 0.6905\n",
      "Epoch 296/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7846 - accuracy: 0.6603 - val_loss: 0.7351 - val_accuracy: 0.6905\n",
      "Epoch 297/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7808 - accuracy: 0.6571 - val_loss: 0.7346 - val_accuracy: 0.6905\n",
      "Epoch 298/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7784 - accuracy: 0.6508 - val_loss: 0.7344 - val_accuracy: 0.6905\n",
      "Epoch 299/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7794 - accuracy: 0.6571 - val_loss: 0.7339 - val_accuracy: 0.6905\n",
      "Epoch 300/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7782 - accuracy: 0.6413 - val_loss: 0.7333 - val_accuracy: 0.6905\n",
      "Epoch 301/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7749 - accuracy: 0.6635 - val_loss: 0.7324 - val_accuracy: 0.6905\n",
      "Epoch 302/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7732 - accuracy: 0.6635 - val_loss: 0.7320 - val_accuracy: 0.6905\n",
      "Epoch 303/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7827 - accuracy: 0.6476 - val_loss: 0.7313 - val_accuracy: 0.6905\n",
      "Epoch 304/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7795 - accuracy: 0.6540 - val_loss: 0.7308 - val_accuracy: 0.6905\n",
      "Epoch 305/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7769 - accuracy: 0.6571 - val_loss: 0.7308 - val_accuracy: 0.6905\n",
      "Epoch 306/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7735 - accuracy: 0.6635 - val_loss: 0.7302 - val_accuracy: 0.6905\n",
      "Epoch 307/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7690 - accuracy: 0.6635 - val_loss: 0.7298 - val_accuracy: 0.6905\n",
      "Epoch 308/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7720 - accuracy: 0.6603 - val_loss: 0.7293 - val_accuracy: 0.6905\n",
      "Epoch 309/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7724 - accuracy: 0.6349 - val_loss: 0.7289 - val_accuracy: 0.6905\n",
      "Epoch 310/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7764 - accuracy: 0.6540 - val_loss: 0.7288 - val_accuracy: 0.6905\n",
      "Epoch 311/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7679 - accuracy: 0.6444 - val_loss: 0.7284 - val_accuracy: 0.6905\n",
      "Epoch 312/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7707 - accuracy: 0.6476 - val_loss: 0.7283 - val_accuracy: 0.6905\n",
      "Epoch 313/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7730 - accuracy: 0.6508 - val_loss: 0.7276 - val_accuracy: 0.6905\n",
      "Epoch 314/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7736 - accuracy: 0.6603 - val_loss: 0.7273 - val_accuracy: 0.6905\n",
      "Epoch 315/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7854 - accuracy: 0.6444 - val_loss: 0.7270 - val_accuracy: 0.6905\n",
      "Epoch 316/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7714 - accuracy: 0.6603 - val_loss: 0.7270 - val_accuracy: 0.6905\n",
      "Epoch 317/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7686 - accuracy: 0.6381 - val_loss: 0.7266 - val_accuracy: 0.6905\n",
      "Epoch 318/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7707 - accuracy: 0.6508 - val_loss: 0.7263 - val_accuracy: 0.6905\n",
      "Epoch 319/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7735 - accuracy: 0.6413 - val_loss: 0.7260 - val_accuracy: 0.6905\n",
      "Epoch 320/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7727 - accuracy: 0.6476 - val_loss: 0.7257 - val_accuracy: 0.6905\n",
      "Epoch 321/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7616 - accuracy: 0.6603 - val_loss: 0.7253 - val_accuracy: 0.6905\n",
      "Epoch 322/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7715 - accuracy: 0.6635 - val_loss: 0.7251 - val_accuracy: 0.6905\n",
      "Epoch 323/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7755 - accuracy: 0.6635 - val_loss: 0.7244 - val_accuracy: 0.6905\n",
      "Epoch 324/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7719 - accuracy: 0.6476 - val_loss: 0.7240 - val_accuracy: 0.6905\n",
      "Epoch 325/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7792 - accuracy: 0.6444 - val_loss: 0.7237 - val_accuracy: 0.6905\n",
      "Epoch 326/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7629 - accuracy: 0.6508 - val_loss: 0.7235 - val_accuracy: 0.6905\n",
      "Epoch 327/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7676 - accuracy: 0.6571 - val_loss: 0.7231 - val_accuracy: 0.6905\n",
      "Epoch 328/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7672 - accuracy: 0.6571 - val_loss: 0.7230 - val_accuracy: 0.6905\n",
      "Epoch 329/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7656 - accuracy: 0.6413 - val_loss: 0.7231 - val_accuracy: 0.6905\n",
      "Epoch 330/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7656 - accuracy: 0.6508 - val_loss: 0.7223 - val_accuracy: 0.6905\n",
      "Epoch 331/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7602 - accuracy: 0.6603 - val_loss: 0.7217 - val_accuracy: 0.6905\n",
      "Epoch 332/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7616 - accuracy: 0.6476 - val_loss: 0.7210 - val_accuracy: 0.6905\n",
      "Epoch 333/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7640 - accuracy: 0.6730 - val_loss: 0.7208 - val_accuracy: 0.6905\n",
      "Epoch 334/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7623 - accuracy: 0.6571 - val_loss: 0.7205 - val_accuracy: 0.6905\n",
      "Epoch 335/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7675 - accuracy: 0.6540 - val_loss: 0.7199 - val_accuracy: 0.6905\n",
      "Epoch 336/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7582 - accuracy: 0.6667 - val_loss: 0.7199 - val_accuracy: 0.6905\n",
      "Epoch 337/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7640 - accuracy: 0.6444 - val_loss: 0.7194 - val_accuracy: 0.6905\n",
      "Epoch 338/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7629 - accuracy: 0.6571 - val_loss: 0.7189 - val_accuracy: 0.6905\n",
      "Epoch 339/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7661 - accuracy: 0.6540 - val_loss: 0.7188 - val_accuracy: 0.6905\n",
      "Epoch 340/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7613 - accuracy: 0.6508 - val_loss: 0.7187 - val_accuracy: 0.6905\n",
      "Epoch 341/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7637 - accuracy: 0.6571 - val_loss: 0.7184 - val_accuracy: 0.6905\n",
      "Epoch 342/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7672 - accuracy: 0.6444 - val_loss: 0.7186 - val_accuracy: 0.6905\n",
      "Epoch 343/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7725 - accuracy: 0.6444 - val_loss: 0.7183 - val_accuracy: 0.6905\n",
      "Epoch 344/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7591 - accuracy: 0.6444 - val_loss: 0.7179 - val_accuracy: 0.6905\n",
      "Epoch 345/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7593 - accuracy: 0.6540 - val_loss: 0.7173 - val_accuracy: 0.6905\n",
      "Epoch 346/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7486 - accuracy: 0.6825 - val_loss: 0.7169 - val_accuracy: 0.6905\n",
      "Epoch 347/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7474 - accuracy: 0.6571 - val_loss: 0.7167 - val_accuracy: 0.6905\n",
      "Epoch 348/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7657 - accuracy: 0.6413 - val_loss: 0.7165 - val_accuracy: 0.6905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7552 - accuracy: 0.6540 - val_loss: 0.7161 - val_accuracy: 0.6905\n",
      "Epoch 350/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7576 - accuracy: 0.6381 - val_loss: 0.7154 - val_accuracy: 0.6905\n",
      "Epoch 351/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7584 - accuracy: 0.6667 - val_loss: 0.7149 - val_accuracy: 0.6905\n",
      "Epoch 352/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7571 - accuracy: 0.6667 - val_loss: 0.7147 - val_accuracy: 0.6905\n",
      "Epoch 353/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7603 - accuracy: 0.6603 - val_loss: 0.7146 - val_accuracy: 0.6905\n",
      "Epoch 354/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7618 - accuracy: 0.6603 - val_loss: 0.7143 - val_accuracy: 0.6905\n",
      "Epoch 355/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7680 - accuracy: 0.6444 - val_loss: 0.7142 - val_accuracy: 0.6905\n",
      "Epoch 356/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7551 - accuracy: 0.6667 - val_loss: 0.7141 - val_accuracy: 0.6905\n",
      "Epoch 357/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7599 - accuracy: 0.6476 - val_loss: 0.7137 - val_accuracy: 0.6905\n",
      "Epoch 358/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7484 - accuracy: 0.6476 - val_loss: 0.7137 - val_accuracy: 0.6905\n",
      "Epoch 359/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7591 - accuracy: 0.6698 - val_loss: 0.7136 - val_accuracy: 0.6905\n",
      "Epoch 360/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7592 - accuracy: 0.6476 - val_loss: 0.7136 - val_accuracy: 0.6905\n",
      "Epoch 361/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7451 - accuracy: 0.6730 - val_loss: 0.7134 - val_accuracy: 0.6905\n",
      "Epoch 362/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7506 - accuracy: 0.6508 - val_loss: 0.7130 - val_accuracy: 0.6905\n",
      "Epoch 363/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7573 - accuracy: 0.6540 - val_loss: 0.7127 - val_accuracy: 0.6905\n",
      "Epoch 364/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7536 - accuracy: 0.6540 - val_loss: 0.7121 - val_accuracy: 0.6905\n",
      "Epoch 365/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7545 - accuracy: 0.6444 - val_loss: 0.7115 - val_accuracy: 0.6905\n",
      "Epoch 366/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7538 - accuracy: 0.6222 - val_loss: 0.7113 - val_accuracy: 0.6667\n",
      "Epoch 367/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7482 - accuracy: 0.6508 - val_loss: 0.7108 - val_accuracy: 0.6905\n",
      "Epoch 368/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7416 - accuracy: 0.6571 - val_loss: 0.7106 - val_accuracy: 0.7143\n",
      "Epoch 369/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7482 - accuracy: 0.6317 - val_loss: 0.7098 - val_accuracy: 0.6905\n",
      "Epoch 370/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.7447 - accuracy: 0.6476 - val_loss: 0.7096 - val_accuracy: 0.6905\n",
      "Epoch 371/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7493 - accuracy: 0.6698 - val_loss: 0.7091 - val_accuracy: 0.6905\n",
      "Epoch 372/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7487 - accuracy: 0.6508 - val_loss: 0.7092 - val_accuracy: 0.6905\n",
      "Epoch 373/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7539 - accuracy: 0.6413 - val_loss: 0.7093 - val_accuracy: 0.6905\n",
      "Epoch 374/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7477 - accuracy: 0.6635 - val_loss: 0.7091 - val_accuracy: 0.6905\n",
      "Epoch 375/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7530 - accuracy: 0.6508 - val_loss: 0.7086 - val_accuracy: 0.7143\n",
      "Epoch 376/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7520 - accuracy: 0.6540 - val_loss: 0.7082 - val_accuracy: 0.7143\n",
      "Epoch 377/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7424 - accuracy: 0.6635 - val_loss: 0.7082 - val_accuracy: 0.6905\n",
      "Epoch 378/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7607 - accuracy: 0.6349 - val_loss: 0.7081 - val_accuracy: 0.6905\n",
      "Epoch 379/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7514 - accuracy: 0.6476 - val_loss: 0.7081 - val_accuracy: 0.6905\n",
      "Epoch 380/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7449 - accuracy: 0.6698 - val_loss: 0.7078 - val_accuracy: 0.6905\n",
      "Epoch 381/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7429 - accuracy: 0.6635 - val_loss: 0.7076 - val_accuracy: 0.6905\n",
      "Epoch 382/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7411 - accuracy: 0.6603 - val_loss: 0.7074 - val_accuracy: 0.6905\n",
      "Epoch 383/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7379 - accuracy: 0.6603 - val_loss: 0.7067 - val_accuracy: 0.6905\n",
      "Epoch 384/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7457 - accuracy: 0.6603 - val_loss: 0.7070 - val_accuracy: 0.6905\n",
      "Epoch 385/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.7412 - accuracy: 0.6603 - val_loss: 0.7067 - val_accuracy: 0.6905\n",
      "Epoch 386/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7351 - accuracy: 0.6508 - val_loss: 0.7065 - val_accuracy: 0.6905\n",
      "Epoch 387/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7394 - accuracy: 0.6540 - val_loss: 0.7062 - val_accuracy: 0.6905\n",
      "Epoch 388/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7377 - accuracy: 0.6476 - val_loss: 0.7058 - val_accuracy: 0.6905\n",
      "Epoch 389/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7408 - accuracy: 0.6508 - val_loss: 0.7057 - val_accuracy: 0.6905\n",
      "Epoch 390/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7359 - accuracy: 0.6730 - val_loss: 0.7052 - val_accuracy: 0.6905\n",
      "Epoch 391/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7467 - accuracy: 0.6571 - val_loss: 0.7049 - val_accuracy: 0.6905\n",
      "Epoch 392/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7417 - accuracy: 0.6635 - val_loss: 0.7044 - val_accuracy: 0.6905\n",
      "Epoch 393/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7350 - accuracy: 0.6635 - val_loss: 0.7041 - val_accuracy: 0.6905\n",
      "Epoch 394/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7365 - accuracy: 0.6825 - val_loss: 0.7037 - val_accuracy: 0.6905\n",
      "Epoch 395/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7418 - accuracy: 0.6540 - val_loss: 0.7035 - val_accuracy: 0.6905\n",
      "Epoch 396/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7390 - accuracy: 0.6667 - val_loss: 0.7033 - val_accuracy: 0.6905\n",
      "Epoch 397/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.7430 - accuracy: 0.6571 - val_loss: 0.7033 - val_accuracy: 0.6905\n",
      "Epoch 398/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7386 - accuracy: 0.6635 - val_loss: 0.7030 - val_accuracy: 0.6905\n",
      "Epoch 399/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7286 - accuracy: 0.6571 - val_loss: 0.7027 - val_accuracy: 0.6905\n",
      "Epoch 400/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7393 - accuracy: 0.6540 - val_loss: 0.7024 - val_accuracy: 0.6905\n",
      "Epoch 401/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7354 - accuracy: 0.6667 - val_loss: 0.7023 - val_accuracy: 0.6905\n",
      "Epoch 402/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7364 - accuracy: 0.6571 - val_loss: 0.7019 - val_accuracy: 0.6905\n",
      "Epoch 403/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7505 - accuracy: 0.6508 - val_loss: 0.7020 - val_accuracy: 0.6905\n",
      "Epoch 404/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7419 - accuracy: 0.6476 - val_loss: 0.7021 - val_accuracy: 0.6905\n",
      "Epoch 405/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7433 - accuracy: 0.6476 - val_loss: 0.7018 - val_accuracy: 0.6905\n",
      "Epoch 406/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7407 - accuracy: 0.6667 - val_loss: 0.7014 - val_accuracy: 0.6905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 407/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7291 - accuracy: 0.6635 - val_loss: 0.7012 - val_accuracy: 0.6905\n",
      "Epoch 408/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7377 - accuracy: 0.6603 - val_loss: 0.7010 - val_accuracy: 0.6905\n",
      "Epoch 409/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7352 - accuracy: 0.6540 - val_loss: 0.7008 - val_accuracy: 0.6905\n",
      "Epoch 410/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7350 - accuracy: 0.6571 - val_loss: 0.7007 - val_accuracy: 0.6905\n",
      "Epoch 411/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7402 - accuracy: 0.6667 - val_loss: 0.7007 - val_accuracy: 0.6905\n",
      "Epoch 412/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7270 - accuracy: 0.6508 - val_loss: 0.7001 - val_accuracy: 0.6905\n",
      "Epoch 413/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7308 - accuracy: 0.6635 - val_loss: 0.6998 - val_accuracy: 0.6905\n",
      "Epoch 414/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7328 - accuracy: 0.6444 - val_loss: 0.6998 - val_accuracy: 0.6905\n",
      "Epoch 415/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7346 - accuracy: 0.6730 - val_loss: 0.6987 - val_accuracy: 0.6905\n",
      "Epoch 416/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7322 - accuracy: 0.6635 - val_loss: 0.6978 - val_accuracy: 0.6905\n",
      "Epoch 417/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7265 - accuracy: 0.6571 - val_loss: 0.6975 - val_accuracy: 0.6905\n",
      "Epoch 418/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.7365 - accuracy: 0.6508 - val_loss: 0.6975 - val_accuracy: 0.6905\n",
      "Epoch 419/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7342 - accuracy: 0.6635 - val_loss: 0.6975 - val_accuracy: 0.6905\n",
      "Epoch 420/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7355 - accuracy: 0.6667 - val_loss: 0.6974 - val_accuracy: 0.6905\n",
      "Epoch 421/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7404 - accuracy: 0.6635 - val_loss: 0.6973 - val_accuracy: 0.6905\n",
      "Epoch 422/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7300 - accuracy: 0.6698 - val_loss: 0.6969 - val_accuracy: 0.6905\n",
      "Epoch 423/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7229 - accuracy: 0.6571 - val_loss: 0.6962 - val_accuracy: 0.6905\n",
      "Epoch 424/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.7263 - accuracy: 0.6635 - val_loss: 0.6960 - val_accuracy: 0.6905\n",
      "Epoch 425/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7277 - accuracy: 0.6762 - val_loss: 0.6956 - val_accuracy: 0.6905\n",
      "Epoch 426/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7221 - accuracy: 0.6667 - val_loss: 0.6957 - val_accuracy: 0.6905\n",
      "Epoch 427/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7240 - accuracy: 0.6730 - val_loss: 0.6955 - val_accuracy: 0.6905\n",
      "Epoch 428/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7249 - accuracy: 0.6635 - val_loss: 0.6955 - val_accuracy: 0.6905\n",
      "Epoch 429/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7249 - accuracy: 0.6540 - val_loss: 0.6953 - val_accuracy: 0.6905\n",
      "Epoch 430/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7260 - accuracy: 0.6540 - val_loss: 0.6949 - val_accuracy: 0.6905\n",
      "Epoch 431/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7279 - accuracy: 0.6667 - val_loss: 0.6947 - val_accuracy: 0.6905\n",
      "Epoch 432/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7301 - accuracy: 0.6667 - val_loss: 0.6946 - val_accuracy: 0.6905\n",
      "Epoch 433/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.7222 - accuracy: 0.6667 - val_loss: 0.6941 - val_accuracy: 0.6905\n",
      "Epoch 434/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7239 - accuracy: 0.6603 - val_loss: 0.6937 - val_accuracy: 0.6905\n",
      "Epoch 435/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7283 - accuracy: 0.6508 - val_loss: 0.6937 - val_accuracy: 0.6905\n",
      "Epoch 436/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7285 - accuracy: 0.6698 - val_loss: 0.6938 - val_accuracy: 0.6905\n",
      "Epoch 437/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7199 - accuracy: 0.6762 - val_loss: 0.6938 - val_accuracy: 0.6905\n",
      "Epoch 438/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7309 - accuracy: 0.6476 - val_loss: 0.6936 - val_accuracy: 0.6905\n",
      "Epoch 439/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.7310 - accuracy: 0.6667 - val_loss: 0.6934 - val_accuracy: 0.6905\n",
      "Epoch 440/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7194 - accuracy: 0.6603 - val_loss: 0.6927 - val_accuracy: 0.6905\n",
      "Epoch 441/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7321 - accuracy: 0.6476 - val_loss: 0.6919 - val_accuracy: 0.6905\n",
      "Epoch 442/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7305 - accuracy: 0.6603 - val_loss: 0.6916 - val_accuracy: 0.6905\n",
      "Epoch 443/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7244 - accuracy: 0.6540 - val_loss: 0.6908 - val_accuracy: 0.6905\n",
      "Epoch 444/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7239 - accuracy: 0.6698 - val_loss: 0.6910 - val_accuracy: 0.6905\n",
      "Epoch 445/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7271 - accuracy: 0.6698 - val_loss: 0.6911 - val_accuracy: 0.6905\n",
      "Epoch 446/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7197 - accuracy: 0.6540 - val_loss: 0.6912 - val_accuracy: 0.6905\n",
      "Epoch 447/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7216 - accuracy: 0.6603 - val_loss: 0.6908 - val_accuracy: 0.6905\n",
      "Epoch 448/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7206 - accuracy: 0.6540 - val_loss: 0.6908 - val_accuracy: 0.6905\n",
      "Epoch 449/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7196 - accuracy: 0.6698 - val_loss: 0.6906 - val_accuracy: 0.6905\n",
      "Epoch 450/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7270 - accuracy: 0.6540 - val_loss: 0.6902 - val_accuracy: 0.6905\n",
      "Epoch 451/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7207 - accuracy: 0.6698 - val_loss: 0.6902 - val_accuracy: 0.6905\n",
      "Epoch 452/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7139 - accuracy: 0.6603 - val_loss: 0.6898 - val_accuracy: 0.6905\n",
      "Epoch 453/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7248 - accuracy: 0.6540 - val_loss: 0.6894 - val_accuracy: 0.6905\n",
      "Epoch 454/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7174 - accuracy: 0.6508 - val_loss: 0.6895 - val_accuracy: 0.6905\n",
      "Epoch 455/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7278 - accuracy: 0.6540 - val_loss: 0.6893 - val_accuracy: 0.6905\n",
      "Epoch 456/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7205 - accuracy: 0.6603 - val_loss: 0.6894 - val_accuracy: 0.6905\n",
      "Epoch 457/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7162 - accuracy: 0.6571 - val_loss: 0.6892 - val_accuracy: 0.6905\n",
      "Epoch 458/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7205 - accuracy: 0.6603 - val_loss: 0.6891 - val_accuracy: 0.6905\n",
      "Epoch 459/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7186 - accuracy: 0.6794 - val_loss: 0.6891 - val_accuracy: 0.6905\n",
      "Epoch 460/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7136 - accuracy: 0.6730 - val_loss: 0.6888 - val_accuracy: 0.6905\n",
      "Epoch 461/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.7319 - accuracy: 0.6444 - val_loss: 0.6885 - val_accuracy: 0.6905\n",
      "Epoch 462/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.7166 - accuracy: 0.6571 - val_loss: 0.6887 - val_accuracy: 0.6905\n",
      "Epoch 463/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7193 - accuracy: 0.6603 - val_loss: 0.6885 - val_accuracy: 0.6905\n",
      "Epoch 464/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7119 - accuracy: 0.6667 - val_loss: 0.6882 - val_accuracy: 0.6905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 465/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7127 - accuracy: 0.6603 - val_loss: 0.6884 - val_accuracy: 0.6905\n",
      "Epoch 466/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7150 - accuracy: 0.6444 - val_loss: 0.6880 - val_accuracy: 0.6905\n",
      "Epoch 467/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.7135 - accuracy: 0.6540 - val_loss: 0.6877 - val_accuracy: 0.6905\n",
      "Epoch 468/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.7288 - accuracy: 0.6476 - val_loss: 0.6876 - val_accuracy: 0.6905\n",
      "Epoch 469/500\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.7207 - accuracy: 0.6698 - val_loss: 0.6874 - val_accuracy: 0.6905\n",
      "Epoch 470/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.7145 - accuracy: 0.6603 - val_loss: 0.6872 - val_accuracy: 0.6905\n",
      "Epoch 471/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.7207 - accuracy: 0.6476 - val_loss: 0.6877 - val_accuracy: 0.6905\n",
      "Epoch 472/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.7149 - accuracy: 0.6603 - val_loss: 0.6876 - val_accuracy: 0.6905\n",
      "Epoch 473/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.7119 - accuracy: 0.6508 - val_loss: 0.6876 - val_accuracy: 0.6905\n",
      "Epoch 474/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7084 - accuracy: 0.6571 - val_loss: 0.6871 - val_accuracy: 0.6905\n",
      "Epoch 475/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7134 - accuracy: 0.6635 - val_loss: 0.6863 - val_accuracy: 0.6905\n",
      "Epoch 476/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.7173 - accuracy: 0.6667 - val_loss: 0.6857 - val_accuracy: 0.6905\n",
      "Epoch 477/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7201 - accuracy: 0.6508 - val_loss: 0.6854 - val_accuracy: 0.6905\n",
      "Epoch 478/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7106 - accuracy: 0.6698 - val_loss: 0.6851 - val_accuracy: 0.6905\n",
      "Epoch 479/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7171 - accuracy: 0.6667 - val_loss: 0.6854 - val_accuracy: 0.6905\n",
      "Epoch 480/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7247 - accuracy: 0.6571 - val_loss: 0.6857 - val_accuracy: 0.6905\n",
      "Epoch 481/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7126 - accuracy: 0.6444 - val_loss: 0.6860 - val_accuracy: 0.6905\n",
      "Epoch 482/500\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.7177 - accuracy: 0.6540 - val_loss: 0.6857 - val_accuracy: 0.6905\n",
      "Epoch 483/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7067 - accuracy: 0.6603 - val_loss: 0.6853 - val_accuracy: 0.6905\n",
      "Epoch 484/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7132 - accuracy: 0.6444 - val_loss: 0.6848 - val_accuracy: 0.6905\n",
      "Epoch 485/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7134 - accuracy: 0.6540 - val_loss: 0.6844 - val_accuracy: 0.6905\n",
      "Epoch 486/500\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.7034 - accuracy: 0.6667 - val_loss: 0.6843 - val_accuracy: 0.6905\n",
      "Epoch 487/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7131 - accuracy: 0.6571 - val_loss: 0.6844 - val_accuracy: 0.6905\n",
      "Epoch 488/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7125 - accuracy: 0.6540 - val_loss: 0.6846 - val_accuracy: 0.6905\n",
      "Epoch 489/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7110 - accuracy: 0.6667 - val_loss: 0.6845 - val_accuracy: 0.6905\n",
      "Epoch 490/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7148 - accuracy: 0.6540 - val_loss: 0.6843 - val_accuracy: 0.6905\n",
      "Epoch 491/500\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7123 - accuracy: 0.6730 - val_loss: 0.6847 - val_accuracy: 0.6905\n",
      "Epoch 492/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7067 - accuracy: 0.6603 - val_loss: 0.6845 - val_accuracy: 0.6905\n",
      "Epoch 493/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7141 - accuracy: 0.6444 - val_loss: 0.6840 - val_accuracy: 0.6905\n",
      "Epoch 494/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7087 - accuracy: 0.6667 - val_loss: 0.6834 - val_accuracy: 0.6905\n",
      "Epoch 495/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7127 - accuracy: 0.6571 - val_loss: 0.6834 - val_accuracy: 0.6905\n",
      "Epoch 496/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6998 - accuracy: 0.6762 - val_loss: 0.6830 - val_accuracy: 0.6905\n",
      "Epoch 497/500\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7068 - accuracy: 0.6540 - val_loss: 0.6828 - val_accuracy: 0.6905\n",
      "Epoch 498/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7182 - accuracy: 0.6317 - val_loss: 0.6831 - val_accuracy: 0.6905\n",
      "Epoch 499/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7111 - accuracy: 0.6762 - val_loss: 0.6832 - val_accuracy: 0.6905\n",
      "Epoch 500/500\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7052 - accuracy: 0.6571 - val_loss: 0.6825 - val_accuracy: 0.6905\n",
      "\n",
      "\n",
      "Test loss: 0.6825287938117981\n",
      "Test accuracy: 0.6904761791229248\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Building the RNN ##\n",
    "print()\n",
    "print(\"length of train data: \", len(train_x))\n",
    "print(\"length of validation data: \", len(validation_x))\n",
    "print()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(train_x.shape[1:]), activation='tanh', return_sequences=True))\n",
    "# model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(LSTM(64, activation='tanh'))\n",
    "# model.add(Dropout(0.3))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(64, activation='tanh'))\n",
    "# model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.000015, decay=1e-6)\n",
    "# opt = tf.keras.optimizers.Adam(learning_rate=0.0001, decay=1e-6)\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=opt,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_x, train_y,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(validation_x, validation_y)\n",
    ")\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "# Score model\n",
    "score = model.evaluate(validation_x, validation_y, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.6825287938117981\n",
      "Test accuracy: 0.6904761791229248\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(10,7))\n",
    "plt.xlabel('epoch')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_test_buys(tickers, SEQ_LEN, SHIFT):\n",
    "    Sequential_data = []\n",
    "    for ticker in tickers:\n",
    "        df = set_data(ticker)[-SHIFT:]\n",
    "        print(df.tail(15))\n",
    "\n",
    "        sequential_data = []  # this is a list that will CONTAIN the sequences\n",
    "        prev_days = deque(maxlen=SEQ_LEN)  # These will be our actual sequences. They are made with deque, which keeps the maximum length by popping out older values as new ones come in\n",
    "        \n",
    "        for i in df.values:  # iterate over the values\n",
    "            prev_days.append([n for n in i[:-2]])  # store all but the target\n",
    "            if len(prev_days) == SEQ_LEN:  # make sure we have 60 sequences!\n",
    "                sequential_data.append([np.array(prev_days), i[-2], i[-1]])  # append those bad boys!\n",
    "        \n",
    "        Sequential_data = Sequential_data + sequential_data\n",
    "        \n",
    "    X = []; y = []; z = []\n",
    "    for seq, target, actual in Sequential_data:  # going over our new sequential data\n",
    "        X.append(seq)  # X is the sequences\n",
    "        y.append(target)  # y is the targets/labels (buys vs sell/notbuy)\n",
    "        z.append(actual)\n",
    "\n",
    "    return np.array(X).astype(\"float64\"), np.array(y).astype(\"uint8\"), np.array(z).astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            W_il  SMA10_il  CO_il  CP_ol  close_per1\n",
      "date                                                \n",
      "2021-12-09     1         0      0      1   -6.827178\n",
      "2021-12-10     1         0      1      0   -0.873471\n",
      "2021-12-13     1         0      0      0   -4.185535\n",
      "2021-12-14     1         0      0      0   -2.669567\n",
      "2021-12-15     0         0      0      2    4.842527\n",
      "2021-12-16     1         0      1      1   -6.221058\n",
      "2021-12-17     1         0      0      0    2.682863\n",
      "2021-12-20     1         0      0      0   -4.263614\n",
      "2021-12-21     0         1      1      2    8.627715\n",
      "2021-12-22     0         1      0      0    2.851790\n",
      "2021-12-23    -1         1      1      0    2.395711\n",
      "2021-12-27    -1         1      1      0    2.850358\n",
      "2021-12-28    -1         1      0      0   -1.812933\n",
      "2021-12-29    -1         1      0      0    0.270497\n",
      "2021-12-30    -1         1      0      0   -0.140749\n"
     ]
    }
   ],
   "source": [
    "last_trading_days = 20\n",
    "test_x, test_y, test_z = process_test_buys(tickers_test, SEQ_LEN, last_trading_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.  1.  0.]\n",
      " [-1.  1.  0.]]\n",
      "0\n",
      "-0.14074917144651922\n"
     ]
    }
   ],
   "source": [
    "print(test_x[-1])\n",
    "print(test_y[-1])\n",
    "print(test_z[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []; total = 0\n",
    "for i, j in zip(output, test_z):\n",
    "    if np.argmax(i) == 2:\n",
    "        total += 1\n",
    "#         results.append([i,j])\n",
    "        results.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trading period. The last 100 trading days.\n",
      "Trading period: 5 percent, over 8 trades.\n",
      "Average daily return: 5 percent, over 8 trades.\n",
      "You started with $5000 and finished with $7591 after 8 trades.\n"
     ]
    }
   ],
   "source": [
    "print('Trading period. The last %d trading days.' % (last_trading_days))\n",
    "print('Trading period: %d percent, over %d trades.' % (np.sum(results)/len(results), len(results)))\n",
    "print('Average daily return: %d percent, over %d trades.' % (np.sum(results)/len(results), len(results)))\n",
    "start = 5000\n",
    "finish = start\n",
    "for i in results:\n",
    "    finish = finish + (i/100) * finish\n",
    "    \n",
    "print('You started with $%d and finished with $%d after %d trades.' % (start, finish, len(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.4082912116520685, -0.772769021589037, 5.025056559514063, 5.726489588815231, 2.945719141125891, 8.35394753164409, -1.2505481437498966, 2.017374950722206, -2.9965008400013704, 0.6445998637189643, 4.458672335756675, 5.388521343106012, 4.3221755332707, -0.5709564715190796, 4.776841940851462, 1.0774372730292692, 4.736963722489929, 1.7171922475946566, 4.332835651170441, -0.9142991318043636, 1.9584132644258512, -2.2327137641667827, 6.005465774391272, 0.657241209325643, 4.243112701059504, 0.9386188953442121, 2.4476563509958416, 0.23331953432994545, -1.2771784113766782, -1.2791909238900834, -0.6247845791248041, -6.820156418592194, 6.840351822165136, -0.8734705143035981, 8.627715496969547, 2.3957114324287376, 2.850358210053372]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []; total = 0\n",
    "for i, j in zip(output, test_z):\n",
    "    if i[2] > 0.6:\n",
    "        total += 1\n",
    "#         results.append([i,j])\n",
    "        results.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trading period: 5 percent, over 8 trades.\n",
      "Average daily return: 5 percent, over 8 trades.\n",
      "You started with $5000 and finished with $7591 after 8 trades.\n"
     ]
    }
   ],
   "source": [
    "print('Trading period. The last %d trading days.' % (last_trading_days))\n",
    "print('Trading period: %d percent, over %d trades.' % (np.sum(results)/len(results), len(results)))\n",
    "print('Average daily return: %d percent, over %d trades.' % (np.sum(results)/len(results), len(results)))\n",
    "start = 5000\n",
    "finish = start\n",
    "for i in results:\n",
    "    finish = finish + (i/100) * finish\n",
    "    \n",
    "print('You started with $%d and finished with $%d after %d trades.' % (start, finish, len(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.025056559514063, 2.945719141125891, 4.458672335756675, 4.736963722489929, 4.332835651170441, 6.005465774391272, 6.840351822165136, 8.627715496969547]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if os.path.isfile('TNA_model.h5') is False:\n",
    "    model.save('TNA_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = load_model('TNA_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_8 (LSTM)                (None, 2, 32)             4608      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 2, 32)             128       \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 64)                24832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 34,179\n",
      "Trainable params: 33,987\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "output = model1.predict(test_x[-2:-1])\n",
    "print(np.argmax(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-1.  1.  0.]\n",
      "  [-1.  1.  0.]]]\n"
     ]
    }
   ],
   "source": [
    "print(test_x[-2:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

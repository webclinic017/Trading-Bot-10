{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "import random\n",
    "from collections import deque\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, BatchNormalization, Flatten, Activation\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ModelCheckpoint\n",
    "import time\n",
    "import statistics\n",
    "from sklearn import preprocessing\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = \"TNA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDB(ticker):\n",
    "    tick = ticker\n",
    "    # Load data\n",
    "    data = yf.Ticker(tick)\n",
    "    df = data.history(period=\"5y\", interval=\"1d\")\n",
    "#     df = data.history(start=\"2018-12-01\", end=\"2020-03-01\")\n",
    "#     start=\"2017-01-01\", end=\"2017-04-30\"\n",
    "    \n",
    "    # add data points\n",
    "    df['close_per1'] = df.ta.percent_return(1)*100\n",
    "    df['sma10'] = df.ta.sma(length=10)\n",
    "    df['williams'] = df.ta.willr()\n",
    "\n",
    "\n",
    "    df = df[[\n",
    "            'open','close','sma10','williams','close_per1'\n",
    "            ]]\n",
    "\n",
    "    df = df.dropna()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.448215298951527\n",
      "                 open      close      sma10   williams  close_per1\n",
      "date                                                              \n",
      "2017-01-23  48.812677  48.649506  49.949431 -85.270657   -1.135450\n",
      "2017-01-24  49.163738  50.775665  50.048322 -47.116249    4.370362\n",
      "2017-01-25  52.031582  52.328255  50.155618 -16.129111    3.057743\n",
      "2017-01-26  52.348033  51.715126  50.177868 -19.549714   -1.171697\n",
      "2017-01-27  51.764578  51.111897  50.261432 -32.036797   -1.166447\n",
      "                 open      close      sma10   williams  close_per1\n",
      "date                                                              \n",
      "2021-12-27  84.500000  86.599998  79.254777 -14.188268    2.850358\n",
      "2021-12-28  86.199997  85.029999  79.934092 -22.320079   -1.812933\n",
      "2021-12-29  84.889999  85.260002  80.845266 -17.004946    0.270497\n",
      "2021-12-30  85.180000  85.139999  81.375690 -17.658998   -0.140749\n",
      "2021-12-31  84.550003  85.010002  82.389777 -18.367524   -0.152686\n"
     ]
    }
   ],
   "source": [
    "data = getDB(ticker)\n",
    "print(data['close_per1'].std())\n",
    "print(data.head(5))\n",
    "print(data.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2017-01-23 00:00:00')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[1]\n",
    "data.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_data(ticker):\n",
    "    df = getDB(ticker)\n",
    "\n",
    "    df['CP_ol'] = 0 # open to close day percentage [classify by 0,1,2]\n",
    "    df['CO_il'] = 0 # close(i) to open(i+1) price [classify by 0,1]\n",
    "    df['SMA10_il'] = 0 # sma(10 day) compared to close price (i)\n",
    "    df['W_il'] = 0 # Williams [classify by -1,0,1]\n",
    "    \n",
    "    value = df['close_per1'].std()\n",
    "    \n",
    "    # setting the outputs in the df\n",
    "    for i in range(len(df)):\n",
    "        if df.iloc[i]['close_per1'] > value:\n",
    "            df.iloc[i, df.columns.get_loc('CP_ol')] = 2\n",
    "        elif df.iloc[i]['close_per1'] < -value:\n",
    "            df.iloc[i, df.columns.get_loc('CP_ol')] = 1\n",
    "        else:\n",
    "            df.iloc[i, df.columns.get_loc('CP_ol')] = 0\n",
    "    \n",
    "    # setting the inputs in the df\n",
    "    for i in range(len(df)-1):\n",
    "#         try:\n",
    "#         print(\"close data:\",df.index[i])\n",
    "#         print(\"open data:\",df.index[i+1])\n",
    "#         print(\"putting data here:\",df.index[i+1])\n",
    "#         print()\n",
    "        if df.iloc[i]['close'] < df.iloc[i+1]['open']:\n",
    "            df.iloc[i+1, df.columns.get_loc('CO_il')] = 1\n",
    "        else:\n",
    "            df.iloc[i+1, df.columns.get_loc('CO_il')] = 0\n",
    "#         except:\n",
    "#             df.iloc[i+1, df.columns.get_loc('CO_il')] = np.nan\n",
    "            \n",
    "    \n",
    "#     # setting the inputs in the df\n",
    "#     for i in range(len(df)):\n",
    "#         try:\n",
    "#             if df.iloc[i]['close'] > df.iloc[i]['sma10']:\n",
    "#                 df.iloc[i, df.columns.get_loc('SMA10_il')] = 1\n",
    "#             else:\n",
    "#                 df.iloc[i, df.columns.get_loc('SMA10_il')] = 0\n",
    "#         except:\n",
    "#             df.iloc[i, df.columns.get_loc('SMA10_il')] = np.nan\n",
    "       \n",
    "    # setting the inputs in the df\n",
    "    for i in range(len(df)-1):\n",
    "#         try:\n",
    "        if df.iloc[i+1]['open'] > df.iloc[i]['sma10']:\n",
    "            df.iloc[i+1, df.columns.get_loc('SMA10_il')] = 1\n",
    "        else:\n",
    "            df.iloc[i+1, df.columns.get_loc('SMA10_il')] = 0\n",
    "#         except:\n",
    "#             df.iloc[i+1, df.columns.get_loc('SMA10_il')] = np.nan\n",
    "    \n",
    "    \n",
    "    # setting the inputs in the df\n",
    "    for i in range(len(df)):\n",
    "        if df.iloc[i]['williams'] > -30: # overbought\n",
    "            df.iloc[i, df.columns.get_loc('W_il')] = -1\n",
    "        elif df.iloc[i]['williams'] < -70: # oversold\n",
    "            df.iloc[i, df.columns.get_loc('W_il')] = 1\n",
    "        else:\n",
    "            df.iloc[i, df.columns.get_loc('W_il')] = 0 # neutral\n",
    "    \n",
    "    df['W_il'] = df.W_il.shift(1)\n",
    "#     df['SMA10_il'] = df.SMA10_il.shift(1)\n",
    "    \n",
    "    # deleting data that is not normalized\n",
    "    del df['open']\n",
    "    del df['close']\n",
    "    del df['sma10']\n",
    "    del df['williams']\n",
    "#     del df['close_per1']\n",
    "    \n",
    "    # reformating\n",
    "    df = df[[\n",
    "            'W_il','SMA10_il','CO_il','CP_ol','close_per1'\n",
    "            ]]\n",
    "    \n",
    "    df = df.dropna()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            W_il  SMA10_il  CO_il  CP_ol  close_per1\n",
      "date                                                \n",
      "2017-01-24   1.0         0      1      0    4.370354\n",
      "2017-01-25   0.0         1      1      0    3.057758\n",
      "2017-01-26  -1.0         1      1      0   -1.171690\n",
      "2017-01-27  -1.0         1      1      0   -1.166469\n",
      "2017-01-30   0.0         0      0      0   -3.976005\n"
     ]
    }
   ],
   "source": [
    "df = set_data(ticker)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5161695727160296\n"
     ]
    }
   ],
   "source": [
    "A = []\n",
    "# setting the outputs in the df\n",
    "for i in range(len(df)):\n",
    "    if df.iloc[i]['CO_il'] == 1:\n",
    "        if \n",
    "        A.append(df.iloc[i]['close_per1'])\n",
    "a = np.average(A)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_train(tickers, SEQ_LEN, SHIFT):\n",
    "    Sequential_data = []\n",
    "    for ticker in tickers:\n",
    "        df = set_data(ticker)[0:-SHIFT]\n",
    "        \n",
    "        del df['close_per1']\n",
    "\n",
    "        sequential_data = []  # this is a list that will CONTAIN the sequences\n",
    "        prev_days = deque(maxlen=SEQ_LEN)  # These will be our actual sequences. They are made with deque, which keeps the maximum length by popping out older values as new ones come in\n",
    "        \n",
    "        for i in df.values:  # iterate over the values\n",
    "            prev_days.append([n for n in i[:-1]])  # store all but the target\n",
    "            if len(prev_days) == SEQ_LEN:  # make sure we have 60 sequences!\n",
    "                sequential_data.append([np.array(prev_days), i[-1]])  # append those bad boys!\n",
    "        \n",
    "        \n",
    "        random.shuffle(sequential_data)  # shuffle for good measure.\n",
    "        \n",
    "        buy = []; notbuy = []; maybe = []\n",
    "        \n",
    "        for seq, target in sequential_data:  # iterate over the sequential data\n",
    "            if target == 0:\n",
    "                maybe.append([seq, target])\n",
    "            elif target == 1:\n",
    "                notbuy.append([seq, target]) \n",
    "            elif target == 2:\n",
    "                buy.append([seq, target])  \n",
    "        \n",
    "        # suffle data\n",
    "        random.shuffle(buy)\n",
    "        random.shuffle(notbuy)\n",
    "        random.shuffle(maybe)\n",
    "        \n",
    "        lower = min(len(buy), len(notbuy), len(maybe))  # what's the shorter length?\n",
    "        \n",
    "        # make sure lists are only up to the shortest length.\n",
    "        buy = buy[:lower]  \n",
    "        notbuy = notbuy[:lower]\n",
    "        maybe = maybe[:lower]\n",
    "        \n",
    "        sequential_data = buy+notbuy+maybe # add them together\n",
    "        random.shuffle(sequential_data)  # another shuffle, so the model doesn't get confused with all 1 class then the other.\n",
    "    \n",
    "        Sequential_data = Sequential_data + sequential_data\n",
    "        \n",
    "    random.shuffle(Sequential_data)\n",
    "    X = []; y = []\n",
    "    for seq, target in Sequential_data:  # going over our new sequential data\n",
    "        X.append(seq)  # X is the sequences\n",
    "        y.append(target)  # y is the targets/labels (buys vs sell/notbuy)\n",
    "\n",
    "    return np.array(X).astype(\"float64\"), np.array(y).astype(\"uint8\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_test(tickers, SEQ_LEN, SHIFT):\n",
    "    Sequential_data = []\n",
    "    for ticker in tickers:\n",
    "        df = set_data(ticker)[-SHIFT:]\n",
    "        \n",
    "        del df['close_per1']\n",
    "\n",
    "        sequential_data = []  # this is a list that will CONTAIN the sequences\n",
    "        prev_days = deque(maxlen=SEQ_LEN)  # These will be our actual sequences. They are made with deque, which keeps the maximum length by popping out older values as new ones come in\n",
    "        \n",
    "        for i in df.values:  # iterate over the values\n",
    "            prev_days.append([n for n in i[:-1]])  # store all but the target\n",
    "            if len(prev_days) == SEQ_LEN:  # make sure we have 60 sequences!\n",
    "                sequential_data.append([np.array(prev_days), i[-1]])  # append those bad boys!\n",
    "        \n",
    "        \n",
    "        random.shuffle(sequential_data)  # shuffle for good measure.\n",
    "        \n",
    "        buy = []; notbuy = []; maybe = []\n",
    "        \n",
    "        for seq, target in sequential_data:  # iterate over the sequential data\n",
    "            if target == 0:\n",
    "                maybe.append([seq, target])\n",
    "            elif target == 1:\n",
    "                notbuy.append([seq, target]) \n",
    "            elif target == 2:\n",
    "                buy.append([seq, target])  \n",
    "        \n",
    "        # suffle data\n",
    "        random.shuffle(buy)\n",
    "        random.shuffle(notbuy)\n",
    "        random.shuffle(maybe)\n",
    "        \n",
    "        lower = min(len(buy), len(notbuy), len(maybe))  # what's the shorter length?\n",
    "        \n",
    "        # make sure lists are only up to the shortest length.\n",
    "        buy = buy[:lower]  \n",
    "        notbuy = notbuy[:lower]\n",
    "        maybe = maybe[:lower]\n",
    "        \n",
    "        sequential_data = buy+notbuy+maybe # add them together\n",
    "        random.shuffle(sequential_data)  # another shuffle, so the model doesn't get confused with all 1 class then the other.\n",
    "    \n",
    "        Sequential_data = Sequential_data + sequential_data\n",
    "        \n",
    "    random.shuffle(Sequential_data)\n",
    "    X = []; y = []\n",
    "    for seq, target in Sequential_data:  # going over our new sequential data\n",
    "        X.append(seq)  # X is the sequences\n",
    "        y.append(target)  # y is the targets/labels (buys vs sell/notbuy)\n",
    "\n",
    "    return np.array(X).astype(\"float64\"), np.array(y).astype(\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 3  # how long of a preceeding sequence to collect for RNN\n",
    "# FUTURE_PERIOD_PREDICT = 3  # how far into the future are we trying to predict?\n",
    "SHIFT = 150  # how far to shift the data so it can be back testest\n",
    "BATCH_SIZE = 64 # how many batches? Try smaller batch if you're getting OOM (out of memory) errors.\n",
    "EPOCHS = 750 # how many passes through our data\n",
    "\n",
    "\n",
    "tickers_train = [ticker]\n",
    "tickers_test = [ticker]\n",
    "\n",
    "train_x, train_y = process_train(tickers_train, SEQ_LEN,SHIFT)\n",
    "validation_x, validation_y = process_test(tickers_test, SEQ_LEN, SHIFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 1.]]\n",
      "training data length: 315\n",
      "validation data length: 42\n"
     ]
    }
   ],
   "source": [
    "print(train_x[0])\n",
    "print('training data length: %d' % (len(train_x)))\n",
    "print('validation data length: %d' % (len(validation_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "length of train data:  315\n",
      "length of validation data:  42\n",
      "\n",
      "Epoch 1/750\n",
      "5/5 [==============================] - 3s 148ms/step - loss: 1.1403 - accuracy: 0.3714 - val_loss: 1.0992 - val_accuracy: 0.2381\n",
      "Epoch 2/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.1385 - accuracy: 0.3905 - val_loss: 1.0991 - val_accuracy: 0.3810\n",
      "Epoch 3/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.1308 - accuracy: 0.3651 - val_loss: 1.0990 - val_accuracy: 0.3810\n",
      "Epoch 4/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.1254 - accuracy: 0.3841 - val_loss: 1.0989 - val_accuracy: 0.4048\n",
      "Epoch 5/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.1240 - accuracy: 0.3587 - val_loss: 1.0988 - val_accuracy: 0.4048\n",
      "Epoch 6/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.1175 - accuracy: 0.3778 - val_loss: 1.0986 - val_accuracy: 0.4286\n",
      "Epoch 7/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.1042 - accuracy: 0.4095 - val_loss: 1.0985 - val_accuracy: 0.4048\n",
      "Epoch 8/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.1041 - accuracy: 0.3905 - val_loss: 1.0983 - val_accuracy: 0.3810\n",
      "Epoch 9/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.1077 - accuracy: 0.3746 - val_loss: 1.0982 - val_accuracy: 0.3810\n",
      "Epoch 10/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0971 - accuracy: 0.3937 - val_loss: 1.0980 - val_accuracy: 0.3810\n",
      "Epoch 11/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.1045 - accuracy: 0.3841 - val_loss: 1.0979 - val_accuracy: 0.4048\n",
      "Epoch 12/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0853 - accuracy: 0.4286 - val_loss: 1.0977 - val_accuracy: 0.4048\n",
      "Epoch 13/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0875 - accuracy: 0.4159 - val_loss: 1.0976 - val_accuracy: 0.4048\n",
      "Epoch 14/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0849 - accuracy: 0.4063 - val_loss: 1.0974 - val_accuracy: 0.4762\n",
      "Epoch 15/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0836 - accuracy: 0.4190 - val_loss: 1.0972 - val_accuracy: 0.4762\n",
      "Epoch 16/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0781 - accuracy: 0.4254 - val_loss: 1.0971 - val_accuracy: 0.4762\n",
      "Epoch 17/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0743 - accuracy: 0.4095 - val_loss: 1.0969 - val_accuracy: 0.4762\n",
      "Epoch 18/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0760 - accuracy: 0.4127 - val_loss: 1.0967 - val_accuracy: 0.4762\n",
      "Epoch 19/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0709 - accuracy: 0.4508 - val_loss: 1.0966 - val_accuracy: 0.4762\n",
      "Epoch 20/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.0687 - accuracy: 0.4413 - val_loss: 1.0964 - val_accuracy: 0.4762\n",
      "Epoch 21/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0645 - accuracy: 0.4381 - val_loss: 1.0962 - val_accuracy: 0.4762\n",
      "Epoch 22/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0639 - accuracy: 0.4159 - val_loss: 1.0960 - val_accuracy: 0.4762\n",
      "Epoch 23/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0672 - accuracy: 0.4286 - val_loss: 1.0958 - val_accuracy: 0.4762\n",
      "Epoch 24/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0650 - accuracy: 0.4381 - val_loss: 1.0957 - val_accuracy: 0.4762\n",
      "Epoch 25/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0590 - accuracy: 0.4063 - val_loss: 1.0954 - val_accuracy: 0.4762\n",
      "Epoch 26/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0643 - accuracy: 0.4286 - val_loss: 1.0952 - val_accuracy: 0.4762\n",
      "Epoch 27/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0579 - accuracy: 0.4349 - val_loss: 1.0950 - val_accuracy: 0.4762\n",
      "Epoch 28/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0545 - accuracy: 0.4190 - val_loss: 1.0948 - val_accuracy: 0.4762\n",
      "Epoch 29/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0569 - accuracy: 0.4349 - val_loss: 1.0945 - val_accuracy: 0.4524\n",
      "Epoch 30/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0580 - accuracy: 0.4508 - val_loss: 1.0942 - val_accuracy: 0.4524\n",
      "Epoch 31/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0596 - accuracy: 0.4254 - val_loss: 1.0939 - val_accuracy: 0.4524\n",
      "Epoch 32/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0461 - accuracy: 0.4286 - val_loss: 1.0936 - val_accuracy: 0.4524\n",
      "Epoch 33/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0448 - accuracy: 0.4540 - val_loss: 1.0934 - val_accuracy: 0.4762\n",
      "Epoch 34/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0473 - accuracy: 0.4317 - val_loss: 1.0930 - val_accuracy: 0.4762\n",
      "Epoch 35/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0482 - accuracy: 0.4667 - val_loss: 1.0927 - val_accuracy: 0.4762\n",
      "Epoch 36/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0453 - accuracy: 0.4730 - val_loss: 1.0924 - val_accuracy: 0.4762\n",
      "Epoch 37/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0424 - accuracy: 0.4444 - val_loss: 1.0920 - val_accuracy: 0.4762\n",
      "Epoch 38/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0411 - accuracy: 0.4635 - val_loss: 1.0916 - val_accuracy: 0.4762\n",
      "Epoch 39/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0452 - accuracy: 0.4635 - val_loss: 1.0912 - val_accuracy: 0.4762\n",
      "Epoch 40/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0329 - accuracy: 0.4667 - val_loss: 1.0908 - val_accuracy: 0.4762\n",
      "Epoch 41/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0398 - accuracy: 0.4508 - val_loss: 1.0903 - val_accuracy: 0.5000\n",
      "Epoch 42/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0374 - accuracy: 0.4540 - val_loss: 1.0898 - val_accuracy: 0.5238\n",
      "Epoch 43/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0349 - accuracy: 0.4698 - val_loss: 1.0893 - val_accuracy: 0.5476\n",
      "Epoch 44/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0376 - accuracy: 0.4444 - val_loss: 1.0888 - val_accuracy: 0.5476\n",
      "Epoch 45/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0390 - accuracy: 0.4603 - val_loss: 1.0882 - val_accuracy: 0.5476\n",
      "Epoch 46/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0348 - accuracy: 0.4762 - val_loss: 1.0877 - val_accuracy: 0.5476\n",
      "Epoch 47/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0347 - accuracy: 0.4698 - val_loss: 1.0870 - val_accuracy: 0.5476\n",
      "Epoch 48/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0301 - accuracy: 0.4730 - val_loss: 1.0863 - val_accuracy: 0.5476\n",
      "Epoch 49/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0311 - accuracy: 0.4603 - val_loss: 1.0856 - val_accuracy: 0.5476\n",
      "Epoch 50/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0259 - accuracy: 0.4571 - val_loss: 1.0849 - val_accuracy: 0.5476\n",
      "Epoch 51/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0379 - accuracy: 0.4571 - val_loss: 1.0842 - val_accuracy: 0.5476\n",
      "Epoch 52/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0269 - accuracy: 0.4698 - val_loss: 1.0835 - val_accuracy: 0.5476\n",
      "Epoch 53/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0299 - accuracy: 0.4794 - val_loss: 1.0827 - val_accuracy: 0.5476\n",
      "Epoch 54/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0283 - accuracy: 0.4825 - val_loss: 1.0819 - val_accuracy: 0.5476\n",
      "Epoch 55/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0306 - accuracy: 0.4794 - val_loss: 1.0811 - val_accuracy: 0.5476\n",
      "Epoch 56/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0242 - accuracy: 0.4794 - val_loss: 1.0801 - val_accuracy: 0.5476\n",
      "Epoch 57/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0178 - accuracy: 0.4667 - val_loss: 1.0791 - val_accuracy: 0.5476\n",
      "Epoch 58/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0267 - accuracy: 0.4540 - val_loss: 1.0780 - val_accuracy: 0.5476\n",
      "Epoch 59/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0289 - accuracy: 0.4571 - val_loss: 1.0768 - val_accuracy: 0.5476\n",
      "Epoch 60/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0166 - accuracy: 0.4730 - val_loss: 1.0756 - val_accuracy: 0.5476\n",
      "Epoch 61/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0278 - accuracy: 0.4571 - val_loss: 1.0745 - val_accuracy: 0.5476\n",
      "Epoch 62/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0197 - accuracy: 0.4603 - val_loss: 1.0733 - val_accuracy: 0.5476\n",
      "Epoch 63/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0158 - accuracy: 0.4635 - val_loss: 1.0722 - val_accuracy: 0.5476\n",
      "Epoch 64/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0271 - accuracy: 0.4444 - val_loss: 1.0709 - val_accuracy: 0.5476\n",
      "Epoch 65/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0206 - accuracy: 0.4762 - val_loss: 1.0696 - val_accuracy: 0.5476\n",
      "Epoch 66/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0209 - accuracy: 0.4635 - val_loss: 1.0681 - val_accuracy: 0.5476\n",
      "Epoch 67/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0162 - accuracy: 0.4921 - val_loss: 1.0666 - val_accuracy: 0.5476\n",
      "Epoch 68/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0152 - accuracy: 0.4603 - val_loss: 1.0652 - val_accuracy: 0.5476\n",
      "Epoch 69/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0167 - accuracy: 0.4984 - val_loss: 1.0636 - val_accuracy: 0.5714\n",
      "Epoch 70/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0186 - accuracy: 0.4571 - val_loss: 1.0618 - val_accuracy: 0.5714\n",
      "Epoch 71/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0145 - accuracy: 0.4762 - val_loss: 1.0605 - val_accuracy: 0.5714\n",
      "Epoch 72/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0157 - accuracy: 0.4794 - val_loss: 1.0589 - val_accuracy: 0.5714\n",
      "Epoch 73/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0131 - accuracy: 0.4730 - val_loss: 1.0571 - val_accuracy: 0.5714\n",
      "Epoch 74/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0129 - accuracy: 0.4794 - val_loss: 1.0553 - val_accuracy: 0.5714\n",
      "Epoch 75/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0117 - accuracy: 0.4825 - val_loss: 1.0534 - val_accuracy: 0.5714\n",
      "Epoch 76/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0143 - accuracy: 0.4825 - val_loss: 1.0514 - val_accuracy: 0.5714\n",
      "Epoch 77/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0070 - accuracy: 0.4952 - val_loss: 1.0495 - val_accuracy: 0.5714\n",
      "Epoch 78/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0103 - accuracy: 0.4730 - val_loss: 1.0473 - val_accuracy: 0.5714\n",
      "Epoch 79/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0142 - accuracy: 0.4825 - val_loss: 1.0450 - val_accuracy: 0.5714\n",
      "Epoch 80/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0159 - accuracy: 0.4857 - val_loss: 1.0430 - val_accuracy: 0.5714\n",
      "Epoch 81/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0145 - accuracy: 0.4635 - val_loss: 1.0410 - val_accuracy: 0.5714\n",
      "Epoch 82/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0034 - accuracy: 0.4984 - val_loss: 1.0387 - val_accuracy: 0.5714\n",
      "Epoch 83/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0100 - accuracy: 0.4857 - val_loss: 1.0366 - val_accuracy: 0.5714\n",
      "Epoch 84/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0046 - accuracy: 0.5079 - val_loss: 1.0346 - val_accuracy: 0.5714\n",
      "Epoch 85/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0086 - accuracy: 0.4825 - val_loss: 1.0324 - val_accuracy: 0.5714\n",
      "Epoch 86/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0073 - accuracy: 0.4889 - val_loss: 1.0305 - val_accuracy: 0.5714\n",
      "Epoch 87/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0018 - accuracy: 0.4984 - val_loss: 1.0285 - val_accuracy: 0.5714\n",
      "Epoch 88/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0054 - accuracy: 0.4921 - val_loss: 1.0263 - val_accuracy: 0.5714\n",
      "Epoch 89/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9999 - accuracy: 0.4984 - val_loss: 1.0238 - val_accuracy: 0.5714\n",
      "Epoch 90/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9988 - accuracy: 0.4984 - val_loss: 1.0217 - val_accuracy: 0.5952\n",
      "Epoch 91/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0021 - accuracy: 0.5111 - val_loss: 1.0189 - val_accuracy: 0.5952\n",
      "Epoch 92/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0007 - accuracy: 0.5016 - val_loss: 1.0167 - val_accuracy: 0.5952\n",
      "Epoch 93/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0012 - accuracy: 0.5206 - val_loss: 1.0147 - val_accuracy: 0.5952\n",
      "Epoch 94/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0002 - accuracy: 0.4921 - val_loss: 1.0127 - val_accuracy: 0.5952\n",
      "Epoch 95/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0062 - accuracy: 0.4762 - val_loss: 1.0107 - val_accuracy: 0.5952\n",
      "Epoch 96/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9931 - accuracy: 0.4952 - val_loss: 1.0084 - val_accuracy: 0.5952\n",
      "Epoch 97/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0041 - accuracy: 0.4984 - val_loss: 1.0064 - val_accuracy: 0.5952\n",
      "Epoch 98/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9899 - accuracy: 0.5079 - val_loss: 1.0043 - val_accuracy: 0.5952\n",
      "Epoch 99/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9961 - accuracy: 0.4952 - val_loss: 1.0021 - val_accuracy: 0.5952\n",
      "Epoch 100/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9929 - accuracy: 0.4921 - val_loss: 0.9995 - val_accuracy: 0.5952\n",
      "Epoch 101/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9908 - accuracy: 0.5079 - val_loss: 0.9978 - val_accuracy: 0.5952\n",
      "Epoch 102/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0016 - accuracy: 0.4984 - val_loss: 0.9956 - val_accuracy: 0.5952\n",
      "Epoch 103/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9988 - accuracy: 0.5048 - val_loss: 0.9941 - val_accuracy: 0.5952\n",
      "Epoch 104/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9937 - accuracy: 0.4952 - val_loss: 0.9921 - val_accuracy: 0.5714\n",
      "Epoch 105/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9965 - accuracy: 0.5016 - val_loss: 0.9902 - val_accuracy: 0.5952\n",
      "Epoch 106/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9945 - accuracy: 0.4921 - val_loss: 0.9888 - val_accuracy: 0.5952\n",
      "Epoch 107/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9991 - accuracy: 0.5175 - val_loss: 0.9875 - val_accuracy: 0.5952\n",
      "Epoch 108/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9936 - accuracy: 0.5143 - val_loss: 0.9860 - val_accuracy: 0.5952\n",
      "Epoch 109/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9963 - accuracy: 0.4889 - val_loss: 0.9848 - val_accuracy: 0.5952\n",
      "Epoch 110/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9888 - accuracy: 0.4952 - val_loss: 0.9839 - val_accuracy: 0.5952\n",
      "Epoch 111/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9967 - accuracy: 0.4952 - val_loss: 0.9825 - val_accuracy: 0.5952\n",
      "Epoch 112/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9865 - accuracy: 0.5048 - val_loss: 0.9813 - val_accuracy: 0.5952\n",
      "Epoch 113/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9858 - accuracy: 0.5048 - val_loss: 0.9799 - val_accuracy: 0.5952\n",
      "Epoch 114/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9864 - accuracy: 0.5238 - val_loss: 0.9788 - val_accuracy: 0.5952\n",
      "Epoch 115/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9890 - accuracy: 0.5048 - val_loss: 0.9779 - val_accuracy: 0.5952\n",
      "Epoch 116/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9889 - accuracy: 0.4984 - val_loss: 0.9767 - val_accuracy: 0.5952\n",
      "Epoch 117/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9897 - accuracy: 0.5238 - val_loss: 0.9755 - val_accuracy: 0.5952\n",
      "Epoch 118/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9905 - accuracy: 0.5016 - val_loss: 0.9751 - val_accuracy: 0.5952\n",
      "Epoch 119/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9860 - accuracy: 0.5111 - val_loss: 0.9745 - val_accuracy: 0.5952\n",
      "Epoch 120/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9925 - accuracy: 0.4952 - val_loss: 0.9736 - val_accuracy: 0.5952\n",
      "Epoch 121/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9906 - accuracy: 0.4921 - val_loss: 0.9728 - val_accuracy: 0.5952\n",
      "Epoch 122/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9895 - accuracy: 0.5016 - val_loss: 0.9727 - val_accuracy: 0.5952\n",
      "Epoch 123/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9883 - accuracy: 0.5270 - val_loss: 0.9718 - val_accuracy: 0.5714\n",
      "Epoch 124/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9863 - accuracy: 0.4921 - val_loss: 0.9719 - val_accuracy: 0.5714\n",
      "Epoch 125/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9823 - accuracy: 0.5079 - val_loss: 0.9710 - val_accuracy: 0.5714\n",
      "Epoch 126/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9812 - accuracy: 0.5175 - val_loss: 0.9702 - val_accuracy: 0.5714\n",
      "Epoch 127/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9784 - accuracy: 0.5143 - val_loss: 0.9700 - val_accuracy: 0.5714\n",
      "Epoch 128/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9856 - accuracy: 0.5206 - val_loss: 0.9699 - val_accuracy: 0.5714\n",
      "Epoch 129/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9806 - accuracy: 0.5016 - val_loss: 0.9698 - val_accuracy: 0.5476\n",
      "Epoch 130/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9827 - accuracy: 0.5270 - val_loss: 0.9693 - val_accuracy: 0.5476\n",
      "Epoch 131/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9794 - accuracy: 0.5111 - val_loss: 0.9688 - val_accuracy: 0.5238\n",
      "Epoch 132/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9798 - accuracy: 0.5333 - val_loss: 0.9688 - val_accuracy: 0.5238\n",
      "Epoch 133/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9841 - accuracy: 0.5238 - val_loss: 0.9689 - val_accuracy: 0.5238\n",
      "Epoch 134/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9814 - accuracy: 0.4857 - val_loss: 0.9687 - val_accuracy: 0.5238\n",
      "Epoch 135/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9799 - accuracy: 0.5238 - val_loss: 0.9683 - val_accuracy: 0.5238\n",
      "Epoch 136/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9846 - accuracy: 0.4984 - val_loss: 0.9679 - val_accuracy: 0.5238\n",
      "Epoch 137/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9839 - accuracy: 0.4984 - val_loss: 0.9674 - val_accuracy: 0.5238\n",
      "Epoch 138/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9790 - accuracy: 0.5175 - val_loss: 0.9673 - val_accuracy: 0.5238\n",
      "Epoch 139/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9818 - accuracy: 0.5143 - val_loss: 0.9673 - val_accuracy: 0.5238\n",
      "Epoch 140/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9705 - accuracy: 0.5206 - val_loss: 0.9670 - val_accuracy: 0.5238\n",
      "Epoch 141/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9694 - accuracy: 0.5270 - val_loss: 0.9667 - val_accuracy: 0.5238\n",
      "Epoch 142/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9770 - accuracy: 0.4952 - val_loss: 0.9661 - val_accuracy: 0.5238\n",
      "Epoch 143/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9787 - accuracy: 0.5079 - val_loss: 0.9660 - val_accuracy: 0.5238\n",
      "Epoch 144/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9779 - accuracy: 0.5079 - val_loss: 0.9660 - val_accuracy: 0.5238\n",
      "Epoch 145/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9707 - accuracy: 0.5238 - val_loss: 0.9654 - val_accuracy: 0.5238\n",
      "Epoch 146/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9749 - accuracy: 0.4921 - val_loss: 0.9654 - val_accuracy: 0.5238\n",
      "Epoch 147/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9667 - accuracy: 0.5111 - val_loss: 0.9652 - val_accuracy: 0.5238\n",
      "Epoch 148/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9748 - accuracy: 0.5270 - val_loss: 0.9647 - val_accuracy: 0.5238\n",
      "Epoch 149/750\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.9713 - accuracy: 0.5302 - val_loss: 0.9646 - val_accuracy: 0.5238\n",
      "Epoch 150/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9727 - accuracy: 0.5270 - val_loss: 0.9647 - val_accuracy: 0.5238\n",
      "Epoch 151/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9760 - accuracy: 0.5079 - val_loss: 0.9655 - val_accuracy: 0.5238\n",
      "Epoch 152/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9668 - accuracy: 0.5270 - val_loss: 0.9658 - val_accuracy: 0.5238\n",
      "Epoch 153/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9638 - accuracy: 0.5333 - val_loss: 0.9659 - val_accuracy: 0.5238\n",
      "Epoch 154/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9695 - accuracy: 0.5238 - val_loss: 0.9665 - val_accuracy: 0.5238\n",
      "Epoch 155/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9666 - accuracy: 0.5079 - val_loss: 0.9664 - val_accuracy: 0.5238\n",
      "Epoch 156/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9684 - accuracy: 0.5048 - val_loss: 0.9668 - val_accuracy: 0.5238\n",
      "Epoch 157/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9710 - accuracy: 0.5206 - val_loss: 0.9669 - val_accuracy: 0.5238\n",
      "Epoch 158/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9617 - accuracy: 0.5111 - val_loss: 0.9666 - val_accuracy: 0.5238\n",
      "Epoch 159/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9722 - accuracy: 0.5111 - val_loss: 0.9662 - val_accuracy: 0.5238\n",
      "Epoch 160/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9702 - accuracy: 0.4921 - val_loss: 0.9659 - val_accuracy: 0.5238\n",
      "Epoch 161/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9684 - accuracy: 0.5143 - val_loss: 0.9659 - val_accuracy: 0.5238\n",
      "Epoch 162/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9701 - accuracy: 0.5238 - val_loss: 0.9656 - val_accuracy: 0.5238\n",
      "Epoch 163/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9681 - accuracy: 0.5302 - val_loss: 0.9652 - val_accuracy: 0.5238\n",
      "Epoch 164/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9679 - accuracy: 0.5429 - val_loss: 0.9645 - val_accuracy: 0.5238\n",
      "Epoch 165/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9712 - accuracy: 0.5175 - val_loss: 0.9646 - val_accuracy: 0.5238\n",
      "Epoch 166/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9638 - accuracy: 0.5206 - val_loss: 0.9635 - val_accuracy: 0.5238\n",
      "Epoch 167/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9738 - accuracy: 0.5079 - val_loss: 0.9644 - val_accuracy: 0.5238\n",
      "Epoch 168/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9683 - accuracy: 0.5175 - val_loss: 0.9652 - val_accuracy: 0.5238\n",
      "Epoch 169/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9624 - accuracy: 0.5270 - val_loss: 0.9644 - val_accuracy: 0.5238\n",
      "Epoch 170/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9595 - accuracy: 0.5206 - val_loss: 0.9651 - val_accuracy: 0.5238\n",
      "Epoch 171/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9592 - accuracy: 0.5175 - val_loss: 0.9652 - val_accuracy: 0.5238\n",
      "Epoch 172/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9607 - accuracy: 0.5333 - val_loss: 0.9655 - val_accuracy: 0.5238\n",
      "Epoch 173/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9625 - accuracy: 0.5302 - val_loss: 0.9654 - val_accuracy: 0.5238\n",
      "Epoch 174/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9584 - accuracy: 0.5175 - val_loss: 0.9650 - val_accuracy: 0.5238\n",
      "Epoch 175/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9582 - accuracy: 0.5333 - val_loss: 0.9642 - val_accuracy: 0.5238\n",
      "Epoch 176/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9560 - accuracy: 0.5238 - val_loss: 0.9637 - val_accuracy: 0.5238\n",
      "Epoch 177/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9559 - accuracy: 0.5206 - val_loss: 0.9636 - val_accuracy: 0.5238\n",
      "Epoch 178/750\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.9615 - accuracy: 0.5016 - val_loss: 0.9632 - val_accuracy: 0.5238\n",
      "Epoch 179/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9523 - accuracy: 0.5270 - val_loss: 0.9635 - val_accuracy: 0.5238\n",
      "Epoch 180/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.9606 - accuracy: 0.5429 - val_loss: 0.9638 - val_accuracy: 0.5238\n",
      "Epoch 181/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9703 - accuracy: 0.5397 - val_loss: 0.9637 - val_accuracy: 0.5238\n",
      "Epoch 182/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9550 - accuracy: 0.5238 - val_loss: 0.9636 - val_accuracy: 0.5238\n",
      "Epoch 183/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9584 - accuracy: 0.5175 - val_loss: 0.9638 - val_accuracy: 0.5238\n",
      "Epoch 184/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9568 - accuracy: 0.4952 - val_loss: 0.9635 - val_accuracy: 0.5238\n",
      "Epoch 185/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9530 - accuracy: 0.5238 - val_loss: 0.9627 - val_accuracy: 0.5238\n",
      "Epoch 186/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9564 - accuracy: 0.5302 - val_loss: 0.9623 - val_accuracy: 0.5238\n",
      "Epoch 187/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9515 - accuracy: 0.5556 - val_loss: 0.9630 - val_accuracy: 0.5238\n",
      "Epoch 188/750\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.9578 - accuracy: 0.5302 - val_loss: 0.9626 - val_accuracy: 0.5238\n",
      "Epoch 189/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9542 - accuracy: 0.5365 - val_loss: 0.9631 - val_accuracy: 0.5238\n",
      "Epoch 190/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9578 - accuracy: 0.5175 - val_loss: 0.9638 - val_accuracy: 0.5238\n",
      "Epoch 191/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9500 - accuracy: 0.5365 - val_loss: 0.9638 - val_accuracy: 0.5238\n",
      "Epoch 192/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9561 - accuracy: 0.5143 - val_loss: 0.9633 - val_accuracy: 0.5238\n",
      "Epoch 193/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9501 - accuracy: 0.5175 - val_loss: 0.9635 - val_accuracy: 0.5238\n",
      "Epoch 194/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9511 - accuracy: 0.5270 - val_loss: 0.9637 - val_accuracy: 0.5238\n",
      "Epoch 195/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9508 - accuracy: 0.5206 - val_loss: 0.9635 - val_accuracy: 0.5238\n",
      "Epoch 196/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9505 - accuracy: 0.5492 - val_loss: 0.9635 - val_accuracy: 0.5238\n",
      "Epoch 197/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9499 - accuracy: 0.5175 - val_loss: 0.9642 - val_accuracy: 0.5238\n",
      "Epoch 198/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9454 - accuracy: 0.5333 - val_loss: 0.9637 - val_accuracy: 0.5238\n",
      "Epoch 199/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9492 - accuracy: 0.5302 - val_loss: 0.9636 - val_accuracy: 0.5238\n",
      "Epoch 200/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9507 - accuracy: 0.5143 - val_loss: 0.9632 - val_accuracy: 0.5238\n",
      "Epoch 201/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9572 - accuracy: 0.5111 - val_loss: 0.9638 - val_accuracy: 0.5238\n",
      "Epoch 202/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9485 - accuracy: 0.5397 - val_loss: 0.9635 - val_accuracy: 0.5238\n",
      "Epoch 203/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9437 - accuracy: 0.5397 - val_loss: 0.9632 - val_accuracy: 0.5238\n",
      "Epoch 204/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9479 - accuracy: 0.5143 - val_loss: 0.9630 - val_accuracy: 0.5238\n",
      "Epoch 205/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9510 - accuracy: 0.5175 - val_loss: 0.9629 - val_accuracy: 0.5238\n",
      "Epoch 206/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9510 - accuracy: 0.5302 - val_loss: 0.9627 - val_accuracy: 0.5238\n",
      "Epoch 207/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9543 - accuracy: 0.5206 - val_loss: 0.9632 - val_accuracy: 0.5238\n",
      "Epoch 208/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9422 - accuracy: 0.5556 - val_loss: 0.9633 - val_accuracy: 0.5238\n",
      "Epoch 209/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9435 - accuracy: 0.5333 - val_loss: 0.9635 - val_accuracy: 0.5238\n",
      "Epoch 210/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9443 - accuracy: 0.5492 - val_loss: 0.9630 - val_accuracy: 0.5238\n",
      "Epoch 211/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9466 - accuracy: 0.5143 - val_loss: 0.9627 - val_accuracy: 0.5238\n",
      "Epoch 212/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9431 - accuracy: 0.5365 - val_loss: 0.9626 - val_accuracy: 0.5238\n",
      "Epoch 213/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9580 - accuracy: 0.5365 - val_loss: 0.9623 - val_accuracy: 0.5238\n",
      "Epoch 214/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9416 - accuracy: 0.5429 - val_loss: 0.9613 - val_accuracy: 0.5238\n",
      "Epoch 215/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9447 - accuracy: 0.5270 - val_loss: 0.9611 - val_accuracy: 0.5238\n",
      "Epoch 216/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9435 - accuracy: 0.5270 - val_loss: 0.9607 - val_accuracy: 0.5238\n",
      "Epoch 217/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9457 - accuracy: 0.5302 - val_loss: 0.9605 - val_accuracy: 0.5238\n",
      "Epoch 218/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9406 - accuracy: 0.5238 - val_loss: 0.9600 - val_accuracy: 0.5238\n",
      "Epoch 219/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9452 - accuracy: 0.5556 - val_loss: 0.9600 - val_accuracy: 0.5238\n",
      "Epoch 220/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9350 - accuracy: 0.5270 - val_loss: 0.9604 - val_accuracy: 0.5238\n",
      "Epoch 221/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9350 - accuracy: 0.5302 - val_loss: 0.9603 - val_accuracy: 0.5238\n",
      "Epoch 222/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9398 - accuracy: 0.5365 - val_loss: 0.9599 - val_accuracy: 0.5238\n",
      "Epoch 223/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9448 - accuracy: 0.5270 - val_loss: 0.9601 - val_accuracy: 0.5238\n",
      "Epoch 224/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9423 - accuracy: 0.5206 - val_loss: 0.9598 - val_accuracy: 0.5238\n",
      "Epoch 225/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9375 - accuracy: 0.5397 - val_loss: 0.9596 - val_accuracy: 0.5238\n",
      "Epoch 226/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9365 - accuracy: 0.5365 - val_loss: 0.9590 - val_accuracy: 0.5238\n",
      "Epoch 227/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9383 - accuracy: 0.5397 - val_loss: 0.9589 - val_accuracy: 0.5238\n",
      "Epoch 228/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9369 - accuracy: 0.5429 - val_loss: 0.9590 - val_accuracy: 0.5238\n",
      "Epoch 229/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9365 - accuracy: 0.5397 - val_loss: 0.9581 - val_accuracy: 0.5238\n",
      "Epoch 230/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9395 - accuracy: 0.5556 - val_loss: 0.9586 - val_accuracy: 0.5238\n",
      "Epoch 231/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9337 - accuracy: 0.5492 - val_loss: 0.9586 - val_accuracy: 0.5238\n",
      "Epoch 232/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9363 - accuracy: 0.5302 - val_loss: 0.9583 - val_accuracy: 0.5238\n",
      "Epoch 233/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9392 - accuracy: 0.5238 - val_loss: 0.9591 - val_accuracy: 0.5238\n",
      "Epoch 234/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9382 - accuracy: 0.5333 - val_loss: 0.9581 - val_accuracy: 0.5238\n",
      "Epoch 235/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9410 - accuracy: 0.5524 - val_loss: 0.9589 - val_accuracy: 0.5238\n",
      "Epoch 236/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9273 - accuracy: 0.5429 - val_loss: 0.9583 - val_accuracy: 0.5238\n",
      "Epoch 237/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9382 - accuracy: 0.5333 - val_loss: 0.9577 - val_accuracy: 0.5238\n",
      "Epoch 238/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9291 - accuracy: 0.5397 - val_loss: 0.9577 - val_accuracy: 0.5238\n",
      "Epoch 239/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9344 - accuracy: 0.5175 - val_loss: 0.9580 - val_accuracy: 0.5238\n",
      "Epoch 240/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9346 - accuracy: 0.5492 - val_loss: 0.9584 - val_accuracy: 0.5238\n",
      "Epoch 241/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9303 - accuracy: 0.5524 - val_loss: 0.9576 - val_accuracy: 0.5238\n",
      "Epoch 242/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9272 - accuracy: 0.5587 - val_loss: 0.9578 - val_accuracy: 0.5238\n",
      "Epoch 243/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9342 - accuracy: 0.5429 - val_loss: 0.9582 - val_accuracy: 0.5238\n",
      "Epoch 244/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9264 - accuracy: 0.5492 - val_loss: 0.9576 - val_accuracy: 0.5476\n",
      "Epoch 245/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9307 - accuracy: 0.5111 - val_loss: 0.9575 - val_accuracy: 0.5476\n",
      "Epoch 246/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9305 - accuracy: 0.5460 - val_loss: 0.9574 - val_accuracy: 0.5238\n",
      "Epoch 247/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9309 - accuracy: 0.5619 - val_loss: 0.9569 - val_accuracy: 0.5000\n",
      "Epoch 248/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9293 - accuracy: 0.5270 - val_loss: 0.9567 - val_accuracy: 0.5238\n",
      "Epoch 249/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9303 - accuracy: 0.5429 - val_loss: 0.9575 - val_accuracy: 0.5238\n",
      "Epoch 250/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9275 - accuracy: 0.5429 - val_loss: 0.9581 - val_accuracy: 0.5238\n",
      "Epoch 251/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9242 - accuracy: 0.5587 - val_loss: 0.9580 - val_accuracy: 0.5238\n",
      "Epoch 252/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9250 - accuracy: 0.5746 - val_loss: 0.9573 - val_accuracy: 0.5238\n",
      "Epoch 253/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9287 - accuracy: 0.5429 - val_loss: 0.9573 - val_accuracy: 0.5238\n",
      "Epoch 254/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9259 - accuracy: 0.5651 - val_loss: 0.9568 - val_accuracy: 0.5238\n",
      "Epoch 255/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9285 - accuracy: 0.5460 - val_loss: 0.9562 - val_accuracy: 0.5238\n",
      "Epoch 256/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9312 - accuracy: 0.5524 - val_loss: 0.9562 - val_accuracy: 0.5238\n",
      "Epoch 257/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9297 - accuracy: 0.5270 - val_loss: 0.9559 - val_accuracy: 0.5476\n",
      "Epoch 258/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9204 - accuracy: 0.5556 - val_loss: 0.9556 - val_accuracy: 0.5476\n",
      "Epoch 259/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9262 - accuracy: 0.5492 - val_loss: 0.9561 - val_accuracy: 0.5476\n",
      "Epoch 260/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9246 - accuracy: 0.5460 - val_loss: 0.9553 - val_accuracy: 0.5476\n",
      "Epoch 261/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9217 - accuracy: 0.5619 - val_loss: 0.9552 - val_accuracy: 0.5476\n",
      "Epoch 262/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9253 - accuracy: 0.5746 - val_loss: 0.9555 - val_accuracy: 0.5476\n",
      "Epoch 263/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9309 - accuracy: 0.5587 - val_loss: 0.9561 - val_accuracy: 0.5476\n",
      "Epoch 264/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9254 - accuracy: 0.5143 - val_loss: 0.9557 - val_accuracy: 0.5476\n",
      "Epoch 265/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9280 - accuracy: 0.5460 - val_loss: 0.9557 - val_accuracy: 0.5476\n",
      "Epoch 266/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9240 - accuracy: 0.5302 - val_loss: 0.9554 - val_accuracy: 0.5476\n",
      "Epoch 267/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9208 - accuracy: 0.5619 - val_loss: 0.9554 - val_accuracy: 0.5476\n",
      "Epoch 268/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9293 - accuracy: 0.5587 - val_loss: 0.9551 - val_accuracy: 0.5476\n",
      "Epoch 269/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9169 - accuracy: 0.5492 - val_loss: 0.9553 - val_accuracy: 0.5476\n",
      "Epoch 270/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9195 - accuracy: 0.5651 - val_loss: 0.9554 - val_accuracy: 0.5476\n",
      "Epoch 271/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9183 - accuracy: 0.5651 - val_loss: 0.9555 - val_accuracy: 0.5476\n",
      "Epoch 272/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9202 - accuracy: 0.5524 - val_loss: 0.9554 - val_accuracy: 0.5476\n",
      "Epoch 273/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9194 - accuracy: 0.5651 - val_loss: 0.9550 - val_accuracy: 0.5476\n",
      "Epoch 274/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9245 - accuracy: 0.5587 - val_loss: 0.9550 - val_accuracy: 0.5476\n",
      "Epoch 275/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9262 - accuracy: 0.5429 - val_loss: 0.9545 - val_accuracy: 0.5476\n",
      "Epoch 276/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9193 - accuracy: 0.5524 - val_loss: 0.9551 - val_accuracy: 0.5476\n",
      "Epoch 277/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9140 - accuracy: 0.5651 - val_loss: 0.9554 - val_accuracy: 0.5476\n",
      "Epoch 278/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9089 - accuracy: 0.5778 - val_loss: 0.9551 - val_accuracy: 0.5476\n",
      "Epoch 279/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9095 - accuracy: 0.5587 - val_loss: 0.9550 - val_accuracy: 0.5476\n",
      "Epoch 280/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9062 - accuracy: 0.5746 - val_loss: 0.9548 - val_accuracy: 0.5476\n",
      "Epoch 281/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9153 - accuracy: 0.5556 - val_loss: 0.9542 - val_accuracy: 0.5476\n",
      "Epoch 282/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9228 - accuracy: 0.5492 - val_loss: 0.9545 - val_accuracy: 0.5476\n",
      "Epoch 283/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9125 - accuracy: 0.5460 - val_loss: 0.9546 - val_accuracy: 0.5476\n",
      "Epoch 284/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9189 - accuracy: 0.5556 - val_loss: 0.9543 - val_accuracy: 0.5476\n",
      "Epoch 285/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9259 - accuracy: 0.5460 - val_loss: 0.9542 - val_accuracy: 0.5476\n",
      "Epoch 286/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.9194 - accuracy: 0.5651 - val_loss: 0.9546 - val_accuracy: 0.5476\n",
      "Epoch 287/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.9111 - accuracy: 0.5746 - val_loss: 0.9549 - val_accuracy: 0.5476\n",
      "Epoch 288/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9113 - accuracy: 0.5683 - val_loss: 0.9551 - val_accuracy: 0.5476\n",
      "Epoch 289/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9102 - accuracy: 0.5556 - val_loss: 0.9549 - val_accuracy: 0.5476\n",
      "Epoch 290/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9101 - accuracy: 0.5746 - val_loss: 0.9547 - val_accuracy: 0.5476\n",
      "Epoch 291/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 10ms/step - loss: 0.9131 - accuracy: 0.5778 - val_loss: 0.9546 - val_accuracy: 0.5476\n",
      "Epoch 292/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9104 - accuracy: 0.5683 - val_loss: 0.9546 - val_accuracy: 0.5476\n",
      "Epoch 293/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9096 - accuracy: 0.5683 - val_loss: 0.9551 - val_accuracy: 0.5476\n",
      "Epoch 294/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9037 - accuracy: 0.5810 - val_loss: 0.9553 - val_accuracy: 0.5476\n",
      "Epoch 295/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.9042 - accuracy: 0.5873 - val_loss: 0.9548 - val_accuracy: 0.5476\n",
      "Epoch 296/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9182 - accuracy: 0.5778 - val_loss: 0.9548 - val_accuracy: 0.5476\n",
      "Epoch 297/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9070 - accuracy: 0.5524 - val_loss: 0.9548 - val_accuracy: 0.5476\n",
      "Epoch 298/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9101 - accuracy: 0.5778 - val_loss: 0.9550 - val_accuracy: 0.5476\n",
      "Epoch 299/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9092 - accuracy: 0.5619 - val_loss: 0.9547 - val_accuracy: 0.5476\n",
      "Epoch 300/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9102 - accuracy: 0.5746 - val_loss: 0.9552 - val_accuracy: 0.5476\n",
      "Epoch 301/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9085 - accuracy: 0.5746 - val_loss: 0.9547 - val_accuracy: 0.5476\n",
      "Epoch 302/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9059 - accuracy: 0.5905 - val_loss: 0.9539 - val_accuracy: 0.5476\n",
      "Epoch 303/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9114 - accuracy: 0.5778 - val_loss: 0.9531 - val_accuracy: 0.5476\n",
      "Epoch 304/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9060 - accuracy: 0.5841 - val_loss: 0.9535 - val_accuracy: 0.5476\n",
      "Epoch 305/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9044 - accuracy: 0.5778 - val_loss: 0.9529 - val_accuracy: 0.5476\n",
      "Epoch 306/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9150 - accuracy: 0.5651 - val_loss: 0.9527 - val_accuracy: 0.5476\n",
      "Epoch 307/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9108 - accuracy: 0.5746 - val_loss: 0.9528 - val_accuracy: 0.5476\n",
      "Epoch 308/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9023 - accuracy: 0.5651 - val_loss: 0.9528 - val_accuracy: 0.5476\n",
      "Epoch 309/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9082 - accuracy: 0.5619 - val_loss: 0.9519 - val_accuracy: 0.5476\n",
      "Epoch 310/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9081 - accuracy: 0.5524 - val_loss: 0.9522 - val_accuracy: 0.5476\n",
      "Epoch 311/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9093 - accuracy: 0.5587 - val_loss: 0.9524 - val_accuracy: 0.5476\n",
      "Epoch 312/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9099 - accuracy: 0.5651 - val_loss: 0.9525 - val_accuracy: 0.5476\n",
      "Epoch 313/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9087 - accuracy: 0.5683 - val_loss: 0.9532 - val_accuracy: 0.5476\n",
      "Epoch 314/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8971 - accuracy: 0.5810 - val_loss: 0.9529 - val_accuracy: 0.5476\n",
      "Epoch 315/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9086 - accuracy: 0.5651 - val_loss: 0.9527 - val_accuracy: 0.5476\n",
      "Epoch 316/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9115 - accuracy: 0.5683 - val_loss: 0.9526 - val_accuracy: 0.5476\n",
      "Epoch 317/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9037 - accuracy: 0.5746 - val_loss: 0.9529 - val_accuracy: 0.5476\n",
      "Epoch 318/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8929 - accuracy: 0.5937 - val_loss: 0.9529 - val_accuracy: 0.5476\n",
      "Epoch 319/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8933 - accuracy: 0.5873 - val_loss: 0.9530 - val_accuracy: 0.5476\n",
      "Epoch 320/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9035 - accuracy: 0.5810 - val_loss: 0.9532 - val_accuracy: 0.5476\n",
      "Epoch 321/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9029 - accuracy: 0.5810 - val_loss: 0.9528 - val_accuracy: 0.5476\n",
      "Epoch 322/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9022 - accuracy: 0.5651 - val_loss: 0.9523 - val_accuracy: 0.5476\n",
      "Epoch 323/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8961 - accuracy: 0.5619 - val_loss: 0.9519 - val_accuracy: 0.5476\n",
      "Epoch 324/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9058 - accuracy: 0.5556 - val_loss: 0.9515 - val_accuracy: 0.5476\n",
      "Epoch 325/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9023 - accuracy: 0.5746 - val_loss: 0.9514 - val_accuracy: 0.5476\n",
      "Epoch 326/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9004 - accuracy: 0.5619 - val_loss: 0.9519 - val_accuracy: 0.5476\n",
      "Epoch 327/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8928 - accuracy: 0.5746 - val_loss: 0.9514 - val_accuracy: 0.5476\n",
      "Epoch 328/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8997 - accuracy: 0.5778 - val_loss: 0.9517 - val_accuracy: 0.5238\n",
      "Epoch 329/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8942 - accuracy: 0.5873 - val_loss: 0.9517 - val_accuracy: 0.5238\n",
      "Epoch 330/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9097 - accuracy: 0.5746 - val_loss: 0.9521 - val_accuracy: 0.5238\n",
      "Epoch 331/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9063 - accuracy: 0.5778 - val_loss: 0.9525 - val_accuracy: 0.5238\n",
      "Epoch 332/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8918 - accuracy: 0.5746 - val_loss: 0.9522 - val_accuracy: 0.5238\n",
      "Epoch 333/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8988 - accuracy: 0.5841 - val_loss: 0.9525 - val_accuracy: 0.5238\n",
      "Epoch 334/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8987 - accuracy: 0.5810 - val_loss: 0.9517 - val_accuracy: 0.5238\n",
      "Epoch 335/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8990 - accuracy: 0.5841 - val_loss: 0.9520 - val_accuracy: 0.5238\n",
      "Epoch 336/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8915 - accuracy: 0.5746 - val_loss: 0.9520 - val_accuracy: 0.5238\n",
      "Epoch 337/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8895 - accuracy: 0.5746 - val_loss: 0.9527 - val_accuracy: 0.5238\n",
      "Epoch 338/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8884 - accuracy: 0.5841 - val_loss: 0.9527 - val_accuracy: 0.5238\n",
      "Epoch 339/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8964 - accuracy: 0.5905 - val_loss: 0.9522 - val_accuracy: 0.5238\n",
      "Epoch 340/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8975 - accuracy: 0.5746 - val_loss: 0.9522 - val_accuracy: 0.5238\n",
      "Epoch 341/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8959 - accuracy: 0.5778 - val_loss: 0.9515 - val_accuracy: 0.5238\n",
      "Epoch 342/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8918 - accuracy: 0.5937 - val_loss: 0.9510 - val_accuracy: 0.5238\n",
      "Epoch 343/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8907 - accuracy: 0.5937 - val_loss: 0.9501 - val_accuracy: 0.5238\n",
      "Epoch 344/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8985 - accuracy: 0.5429 - val_loss: 0.9494 - val_accuracy: 0.5238\n",
      "Epoch 345/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8895 - accuracy: 0.5841 - val_loss: 0.9497 - val_accuracy: 0.5238\n",
      "Epoch 346/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8941 - accuracy: 0.5714 - val_loss: 0.9500 - val_accuracy: 0.5238\n",
      "Epoch 347/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8911 - accuracy: 0.5683 - val_loss: 0.9502 - val_accuracy: 0.5238\n",
      "Epoch 348/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8905 - accuracy: 0.5873 - val_loss: 0.9504 - val_accuracy: 0.5238\n",
      "Epoch 349/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8969 - accuracy: 0.5778 - val_loss: 0.9503 - val_accuracy: 0.5238\n",
      "Epoch 350/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8938 - accuracy: 0.5873 - val_loss: 0.9502 - val_accuracy: 0.5238\n",
      "Epoch 351/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8908 - accuracy: 0.5714 - val_loss: 0.9504 - val_accuracy: 0.5238\n",
      "Epoch 352/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8919 - accuracy: 0.5841 - val_loss: 0.9507 - val_accuracy: 0.5238\n",
      "Epoch 353/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8863 - accuracy: 0.5937 - val_loss: 0.9506 - val_accuracy: 0.5238\n",
      "Epoch 354/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8897 - accuracy: 0.5873 - val_loss: 0.9502 - val_accuracy: 0.5476\n",
      "Epoch 355/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8940 - accuracy: 0.5841 - val_loss: 0.9501 - val_accuracy: 0.5476\n",
      "Epoch 356/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8879 - accuracy: 0.5873 - val_loss: 0.9501 - val_accuracy: 0.5476\n",
      "Epoch 357/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8894 - accuracy: 0.5683 - val_loss: 0.9495 - val_accuracy: 0.5476\n",
      "Epoch 358/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8930 - accuracy: 0.6063 - val_loss: 0.9492 - val_accuracy: 0.5476\n",
      "Epoch 359/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8944 - accuracy: 0.5905 - val_loss: 0.9493 - val_accuracy: 0.5476\n",
      "Epoch 360/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8969 - accuracy: 0.5619 - val_loss: 0.9500 - val_accuracy: 0.5476\n",
      "Epoch 361/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8895 - accuracy: 0.5873 - val_loss: 0.9497 - val_accuracy: 0.5476\n",
      "Epoch 362/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8936 - accuracy: 0.5683 - val_loss: 0.9496 - val_accuracy: 0.5476\n",
      "Epoch 363/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8854 - accuracy: 0.5810 - val_loss: 0.9492 - val_accuracy: 0.5476\n",
      "Epoch 364/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8811 - accuracy: 0.6000 - val_loss: 0.9491 - val_accuracy: 0.5476\n",
      "Epoch 365/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8890 - accuracy: 0.5810 - val_loss: 0.9484 - val_accuracy: 0.5476\n",
      "Epoch 366/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8892 - accuracy: 0.5873 - val_loss: 0.9490 - val_accuracy: 0.5476\n",
      "Epoch 367/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8851 - accuracy: 0.5714 - val_loss: 0.9495 - val_accuracy: 0.5476\n",
      "Epoch 368/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8838 - accuracy: 0.5841 - val_loss: 0.9489 - val_accuracy: 0.5476\n",
      "Epoch 369/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8833 - accuracy: 0.5778 - val_loss: 0.9486 - val_accuracy: 0.5476\n",
      "Epoch 370/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8781 - accuracy: 0.6190 - val_loss: 0.9493 - val_accuracy: 0.5238\n",
      "Epoch 371/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8858 - accuracy: 0.5778 - val_loss: 0.9489 - val_accuracy: 0.5238\n",
      "Epoch 372/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8779 - accuracy: 0.6095 - val_loss: 0.9487 - val_accuracy: 0.5238\n",
      "Epoch 373/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8855 - accuracy: 0.5905 - val_loss: 0.9485 - val_accuracy: 0.5238\n",
      "Epoch 374/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8885 - accuracy: 0.5556 - val_loss: 0.9486 - val_accuracy: 0.5238\n",
      "Epoch 375/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8844 - accuracy: 0.5778 - val_loss: 0.9487 - val_accuracy: 0.5238\n",
      "Epoch 376/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8767 - accuracy: 0.5873 - val_loss: 0.9487 - val_accuracy: 0.5238\n",
      "Epoch 377/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8778 - accuracy: 0.6095 - val_loss: 0.9481 - val_accuracy: 0.5238\n",
      "Epoch 378/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8838 - accuracy: 0.5746 - val_loss: 0.9484 - val_accuracy: 0.5238\n",
      "Epoch 379/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8824 - accuracy: 0.5937 - val_loss: 0.9488 - val_accuracy: 0.5238\n",
      "Epoch 380/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8838 - accuracy: 0.6095 - val_loss: 0.9486 - val_accuracy: 0.5238\n",
      "Epoch 381/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8775 - accuracy: 0.6127 - val_loss: 0.9481 - val_accuracy: 0.5238\n",
      "Epoch 382/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8898 - accuracy: 0.5905 - val_loss: 0.9478 - val_accuracy: 0.5238\n",
      "Epoch 383/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8816 - accuracy: 0.5778 - val_loss: 0.9473 - val_accuracy: 0.5238\n",
      "Epoch 384/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8771 - accuracy: 0.5746 - val_loss: 0.9471 - val_accuracy: 0.5238\n",
      "Epoch 385/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8747 - accuracy: 0.5905 - val_loss: 0.9467 - val_accuracy: 0.5238\n",
      "Epoch 386/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8883 - accuracy: 0.5841 - val_loss: 0.9470 - val_accuracy: 0.5238\n",
      "Epoch 387/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8918 - accuracy: 0.5810 - val_loss: 0.9471 - val_accuracy: 0.5238\n",
      "Epoch 388/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8826 - accuracy: 0.5937 - val_loss: 0.9479 - val_accuracy: 0.5238\n",
      "Epoch 389/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8838 - accuracy: 0.5746 - val_loss: 0.9479 - val_accuracy: 0.5238\n",
      "Epoch 390/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8829 - accuracy: 0.6032 - val_loss: 0.9482 - val_accuracy: 0.5238\n",
      "Epoch 391/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8741 - accuracy: 0.5937 - val_loss: 0.9474 - val_accuracy: 0.5238\n",
      "Epoch 392/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8877 - accuracy: 0.5651 - val_loss: 0.9480 - val_accuracy: 0.5238\n",
      "Epoch 393/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8672 - accuracy: 0.6095 - val_loss: 0.9487 - val_accuracy: 0.5238\n",
      "Epoch 394/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8763 - accuracy: 0.5937 - val_loss: 0.9486 - val_accuracy: 0.5238\n",
      "Epoch 395/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8739 - accuracy: 0.5746 - val_loss: 0.9476 - val_accuracy: 0.5238\n",
      "Epoch 396/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8766 - accuracy: 0.5937 - val_loss: 0.9476 - val_accuracy: 0.5238\n",
      "Epoch 397/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8849 - accuracy: 0.5873 - val_loss: 0.9473 - val_accuracy: 0.5238\n",
      "Epoch 398/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8825 - accuracy: 0.5841 - val_loss: 0.9474 - val_accuracy: 0.5238\n",
      "Epoch 399/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8726 - accuracy: 0.6032 - val_loss: 0.9482 - val_accuracy: 0.5238\n",
      "Epoch 400/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8819 - accuracy: 0.5810 - val_loss: 0.9488 - val_accuracy: 0.5238\n",
      "Epoch 401/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8791 - accuracy: 0.6063 - val_loss: 0.9478 - val_accuracy: 0.5238\n",
      "Epoch 402/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8804 - accuracy: 0.5683 - val_loss: 0.9477 - val_accuracy: 0.5238\n",
      "Epoch 403/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8759 - accuracy: 0.6063 - val_loss: 0.9473 - val_accuracy: 0.5238\n",
      "Epoch 404/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8662 - accuracy: 0.5968 - val_loss: 0.9477 - val_accuracy: 0.5238\n",
      "Epoch 405/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8817 - accuracy: 0.5810 - val_loss: 0.9470 - val_accuracy: 0.5238\n",
      "Epoch 406/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8695 - accuracy: 0.6000 - val_loss: 0.9472 - val_accuracy: 0.5238\n",
      "Epoch 407/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8786 - accuracy: 0.6032 - val_loss: 0.9471 - val_accuracy: 0.5238\n",
      "Epoch 408/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8825 - accuracy: 0.5619 - val_loss: 0.9468 - val_accuracy: 0.5238\n",
      "Epoch 409/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8797 - accuracy: 0.5683 - val_loss: 0.9469 - val_accuracy: 0.5476\n",
      "Epoch 410/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8734 - accuracy: 0.5778 - val_loss: 0.9477 - val_accuracy: 0.5238\n",
      "Epoch 411/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8674 - accuracy: 0.5968 - val_loss: 0.9477 - val_accuracy: 0.5476\n",
      "Epoch 412/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8817 - accuracy: 0.5810 - val_loss: 0.9474 - val_accuracy: 0.5476\n",
      "Epoch 413/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8721 - accuracy: 0.5905 - val_loss: 0.9472 - val_accuracy: 0.5238\n",
      "Epoch 414/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8692 - accuracy: 0.5746 - val_loss: 0.9471 - val_accuracy: 0.5238\n",
      "Epoch 415/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8699 - accuracy: 0.6000 - val_loss: 0.9467 - val_accuracy: 0.5238\n",
      "Epoch 416/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8725 - accuracy: 0.6032 - val_loss: 0.9468 - val_accuracy: 0.5238\n",
      "Epoch 417/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8735 - accuracy: 0.5905 - val_loss: 0.9459 - val_accuracy: 0.5238\n",
      "Epoch 418/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8717 - accuracy: 0.5714 - val_loss: 0.9460 - val_accuracy: 0.5238\n",
      "Epoch 419/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8749 - accuracy: 0.5841 - val_loss: 0.9461 - val_accuracy: 0.5238\n",
      "Epoch 420/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8752 - accuracy: 0.5714 - val_loss: 0.9461 - val_accuracy: 0.5238\n",
      "Epoch 421/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8673 - accuracy: 0.5873 - val_loss: 0.9461 - val_accuracy: 0.5238\n",
      "Epoch 422/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8664 - accuracy: 0.5841 - val_loss: 0.9461 - val_accuracy: 0.5238\n",
      "Epoch 423/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8677 - accuracy: 0.5905 - val_loss: 0.9459 - val_accuracy: 0.5238\n",
      "Epoch 424/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8761 - accuracy: 0.5810 - val_loss: 0.9453 - val_accuracy: 0.5476\n",
      "Epoch 425/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8644 - accuracy: 0.6032 - val_loss: 0.9458 - val_accuracy: 0.5238\n",
      "Epoch 426/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8736 - accuracy: 0.5810 - val_loss: 0.9468 - val_accuracy: 0.5238\n",
      "Epoch 427/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8667 - accuracy: 0.5714 - val_loss: 0.9464 - val_accuracy: 0.5238\n",
      "Epoch 428/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8672 - accuracy: 0.5937 - val_loss: 0.9465 - val_accuracy: 0.5238\n",
      "Epoch 429/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8676 - accuracy: 0.5905 - val_loss: 0.9470 - val_accuracy: 0.5238\n",
      "Epoch 430/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8691 - accuracy: 0.6063 - val_loss: 0.9468 - val_accuracy: 0.5238\n",
      "Epoch 431/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8727 - accuracy: 0.5778 - val_loss: 0.9469 - val_accuracy: 0.5238\n",
      "Epoch 432/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8708 - accuracy: 0.6095 - val_loss: 0.9469 - val_accuracy: 0.5238\n",
      "Epoch 433/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8713 - accuracy: 0.5873 - val_loss: 0.9469 - val_accuracy: 0.5238\n",
      "Epoch 434/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8729 - accuracy: 0.6063 - val_loss: 0.9459 - val_accuracy: 0.5476\n",
      "Epoch 435/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8685 - accuracy: 0.5937 - val_loss: 0.9469 - val_accuracy: 0.5238\n",
      "Epoch 436/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8624 - accuracy: 0.5968 - val_loss: 0.9472 - val_accuracy: 0.5238\n",
      "Epoch 437/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8605 - accuracy: 0.6127 - val_loss: 0.9469 - val_accuracy: 0.5238\n",
      "Epoch 438/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8641 - accuracy: 0.6032 - val_loss: 0.9467 - val_accuracy: 0.5476\n",
      "Epoch 439/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8689 - accuracy: 0.6063 - val_loss: 0.9467 - val_accuracy: 0.5476\n",
      "Epoch 440/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8709 - accuracy: 0.6159 - val_loss: 0.9464 - val_accuracy: 0.5476\n",
      "Epoch 441/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8597 - accuracy: 0.5968 - val_loss: 0.9467 - val_accuracy: 0.5476\n",
      "Epoch 442/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8719 - accuracy: 0.6127 - val_loss: 0.9461 - val_accuracy: 0.5476\n",
      "Epoch 443/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8658 - accuracy: 0.5841 - val_loss: 0.9463 - val_accuracy: 0.5238\n",
      "Epoch 444/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8690 - accuracy: 0.5746 - val_loss: 0.9468 - val_accuracy: 0.5238\n",
      "Epoch 445/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8622 - accuracy: 0.5937 - val_loss: 0.9464 - val_accuracy: 0.5238\n",
      "Epoch 446/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8701 - accuracy: 0.5841 - val_loss: 0.9467 - val_accuracy: 0.5238\n",
      "Epoch 447/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8642 - accuracy: 0.6032 - val_loss: 0.9467 - val_accuracy: 0.5238\n",
      "Epoch 448/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8643 - accuracy: 0.5810 - val_loss: 0.9466 - val_accuracy: 0.5238\n",
      "Epoch 449/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8670 - accuracy: 0.6000 - val_loss: 0.9459 - val_accuracy: 0.5238\n",
      "Epoch 450/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8658 - accuracy: 0.6159 - val_loss: 0.9458 - val_accuracy: 0.5238\n",
      "Epoch 451/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8637 - accuracy: 0.6159 - val_loss: 0.9455 - val_accuracy: 0.5238\n",
      "Epoch 452/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8575 - accuracy: 0.5968 - val_loss: 0.9457 - val_accuracy: 0.5238\n",
      "Epoch 453/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8717 - accuracy: 0.6000 - val_loss: 0.9458 - val_accuracy: 0.5238\n",
      "Epoch 454/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8548 - accuracy: 0.6190 - val_loss: 0.9454 - val_accuracy: 0.5238\n",
      "Epoch 455/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8537 - accuracy: 0.6063 - val_loss: 0.9447 - val_accuracy: 0.5238\n",
      "Epoch 456/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8641 - accuracy: 0.6063 - val_loss: 0.9454 - val_accuracy: 0.5238\n",
      "Epoch 457/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8724 - accuracy: 0.5873 - val_loss: 0.9458 - val_accuracy: 0.5238\n",
      "Epoch 458/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8609 - accuracy: 0.6095 - val_loss: 0.9465 - val_accuracy: 0.5238\n",
      "Epoch 459/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8605 - accuracy: 0.5968 - val_loss: 0.9461 - val_accuracy: 0.5238\n",
      "Epoch 460/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8625 - accuracy: 0.6159 - val_loss: 0.9462 - val_accuracy: 0.5238\n",
      "Epoch 461/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8565 - accuracy: 0.6000 - val_loss: 0.9464 - val_accuracy: 0.5238\n",
      "Epoch 462/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8593 - accuracy: 0.6381 - val_loss: 0.9457 - val_accuracy: 0.5238\n",
      "Epoch 463/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8587 - accuracy: 0.5873 - val_loss: 0.9454 - val_accuracy: 0.5476\n",
      "Epoch 464/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8575 - accuracy: 0.6190 - val_loss: 0.9464 - val_accuracy: 0.5238\n",
      "Epoch 465/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8602 - accuracy: 0.6095 - val_loss: 0.9466 - val_accuracy: 0.5238\n",
      "Epoch 466/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8665 - accuracy: 0.5841 - val_loss: 0.9464 - val_accuracy: 0.5238\n",
      "Epoch 467/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8598 - accuracy: 0.5873 - val_loss: 0.9465 - val_accuracy: 0.5238\n",
      "Epoch 468/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8726 - accuracy: 0.5841 - val_loss: 0.9469 - val_accuracy: 0.5238\n",
      "Epoch 469/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8587 - accuracy: 0.5937 - val_loss: 0.9463 - val_accuracy: 0.5238\n",
      "Epoch 470/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8634 - accuracy: 0.5968 - val_loss: 0.9454 - val_accuracy: 0.5238\n",
      "Epoch 471/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8642 - accuracy: 0.6317 - val_loss: 0.9453 - val_accuracy: 0.5476\n",
      "Epoch 472/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8627 - accuracy: 0.5968 - val_loss: 0.9457 - val_accuracy: 0.5476\n",
      "Epoch 473/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8695 - accuracy: 0.5937 - val_loss: 0.9464 - val_accuracy: 0.5238\n",
      "Epoch 474/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8583 - accuracy: 0.5937 - val_loss: 0.9463 - val_accuracy: 0.5476\n",
      "Epoch 475/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8585 - accuracy: 0.6127 - val_loss: 0.9465 - val_accuracy: 0.5476\n",
      "Epoch 476/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8482 - accuracy: 0.6286 - val_loss: 0.9467 - val_accuracy: 0.5476\n",
      "Epoch 477/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8545 - accuracy: 0.6159 - val_loss: 0.9467 - val_accuracy: 0.5476\n",
      "Epoch 478/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8548 - accuracy: 0.5968 - val_loss: 0.9463 - val_accuracy: 0.5476\n",
      "Epoch 479/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8662 - accuracy: 0.5810 - val_loss: 0.9467 - val_accuracy: 0.5476\n",
      "Epoch 480/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8473 - accuracy: 0.6063 - val_loss: 0.9462 - val_accuracy: 0.5476\n",
      "Epoch 481/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8643 - accuracy: 0.6032 - val_loss: 0.9463 - val_accuracy: 0.5476\n",
      "Epoch 482/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8529 - accuracy: 0.6095 - val_loss: 0.9469 - val_accuracy: 0.5476\n",
      "Epoch 483/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8584 - accuracy: 0.6000 - val_loss: 0.9470 - val_accuracy: 0.5238\n",
      "Epoch 484/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8543 - accuracy: 0.6032 - val_loss: 0.9466 - val_accuracy: 0.5238\n",
      "Epoch 485/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8507 - accuracy: 0.6190 - val_loss: 0.9460 - val_accuracy: 0.5238\n",
      "Epoch 486/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8534 - accuracy: 0.6032 - val_loss: 0.9458 - val_accuracy: 0.5238\n",
      "Epoch 487/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8547 - accuracy: 0.6000 - val_loss: 0.9453 - val_accuracy: 0.5238\n",
      "Epoch 488/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8642 - accuracy: 0.5937 - val_loss: 0.9453 - val_accuracy: 0.5476\n",
      "Epoch 489/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8538 - accuracy: 0.6000 - val_loss: 0.9454 - val_accuracy: 0.5238\n",
      "Epoch 490/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8531 - accuracy: 0.6000 - val_loss: 0.9453 - val_accuracy: 0.5238\n",
      "Epoch 491/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8568 - accuracy: 0.5905 - val_loss: 0.9451 - val_accuracy: 0.5238\n",
      "Epoch 492/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8481 - accuracy: 0.5968 - val_loss: 0.9453 - val_accuracy: 0.5238\n",
      "Epoch 493/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8515 - accuracy: 0.6000 - val_loss: 0.9459 - val_accuracy: 0.5238\n",
      "Epoch 494/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8498 - accuracy: 0.6286 - val_loss: 0.9460 - val_accuracy: 0.5238\n",
      "Epoch 495/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8570 - accuracy: 0.6000 - val_loss: 0.9464 - val_accuracy: 0.5238\n",
      "Epoch 496/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8606 - accuracy: 0.5905 - val_loss: 0.9462 - val_accuracy: 0.5238\n",
      "Epoch 497/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8464 - accuracy: 0.6032 - val_loss: 0.9464 - val_accuracy: 0.5238\n",
      "Epoch 498/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8535 - accuracy: 0.6127 - val_loss: 0.9468 - val_accuracy: 0.5238\n",
      "Epoch 499/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8579 - accuracy: 0.6127 - val_loss: 0.9470 - val_accuracy: 0.5238\n",
      "Epoch 500/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8617 - accuracy: 0.5778 - val_loss: 0.9473 - val_accuracy: 0.5476\n",
      "Epoch 501/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8584 - accuracy: 0.6000 - val_loss: 0.9470 - val_accuracy: 0.5476\n",
      "Epoch 502/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8597 - accuracy: 0.6000 - val_loss: 0.9467 - val_accuracy: 0.5476\n",
      "Epoch 503/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8499 - accuracy: 0.6063 - val_loss: 0.9469 - val_accuracy: 0.5476\n",
      "Epoch 504/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8521 - accuracy: 0.6063 - val_loss: 0.9466 - val_accuracy: 0.5476\n",
      "Epoch 505/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8516 - accuracy: 0.6254 - val_loss: 0.9466 - val_accuracy: 0.5238\n",
      "Epoch 506/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8523 - accuracy: 0.6063 - val_loss: 0.9462 - val_accuracy: 0.5238\n",
      "Epoch 507/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8483 - accuracy: 0.6127 - val_loss: 0.9458 - val_accuracy: 0.5238\n",
      "Epoch 508/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8591 - accuracy: 0.6095 - val_loss: 0.9468 - val_accuracy: 0.5238\n",
      "Epoch 509/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8523 - accuracy: 0.6032 - val_loss: 0.9468 - val_accuracy: 0.5238\n",
      "Epoch 510/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8566 - accuracy: 0.6159 - val_loss: 0.9465 - val_accuracy: 0.5238\n",
      "Epoch 511/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8500 - accuracy: 0.6095 - val_loss: 0.9464 - val_accuracy: 0.5238\n",
      "Epoch 512/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8463 - accuracy: 0.6381 - val_loss: 0.9459 - val_accuracy: 0.5238\n",
      "Epoch 513/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8560 - accuracy: 0.5810 - val_loss: 0.9461 - val_accuracy: 0.5476\n",
      "Epoch 514/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8552 - accuracy: 0.6190 - val_loss: 0.9466 - val_accuracy: 0.5476\n",
      "Epoch 515/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8458 - accuracy: 0.6032 - val_loss: 0.9460 - val_accuracy: 0.5476\n",
      "Epoch 516/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8470 - accuracy: 0.5905 - val_loss: 0.9465 - val_accuracy: 0.5476\n",
      "Epoch 517/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8464 - accuracy: 0.6000 - val_loss: 0.9463 - val_accuracy: 0.5476\n",
      "Epoch 518/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8459 - accuracy: 0.6349 - val_loss: 0.9459 - val_accuracy: 0.5238\n",
      "Epoch 519/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8537 - accuracy: 0.5937 - val_loss: 0.9464 - val_accuracy: 0.5238\n",
      "Epoch 520/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8461 - accuracy: 0.6286 - val_loss: 0.9469 - val_accuracy: 0.5238\n",
      "Epoch 521/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8452 - accuracy: 0.6063 - val_loss: 0.9472 - val_accuracy: 0.5238\n",
      "Epoch 522/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8482 - accuracy: 0.6190 - val_loss: 0.9474 - val_accuracy: 0.5238\n",
      "Epoch 523/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8532 - accuracy: 0.5937 - val_loss: 0.9475 - val_accuracy: 0.5238\n",
      "Epoch 524/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8536 - accuracy: 0.6032 - val_loss: 0.9481 - val_accuracy: 0.5238\n",
      "Epoch 525/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8431 - accuracy: 0.6254 - val_loss: 0.9473 - val_accuracy: 0.5238\n",
      "Epoch 526/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8446 - accuracy: 0.6032 - val_loss: 0.9469 - val_accuracy: 0.5238\n",
      "Epoch 527/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8518 - accuracy: 0.6000 - val_loss: 0.9469 - val_accuracy: 0.5238\n",
      "Epoch 528/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8434 - accuracy: 0.6381 - val_loss: 0.9474 - val_accuracy: 0.5238\n",
      "Epoch 529/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8419 - accuracy: 0.6032 - val_loss: 0.9470 - val_accuracy: 0.5238\n",
      "Epoch 530/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8491 - accuracy: 0.5873 - val_loss: 0.9477 - val_accuracy: 0.5238\n",
      "Epoch 531/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8535 - accuracy: 0.6222 - val_loss: 0.9475 - val_accuracy: 0.5238\n",
      "Epoch 532/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8482 - accuracy: 0.6032 - val_loss: 0.9474 - val_accuracy: 0.5238\n",
      "Epoch 533/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8442 - accuracy: 0.6063 - val_loss: 0.9472 - val_accuracy: 0.5238\n",
      "Epoch 534/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8511 - accuracy: 0.6032 - val_loss: 0.9471 - val_accuracy: 0.5476\n",
      "Epoch 535/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8510 - accuracy: 0.6063 - val_loss: 0.9467 - val_accuracy: 0.5476\n",
      "Epoch 536/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8358 - accuracy: 0.6317 - val_loss: 0.9468 - val_accuracy: 0.5476\n",
      "Epoch 537/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8419 - accuracy: 0.6286 - val_loss: 0.9473 - val_accuracy: 0.5238\n",
      "Epoch 538/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8435 - accuracy: 0.5905 - val_loss: 0.9471 - val_accuracy: 0.5476\n",
      "Epoch 539/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8507 - accuracy: 0.6095 - val_loss: 0.9471 - val_accuracy: 0.5476\n",
      "Epoch 540/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8439 - accuracy: 0.6095 - val_loss: 0.9473 - val_accuracy: 0.5238\n",
      "Epoch 541/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8477 - accuracy: 0.6095 - val_loss: 0.9474 - val_accuracy: 0.5238\n",
      "Epoch 542/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8481 - accuracy: 0.6286 - val_loss: 0.9469 - val_accuracy: 0.5238\n",
      "Epoch 543/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8478 - accuracy: 0.6222 - val_loss: 0.9473 - val_accuracy: 0.5238\n",
      "Epoch 544/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8451 - accuracy: 0.6127 - val_loss: 0.9470 - val_accuracy: 0.5238\n",
      "Epoch 545/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8658 - accuracy: 0.5841 - val_loss: 0.9460 - val_accuracy: 0.5238\n",
      "Epoch 546/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8432 - accuracy: 0.6317 - val_loss: 0.9466 - val_accuracy: 0.5238\n",
      "Epoch 547/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8409 - accuracy: 0.6063 - val_loss: 0.9470 - val_accuracy: 0.5238\n",
      "Epoch 548/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8483 - accuracy: 0.6000 - val_loss: 0.9477 - val_accuracy: 0.5238\n",
      "Epoch 549/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8451 - accuracy: 0.6063 - val_loss: 0.9475 - val_accuracy: 0.5238\n",
      "Epoch 550/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8339 - accuracy: 0.6317 - val_loss: 0.9475 - val_accuracy: 0.5238\n",
      "Epoch 551/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8460 - accuracy: 0.5968 - val_loss: 0.9466 - val_accuracy: 0.5238\n",
      "Epoch 552/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8474 - accuracy: 0.6000 - val_loss: 0.9466 - val_accuracy: 0.5476\n",
      "Epoch 553/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8436 - accuracy: 0.6254 - val_loss: 0.9475 - val_accuracy: 0.5238\n",
      "Epoch 554/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8513 - accuracy: 0.6095 - val_loss: 0.9478 - val_accuracy: 0.5476\n",
      "Epoch 555/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8504 - accuracy: 0.5905 - val_loss: 0.9479 - val_accuracy: 0.5238\n",
      "Epoch 556/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8490 - accuracy: 0.5905 - val_loss: 0.9485 - val_accuracy: 0.5000\n",
      "Epoch 557/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8484 - accuracy: 0.6127 - val_loss: 0.9488 - val_accuracy: 0.5000\n",
      "Epoch 558/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8465 - accuracy: 0.6127 - val_loss: 0.9480 - val_accuracy: 0.5000\n",
      "Epoch 559/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8438 - accuracy: 0.6159 - val_loss: 0.9481 - val_accuracy: 0.5000\n",
      "Epoch 560/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8417 - accuracy: 0.6254 - val_loss: 0.9478 - val_accuracy: 0.5000\n",
      "Epoch 561/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8500 - accuracy: 0.6127 - val_loss: 0.9488 - val_accuracy: 0.5000\n",
      "Epoch 562/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8391 - accuracy: 0.6540 - val_loss: 0.9491 - val_accuracy: 0.5000\n",
      "Epoch 563/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8423 - accuracy: 0.6063 - val_loss: 0.9489 - val_accuracy: 0.5000\n",
      "Epoch 564/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8418 - accuracy: 0.6159 - val_loss: 0.9481 - val_accuracy: 0.5000\n",
      "Epoch 565/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8404 - accuracy: 0.5937 - val_loss: 0.9479 - val_accuracy: 0.5000\n",
      "Epoch 566/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8475 - accuracy: 0.5937 - val_loss: 0.9477 - val_accuracy: 0.5000\n",
      "Epoch 567/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8461 - accuracy: 0.6127 - val_loss: 0.9465 - val_accuracy: 0.5238\n",
      "Epoch 568/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8370 - accuracy: 0.6127 - val_loss: 0.9466 - val_accuracy: 0.5476\n",
      "Epoch 569/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8344 - accuracy: 0.6032 - val_loss: 0.9474 - val_accuracy: 0.5238\n",
      "Epoch 570/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8350 - accuracy: 0.6159 - val_loss: 0.9481 - val_accuracy: 0.5000\n",
      "Epoch 571/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8411 - accuracy: 0.6159 - val_loss: 0.9482 - val_accuracy: 0.5000\n",
      "Epoch 572/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8442 - accuracy: 0.6159 - val_loss: 0.9485 - val_accuracy: 0.5000\n",
      "Epoch 573/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8503 - accuracy: 0.5968 - val_loss: 0.9488 - val_accuracy: 0.5000\n",
      "Epoch 574/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8394 - accuracy: 0.5968 - val_loss: 0.9488 - val_accuracy: 0.5000\n",
      "Epoch 575/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8420 - accuracy: 0.6190 - val_loss: 0.9485 - val_accuracy: 0.5000\n",
      "Epoch 576/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8437 - accuracy: 0.6317 - val_loss: 0.9481 - val_accuracy: 0.5000\n",
      "Epoch 577/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8373 - accuracy: 0.6127 - val_loss: 0.9480 - val_accuracy: 0.5000\n",
      "Epoch 578/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8395 - accuracy: 0.5810 - val_loss: 0.9483 - val_accuracy: 0.5000\n",
      "Epoch 579/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8406 - accuracy: 0.6159 - val_loss: 0.9486 - val_accuracy: 0.5000\n",
      "Epoch 580/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8338 - accuracy: 0.6381 - val_loss: 0.9491 - val_accuracy: 0.5000\n",
      "Epoch 581/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8393 - accuracy: 0.6095 - val_loss: 0.9496 - val_accuracy: 0.5000\n",
      "Epoch 582/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8301 - accuracy: 0.6063 - val_loss: 0.9495 - val_accuracy: 0.5000\n",
      "Epoch 583/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8388 - accuracy: 0.6000 - val_loss: 0.9500 - val_accuracy: 0.5000\n",
      "Epoch 584/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8434 - accuracy: 0.6032 - val_loss: 0.9497 - val_accuracy: 0.5000\n",
      "Epoch 585/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8407 - accuracy: 0.6127 - val_loss: 0.9496 - val_accuracy: 0.5000\n",
      "Epoch 586/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8368 - accuracy: 0.6190 - val_loss: 0.9501 - val_accuracy: 0.5000\n",
      "Epoch 587/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8473 - accuracy: 0.6190 - val_loss: 0.9499 - val_accuracy: 0.5000\n",
      "Epoch 588/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8359 - accuracy: 0.6032 - val_loss: 0.9498 - val_accuracy: 0.5000\n",
      "Epoch 589/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8307 - accuracy: 0.6476 - val_loss: 0.9499 - val_accuracy: 0.5000\n",
      "Epoch 590/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8396 - accuracy: 0.6127 - val_loss: 0.9500 - val_accuracy: 0.5000\n",
      "Epoch 591/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8411 - accuracy: 0.6413 - val_loss: 0.9498 - val_accuracy: 0.5238\n",
      "Epoch 592/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8393 - accuracy: 0.6063 - val_loss: 0.9499 - val_accuracy: 0.5238\n",
      "Epoch 593/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8344 - accuracy: 0.6127 - val_loss: 0.9498 - val_accuracy: 0.5238\n",
      "Epoch 594/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8319 - accuracy: 0.6190 - val_loss: 0.9495 - val_accuracy: 0.5238\n",
      "Epoch 595/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8361 - accuracy: 0.6063 - val_loss: 0.9492 - val_accuracy: 0.5238\n",
      "Epoch 596/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8372 - accuracy: 0.6286 - val_loss: 0.9497 - val_accuracy: 0.5238\n",
      "Epoch 597/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8463 - accuracy: 0.6159 - val_loss: 0.9500 - val_accuracy: 0.5238\n",
      "Epoch 598/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8397 - accuracy: 0.6032 - val_loss: 0.9498 - val_accuracy: 0.5238\n",
      "Epoch 599/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8368 - accuracy: 0.6159 - val_loss: 0.9497 - val_accuracy: 0.5238\n",
      "Epoch 600/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8384 - accuracy: 0.6222 - val_loss: 0.9498 - val_accuracy: 0.5238\n",
      "Epoch 601/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8439 - accuracy: 0.6032 - val_loss: 0.9497 - val_accuracy: 0.5238\n",
      "Epoch 602/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8313 - accuracy: 0.6159 - val_loss: 0.9497 - val_accuracy: 0.5238\n",
      "Epoch 603/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8369 - accuracy: 0.6190 - val_loss: 0.9489 - val_accuracy: 0.5238\n",
      "Epoch 604/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8333 - accuracy: 0.6095 - val_loss: 0.9488 - val_accuracy: 0.5238\n",
      "Epoch 605/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8340 - accuracy: 0.6254 - val_loss: 0.9488 - val_accuracy: 0.5238\n",
      "Epoch 606/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8384 - accuracy: 0.6032 - val_loss: 0.9486 - val_accuracy: 0.5238\n",
      "Epoch 607/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8391 - accuracy: 0.6032 - val_loss: 0.9494 - val_accuracy: 0.5238\n",
      "Epoch 608/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8314 - accuracy: 0.6159 - val_loss: 0.9497 - val_accuracy: 0.5238\n",
      "Epoch 609/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8316 - accuracy: 0.6127 - val_loss: 0.9491 - val_accuracy: 0.5238\n",
      "Epoch 610/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8350 - accuracy: 0.6222 - val_loss: 0.9494 - val_accuracy: 0.5238\n",
      "Epoch 611/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8318 - accuracy: 0.6159 - val_loss: 0.9492 - val_accuracy: 0.5238\n",
      "Epoch 612/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8346 - accuracy: 0.6286 - val_loss: 0.9487 - val_accuracy: 0.5238\n",
      "Epoch 613/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8338 - accuracy: 0.6127 - val_loss: 0.9480 - val_accuracy: 0.5238\n",
      "Epoch 614/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8419 - accuracy: 0.6159 - val_loss: 0.9486 - val_accuracy: 0.5238\n",
      "Epoch 615/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8328 - accuracy: 0.5968 - val_loss: 0.9486 - val_accuracy: 0.5238\n",
      "Epoch 616/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8469 - accuracy: 0.6000 - val_loss: 0.9489 - val_accuracy: 0.5238\n",
      "Epoch 617/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8299 - accuracy: 0.6127 - val_loss: 0.9489 - val_accuracy: 0.5238\n",
      "Epoch 618/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8258 - accuracy: 0.6254 - val_loss: 0.9491 - val_accuracy: 0.5238\n",
      "Epoch 619/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8264 - accuracy: 0.6159 - val_loss: 0.9491 - val_accuracy: 0.5238\n",
      "Epoch 620/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8244 - accuracy: 0.6190 - val_loss: 0.9497 - val_accuracy: 0.5238\n",
      "Epoch 621/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8377 - accuracy: 0.6159 - val_loss: 0.9501 - val_accuracy: 0.5238\n",
      "Epoch 622/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8389 - accuracy: 0.6349 - val_loss: 0.9509 - val_accuracy: 0.5238\n",
      "Epoch 623/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8318 - accuracy: 0.6254 - val_loss: 0.9506 - val_accuracy: 0.5238\n",
      "Epoch 624/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8325 - accuracy: 0.6063 - val_loss: 0.9498 - val_accuracy: 0.5238\n",
      "Epoch 625/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8297 - accuracy: 0.6127 - val_loss: 0.9493 - val_accuracy: 0.5238\n",
      "Epoch 626/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8399 - accuracy: 0.6222 - val_loss: 0.9492 - val_accuracy: 0.5238\n",
      "Epoch 627/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8390 - accuracy: 0.6222 - val_loss: 0.9494 - val_accuracy: 0.5238\n",
      "Epoch 628/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8393 - accuracy: 0.6159 - val_loss: 0.9495 - val_accuracy: 0.5238\n",
      "Epoch 629/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8304 - accuracy: 0.6286 - val_loss: 0.9493 - val_accuracy: 0.5238\n",
      "Epoch 630/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8330 - accuracy: 0.6127 - val_loss: 0.9494 - val_accuracy: 0.5238\n",
      "Epoch 631/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8331 - accuracy: 0.6349 - val_loss: 0.9495 - val_accuracy: 0.5238\n",
      "Epoch 632/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8277 - accuracy: 0.6063 - val_loss: 0.9489 - val_accuracy: 0.5238\n",
      "Epoch 633/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8296 - accuracy: 0.6159 - val_loss: 0.9494 - val_accuracy: 0.5238\n",
      "Epoch 634/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8336 - accuracy: 0.6286 - val_loss: 0.9497 - val_accuracy: 0.5238\n",
      "Epoch 635/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8277 - accuracy: 0.6159 - val_loss: 0.9500 - val_accuracy: 0.5238\n",
      "Epoch 636/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8342 - accuracy: 0.5968 - val_loss: 0.9499 - val_accuracy: 0.5238\n",
      "Epoch 637/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8392 - accuracy: 0.6000 - val_loss: 0.9507 - val_accuracy: 0.5238\n",
      "Epoch 638/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8225 - accuracy: 0.6317 - val_loss: 0.9512 - val_accuracy: 0.5238\n",
      "Epoch 639/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8323 - accuracy: 0.6349 - val_loss: 0.9518 - val_accuracy: 0.5238\n",
      "Epoch 640/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8308 - accuracy: 0.6222 - val_loss: 0.9518 - val_accuracy: 0.5238\n",
      "Epoch 641/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8312 - accuracy: 0.6063 - val_loss: 0.9514 - val_accuracy: 0.5238\n",
      "Epoch 642/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8321 - accuracy: 0.6032 - val_loss: 0.9511 - val_accuracy: 0.5238\n",
      "Epoch 643/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8307 - accuracy: 0.6063 - val_loss: 0.9509 - val_accuracy: 0.5238\n",
      "Epoch 644/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8237 - accuracy: 0.6349 - val_loss: 0.9496 - val_accuracy: 0.5238\n",
      "Epoch 645/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8319 - accuracy: 0.5968 - val_loss: 0.9495 - val_accuracy: 0.5238\n",
      "Epoch 646/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8235 - accuracy: 0.6349 - val_loss: 0.9488 - val_accuracy: 0.5238\n",
      "Epoch 647/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8421 - accuracy: 0.5937 - val_loss: 0.9488 - val_accuracy: 0.5238\n",
      "Epoch 648/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8447 - accuracy: 0.5905 - val_loss: 0.9502 - val_accuracy: 0.5238\n",
      "Epoch 649/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8269 - accuracy: 0.6222 - val_loss: 0.9511 - val_accuracy: 0.5238\n",
      "Epoch 650/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8251 - accuracy: 0.6095 - val_loss: 0.9510 - val_accuracy: 0.5238\n",
      "Epoch 651/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8350 - accuracy: 0.6032 - val_loss: 0.9518 - val_accuracy: 0.5238\n",
      "Epoch 652/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8212 - accuracy: 0.6254 - val_loss: 0.9518 - val_accuracy: 0.5238\n",
      "Epoch 653/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8243 - accuracy: 0.6222 - val_loss: 0.9513 - val_accuracy: 0.5238\n",
      "Epoch 654/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8185 - accuracy: 0.6159 - val_loss: 0.9511 - val_accuracy: 0.5238\n",
      "Epoch 655/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8264 - accuracy: 0.6127 - val_loss: 0.9520 - val_accuracy: 0.5238\n",
      "Epoch 656/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8254 - accuracy: 0.6254 - val_loss: 0.9520 - val_accuracy: 0.5238\n",
      "Epoch 657/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8261 - accuracy: 0.6095 - val_loss: 0.9521 - val_accuracy: 0.5238\n",
      "Epoch 658/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8414 - accuracy: 0.6063 - val_loss: 0.9510 - val_accuracy: 0.5238\n",
      "Epoch 659/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8241 - accuracy: 0.5619 - val_loss: 0.9500 - val_accuracy: 0.5238\n",
      "Epoch 660/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8296 - accuracy: 0.5968 - val_loss: 0.9499 - val_accuracy: 0.5238\n",
      "Epoch 661/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8232 - accuracy: 0.6413 - val_loss: 0.9502 - val_accuracy: 0.5238\n",
      "Epoch 662/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8267 - accuracy: 0.6000 - val_loss: 0.9503 - val_accuracy: 0.5238\n",
      "Epoch 663/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8241 - accuracy: 0.6190 - val_loss: 0.9505 - val_accuracy: 0.5238\n",
      "Epoch 664/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8283 - accuracy: 0.6159 - val_loss: 0.9502 - val_accuracy: 0.5238\n",
      "Epoch 665/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8340 - accuracy: 0.6349 - val_loss: 0.9504 - val_accuracy: 0.5238\n",
      "Epoch 666/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8270 - accuracy: 0.6317 - val_loss: 0.9506 - val_accuracy: 0.5238\n",
      "Epoch 667/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8210 - accuracy: 0.6222 - val_loss: 0.9506 - val_accuracy: 0.5238\n",
      "Epoch 668/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8244 - accuracy: 0.6254 - val_loss: 0.9505 - val_accuracy: 0.5238\n",
      "Epoch 669/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8432 - accuracy: 0.5905 - val_loss: 0.9502 - val_accuracy: 0.5238\n",
      "Epoch 670/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8233 - accuracy: 0.6222 - val_loss: 0.9503 - val_accuracy: 0.5238\n",
      "Epoch 671/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8251 - accuracy: 0.6095 - val_loss: 0.9504 - val_accuracy: 0.5238\n",
      "Epoch 672/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8253 - accuracy: 0.6254 - val_loss: 0.9506 - val_accuracy: 0.5238\n",
      "Epoch 673/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8320 - accuracy: 0.6254 - val_loss: 0.9507 - val_accuracy: 0.5238\n",
      "Epoch 674/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8153 - accuracy: 0.6317 - val_loss: 0.9505 - val_accuracy: 0.5238\n",
      "Epoch 675/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8235 - accuracy: 0.6254 - val_loss: 0.9509 - val_accuracy: 0.5238\n",
      "Epoch 676/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8386 - accuracy: 0.6127 - val_loss: 0.9515 - val_accuracy: 0.5238\n",
      "Epoch 677/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8174 - accuracy: 0.6159 - val_loss: 0.9515 - val_accuracy: 0.5238\n",
      "Epoch 678/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8162 - accuracy: 0.6349 - val_loss: 0.9513 - val_accuracy: 0.5238\n",
      "Epoch 679/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8283 - accuracy: 0.5905 - val_loss: 0.9518 - val_accuracy: 0.5238\n",
      "Epoch 680/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8166 - accuracy: 0.6286 - val_loss: 0.9523 - val_accuracy: 0.5238\n",
      "Epoch 681/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8196 - accuracy: 0.6349 - val_loss: 0.9523 - val_accuracy: 0.5238\n",
      "Epoch 682/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8201 - accuracy: 0.6254 - val_loss: 0.9518 - val_accuracy: 0.5238\n",
      "Epoch 683/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8155 - accuracy: 0.6222 - val_loss: 0.9513 - val_accuracy: 0.5238\n",
      "Epoch 684/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8342 - accuracy: 0.6286 - val_loss: 0.9510 - val_accuracy: 0.5238\n",
      "Epoch 685/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8212 - accuracy: 0.6254 - val_loss: 0.9512 - val_accuracy: 0.5238\n",
      "Epoch 686/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8208 - accuracy: 0.6381 - val_loss: 0.9514 - val_accuracy: 0.5238\n",
      "Epoch 687/750\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.8235 - accuracy: 0.6349 - val_loss: 0.9515 - val_accuracy: 0.5238\n",
      "Epoch 688/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8182 - accuracy: 0.6286 - val_loss: 0.9514 - val_accuracy: 0.5238\n",
      "Epoch 689/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8233 - accuracy: 0.6254 - val_loss: 0.9511 - val_accuracy: 0.5238\n",
      "Epoch 690/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8258 - accuracy: 0.6190 - val_loss: 0.9517 - val_accuracy: 0.5238\n",
      "Epoch 691/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8279 - accuracy: 0.6095 - val_loss: 0.9518 - val_accuracy: 0.5238\n",
      "Epoch 692/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8281 - accuracy: 0.6095 - val_loss: 0.9510 - val_accuracy: 0.5238\n",
      "Epoch 693/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8262 - accuracy: 0.6127 - val_loss: 0.9508 - val_accuracy: 0.5238\n",
      "Epoch 694/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8288 - accuracy: 0.6222 - val_loss: 0.9513 - val_accuracy: 0.5238\n",
      "Epoch 695/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8265 - accuracy: 0.6095 - val_loss: 0.9513 - val_accuracy: 0.5238\n",
      "Epoch 696/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8226 - accuracy: 0.6159 - val_loss: 0.9522 - val_accuracy: 0.5238\n",
      "Epoch 697/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8162 - accuracy: 0.6190 - val_loss: 0.9520 - val_accuracy: 0.5238\n",
      "Epoch 698/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8249 - accuracy: 0.6286 - val_loss: 0.9518 - val_accuracy: 0.5238\n",
      "Epoch 699/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8261 - accuracy: 0.6222 - val_loss: 0.9516 - val_accuracy: 0.5238\n",
      "Epoch 700/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8302 - accuracy: 0.6032 - val_loss: 0.9522 - val_accuracy: 0.5238\n",
      "Epoch 701/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8264 - accuracy: 0.5937 - val_loss: 0.9526 - val_accuracy: 0.5238\n",
      "Epoch 702/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8197 - accuracy: 0.6349 - val_loss: 0.9518 - val_accuracy: 0.5238\n",
      "Epoch 703/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8218 - accuracy: 0.6159 - val_loss: 0.9525 - val_accuracy: 0.5238\n",
      "Epoch 704/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8279 - accuracy: 0.5937 - val_loss: 0.9520 - val_accuracy: 0.5238\n",
      "Epoch 705/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8218 - accuracy: 0.6317 - val_loss: 0.9516 - val_accuracy: 0.5238\n",
      "Epoch 706/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8178 - accuracy: 0.6190 - val_loss: 0.9519 - val_accuracy: 0.5238\n",
      "Epoch 707/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8262 - accuracy: 0.6222 - val_loss: 0.9522 - val_accuracy: 0.5238\n",
      "Epoch 708/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8213 - accuracy: 0.6254 - val_loss: 0.9522 - val_accuracy: 0.5238\n",
      "Epoch 709/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8240 - accuracy: 0.6190 - val_loss: 0.9519 - val_accuracy: 0.5238\n",
      "Epoch 710/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8203 - accuracy: 0.6190 - val_loss: 0.9518 - val_accuracy: 0.5238\n",
      "Epoch 711/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8210 - accuracy: 0.5937 - val_loss: 0.9520 - val_accuracy: 0.5238\n",
      "Epoch 712/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8159 - accuracy: 0.6127 - val_loss: 0.9519 - val_accuracy: 0.5238\n",
      "Epoch 713/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8212 - accuracy: 0.6349 - val_loss: 0.9523 - val_accuracy: 0.5238\n",
      "Epoch 714/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8206 - accuracy: 0.6286 - val_loss: 0.9525 - val_accuracy: 0.5238\n",
      "Epoch 715/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8149 - accuracy: 0.6317 - val_loss: 0.9527 - val_accuracy: 0.5238\n",
      "Epoch 716/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8108 - accuracy: 0.6413 - val_loss: 0.9528 - val_accuracy: 0.5238\n",
      "Epoch 717/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8183 - accuracy: 0.6222 - val_loss: 0.9530 - val_accuracy: 0.5238\n",
      "Epoch 718/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8279 - accuracy: 0.6190 - val_loss: 0.9523 - val_accuracy: 0.5238\n",
      "Epoch 719/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8112 - accuracy: 0.6286 - val_loss: 0.9526 - val_accuracy: 0.5238\n",
      "Epoch 720/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8212 - accuracy: 0.6254 - val_loss: 0.9528 - val_accuracy: 0.5238\n",
      "Epoch 721/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8207 - accuracy: 0.6159 - val_loss: 0.9527 - val_accuracy: 0.5238\n",
      "Epoch 722/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8237 - accuracy: 0.6159 - val_loss: 0.9528 - val_accuracy: 0.5238\n",
      "Epoch 723/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8228 - accuracy: 0.6222 - val_loss: 0.9529 - val_accuracy: 0.5238\n",
      "Epoch 724/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8182 - accuracy: 0.6317 - val_loss: 0.9529 - val_accuracy: 0.5238\n",
      "Epoch 725/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8173 - accuracy: 0.6222 - val_loss: 0.9526 - val_accuracy: 0.5238\n",
      "Epoch 726/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8146 - accuracy: 0.6317 - val_loss: 0.9520 - val_accuracy: 0.5238\n",
      "Epoch 727/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8203 - accuracy: 0.6159 - val_loss: 0.9523 - val_accuracy: 0.5238\n",
      "Epoch 728/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8147 - accuracy: 0.6222 - val_loss: 0.9524 - val_accuracy: 0.5238\n",
      "Epoch 729/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8174 - accuracy: 0.6159 - val_loss: 0.9526 - val_accuracy: 0.5238\n",
      "Epoch 730/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8200 - accuracy: 0.6190 - val_loss: 0.9530 - val_accuracy: 0.5238\n",
      "Epoch 731/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8198 - accuracy: 0.6190 - val_loss: 0.9532 - val_accuracy: 0.5238\n",
      "Epoch 732/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8163 - accuracy: 0.6349 - val_loss: 0.9539 - val_accuracy: 0.5238\n",
      "Epoch 733/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8133 - accuracy: 0.6381 - val_loss: 0.9538 - val_accuracy: 0.5238\n",
      "Epoch 734/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8166 - accuracy: 0.6222 - val_loss: 0.9542 - val_accuracy: 0.5238\n",
      "Epoch 735/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8130 - accuracy: 0.6032 - val_loss: 0.9541 - val_accuracy: 0.5238\n",
      "Epoch 736/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8304 - accuracy: 0.6286 - val_loss: 0.9545 - val_accuracy: 0.5238\n",
      "Epoch 737/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8116 - accuracy: 0.6317 - val_loss: 0.9541 - val_accuracy: 0.5238\n",
      "Epoch 738/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8200 - accuracy: 0.6349 - val_loss: 0.9536 - val_accuracy: 0.5238\n",
      "Epoch 739/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8138 - accuracy: 0.6317 - val_loss: 0.9538 - val_accuracy: 0.5238\n",
      "Epoch 740/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8169 - accuracy: 0.6571 - val_loss: 0.9542 - val_accuracy: 0.5238\n",
      "Epoch 741/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8072 - accuracy: 0.6349 - val_loss: 0.9543 - val_accuracy: 0.5238\n",
      "Epoch 742/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8038 - accuracy: 0.6413 - val_loss: 0.9537 - val_accuracy: 0.5238\n",
      "Epoch 743/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8141 - accuracy: 0.6286 - val_loss: 0.9539 - val_accuracy: 0.5238\n",
      "Epoch 744/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8136 - accuracy: 0.6413 - val_loss: 0.9535 - val_accuracy: 0.5238\n",
      "Epoch 745/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8231 - accuracy: 0.6063 - val_loss: 0.9531 - val_accuracy: 0.5238\n",
      "Epoch 746/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8057 - accuracy: 0.6286 - val_loss: 0.9532 - val_accuracy: 0.5238\n",
      "Epoch 747/750\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.8170 - accuracy: 0.6286 - val_loss: 0.9536 - val_accuracy: 0.5238\n",
      "Epoch 748/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8150 - accuracy: 0.6286 - val_loss: 0.9539 - val_accuracy: 0.5238\n",
      "Epoch 749/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8098 - accuracy: 0.6381 - val_loss: 0.9537 - val_accuracy: 0.5238\n",
      "Epoch 750/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8196 - accuracy: 0.6032 - val_loss: 0.9540 - val_accuracy: 0.5238\n",
      "\n",
      "\n",
      "Test loss: 0.9539925456047058\n",
      "Test accuracy: 0.523809552192688\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Building the RNN ##\n",
    "print()\n",
    "print(\"length of train data: \", len(train_x))\n",
    "print(\"length of validation data: \", len(validation_x))\n",
    "print()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(train_x.shape[1:]), activation='tanh', return_sequences=True))\n",
    "# model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(LSTM(64, activation='tanh'))\n",
    "# model.add(Dropout(0.3))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(64, activation='tanh'))\n",
    "# model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.00001, decay=1e-6)\n",
    "# opt = tf.keras.optimizers.Adam(learning_rate=0.0001, decay=1e-6)\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=opt,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_x, train_y,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(validation_x, validation_y)\n",
    ")\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "# Score model\n",
    "score = model.evaluate(validation_x, validation_y, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.9539925456047058\n",
      "Test accuracy: 0.523809552192688\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(10,7))\n",
    "plt.xlabel('epoch')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_test_buys(tickers, SEQ_LEN, SHIFT):\n",
    "    Sequential_data = []\n",
    "    for ticker in tickers:\n",
    "        df = set_data(ticker)[-SHIFT:]\n",
    "\n",
    "        sequential_data = []  # this is a list that will CONTAIN the sequences\n",
    "        prev_days = deque(maxlen=SEQ_LEN)  # These will be our actual sequences. They are made with deque, which keeps the maximum length by popping out older values as new ones come in\n",
    "        \n",
    "        for i in df.values:  # iterate over the values\n",
    "            prev_days.append([n for n in i[:-2]])  # store all but the target\n",
    "            if len(prev_days) == SEQ_LEN:  # make sure we have 60 sequences!\n",
    "                sequential_data.append([np.array(prev_days), i[-2], i[-1]])  # append those bad boys!\n",
    "        \n",
    "        Sequential_data = Sequential_data + sequential_data\n",
    "        \n",
    "    X = []; y = []; z = []\n",
    "    for seq, target, actual in Sequential_data:  # going over our new sequential data\n",
    "        X.append(seq)  # X is the sequences\n",
    "        y.append(target)  # y is the targets/labels (buys vs sell/notbuy)\n",
    "        z.append(actual)\n",
    "\n",
    "    return np.array(X).astype(\"float64\"), np.array(y).astype(\"uint8\"), np.array(z).astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_trading_days = 100\n",
    "test_x, test_y, test_z = process_test_buys(tickers_test, SEQ_LEN, last_trading_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []; total = 0\n",
    "for i, j in zip(output, test_z):\n",
    "    if np.argmax(i) == 2:\n",
    "        total += 1\n",
    "#         results.append([i,j])\n",
    "        results.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trading period. The last 100 trading days.\n",
      "Average daily return: 1.623460 percent, over 33 trades.\n",
      "You started with $5000 and finished with $8276 after 33 trades.\n"
     ]
    }
   ],
   "source": [
    "print('Trading period. The last %d trading days.' % (last_trading_days))\n",
    "print('Average daily return: %f percent, over %d trades.' % (np.average(results), len(results)))\n",
    "start = 5000\n",
    "finish = start\n",
    "for i in results:\n",
    "    finish = finish + (i/100) * finish\n",
    "    \n",
    "print('You started with $%d and finished with $%d after %d trades.' % (start, finish, len(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.025056559514063, 5.726489588815231, 2.945719141125891, 2.0142415174281503, -2.9965008400013704, -3.8817195659787362, 0.6445998637189643, 4.458672335756675, 5.388521343106012, 4.3221755332707, 1.0774372730292692, 4.736963722489929, -2.3522654959157174, -1.733972163156594, 1.3039937046066319, 4.332835651170441, 1.0787321744884615, 2.9126285555452602, 7.7005575108721525, -0.1503032817136929, -1.2771784113766782, -1.2791909238900834, -0.6247845791248041, -6.820156418592194, 8.209351729204517, -6.248460619411134, 6.049490496665411, 6.840351822165136, 2.2420054420520197, -0.8734705143035981, -6.221057960005282, 8.627715496969547, 2.3957114324287376]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []; total = 0\n",
    "for i, j in zip(output, test_z):\n",
    "    if i[2] > 0.6:\n",
    "        total += 1\n",
    "#         results.append([i,j])\n",
    "        results.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trading period. The last 100 trading days.\n",
      "Average daily return: 1.147891 percent, over 13 trades.\n",
      "You started with $5000 and finished with $5702 after 13 trades.\n"
     ]
    }
   ],
   "source": [
    "print('Trading period. The last %d trading days.' % (last_trading_days))\n",
    "print('Average daily return: %f percent, over %d trades.' % (np.average(results), len(results)))\n",
    "start = 5000\n",
    "finish = start\n",
    "for i in results:\n",
    "    finish = finish + (i/100) * finish\n",
    "    \n",
    "print('You started with $%d and finished with $%d after %d trades.' % (start, finish, len(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.025056559514063, 5.726489588815231, 0.6445998637189643, 5.388521343106012, 4.736963722489929, -1.2791909238900834, -0.6247845791248041, -6.820156418592194, -6.248460619411134, 6.840351822165136, -0.8734705143035981, -6.221057960005282, 8.627715496969547]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if os.path.isfile('FAS_model.h5') is False:\n",
    "    model.save('FAS_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = load_model('FAS_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

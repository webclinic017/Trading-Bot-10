{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "import random\n",
    "from collections import deque\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, BatchNormalization, Flatten, Activation\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ModelCheckpoint\n",
    "import time\n",
    "import statistics\n",
    "from sklearn import preprocessing\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = \"FAS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDB(ticker):\n",
    "    tick = ticker\n",
    "    # Load data\n",
    "    data = yf.Ticker(tick)\n",
    "    df = data.history(period=\"3y\", interval=\"1d\")\n",
    "#     df = data.history(start=\"2018-12-01\", end=\"2020-03-01\")\n",
    "#     start=\"2017-01-01\", end=\"2017-04-30\"\n",
    "    \n",
    "    # add data points\n",
    "    df['close_per1'] = df.ta.percent_return(1)*100\n",
    "    df['sma10'] = df.ta.sma(length=10)\n",
    "    df['williams'] = df.ta.willr()\n",
    "\n",
    "\n",
    "    df = df[[\n",
    "            'open','close','sma10','williams','close_per1'\n",
    "            ]]\n",
    "\n",
    "    df = df.dropna()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.096166027111942\n",
      "                 open      close      sma10   williams  close_per1\n",
      "date                                                              \n",
      "2019-01-18  53.487754  54.967037  49.258179  -0.559063    4.245093\n",
      "2019-01-22  53.818647  53.400166  50.024096 -11.809939   -2.850566\n",
      "2019-01-23  54.061958  53.526691  50.731622 -10.901423    0.236939\n",
      "2019-01-24  53.079013  53.993832  51.410925  -8.702622    0.872724\n",
      "2019-01-25  55.093560  55.580166  52.188521  -5.587977    2.937992\n",
      "                  open       close       sma10   williams  close_per1\n",
      "date                                                                 \n",
      "2021-12-27  129.820007  132.520004  126.454931 -12.336443    2.896196\n",
      "2021-12-28  132.479996  132.509995  127.225233 -13.113711   -0.007553\n",
      "2021-12-29  133.600006  132.289993  127.731278 -14.056528   -0.166026\n",
      "2021-12-30  133.139999  131.279999  128.028655 -18.384868   -0.763470\n",
      "2021-12-31  130.720001  130.940002  127.923165 -19.841926   -0.258986\n"
     ]
    }
   ],
   "source": [
    "data = getDB(ticker)\n",
    "print(data['close_per1'].std())\n",
    "print(data.head(5))\n",
    "print(data.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2019-01-18 00:00:00')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[1]\n",
    "data.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_data(ticker):\n",
    "    df = getDB(ticker)\n",
    "\n",
    "    df['CP_ol'] = 0 # open to close day percentage [classify by 0,1,2]\n",
    "    df['CO_il'] = 0 # close(i) to open(i+1) price [classify by 0,1]\n",
    "    df['SMA10_il'] = 0 # sma(10 day) compared to close price (i)\n",
    "    df['W_il'] = 0 # Williams [classify by -1,0,1]\n",
    "    \n",
    "    value = df['close_per1'].std()\n",
    "    \n",
    "    # setting the outputs in the df\n",
    "    for i in range(len(df)):\n",
    "        if df.iloc[i]['close_per1'] > value:\n",
    "            df.iloc[i, df.columns.get_loc('CP_ol')] = 2\n",
    "        elif df.iloc[i]['close_per1'] < -value:\n",
    "            df.iloc[i, df.columns.get_loc('CP_ol')] = 1\n",
    "        else:\n",
    "            df.iloc[i, df.columns.get_loc('CP_ol')] = 0\n",
    "    \n",
    "    # setting the inputs in the df\n",
    "    for i in range(len(df)-1):\n",
    "#         try:\n",
    "#         print(\"close data:\",df.index[i])\n",
    "#         print(\"open data:\",df.index[i+1])\n",
    "#         print(\"putting data here:\",df.index[i+1])\n",
    "#         print()\n",
    "        if df.iloc[i]['close'] < df.iloc[i+1]['open']:\n",
    "            df.iloc[i+1, df.columns.get_loc('CO_il')] = 1\n",
    "        else:\n",
    "            df.iloc[i+1, df.columns.get_loc('CO_il')] = 0\n",
    "#         except:\n",
    "#             df.iloc[i+1, df.columns.get_loc('CO_il')] = np.nan\n",
    "            \n",
    "    \n",
    "#     # setting the inputs in the df\n",
    "#     for i in range(len(df)):\n",
    "#         try:\n",
    "#             if df.iloc[i]['close'] > df.iloc[i]['sma10']:\n",
    "#                 df.iloc[i, df.columns.get_loc('SMA10_il')] = 1\n",
    "#             else:\n",
    "#                 df.iloc[i, df.columns.get_loc('SMA10_il')] = 0\n",
    "#         except:\n",
    "#             df.iloc[i, df.columns.get_loc('SMA10_il')] = np.nan\n",
    "       \n",
    "    # setting the inputs in the df\n",
    "    for i in range(len(df)-1):\n",
    "#         try:\n",
    "        if df.iloc[i+1]['open'] > df.iloc[i]['sma10']:\n",
    "            df.iloc[i+1, df.columns.get_loc('SMA10_il')] = 1\n",
    "        else:\n",
    "            df.iloc[i+1, df.columns.get_loc('SMA10_il')] = 0\n",
    "#         except:\n",
    "#             df.iloc[i+1, df.columns.get_loc('SMA10_il')] = np.nan\n",
    "    \n",
    "    \n",
    "    # setting the inputs in the df\n",
    "    for i in range(len(df)):\n",
    "        if df.iloc[i]['williams'] > -30: # overbought\n",
    "            df.iloc[i, df.columns.get_loc('W_il')] = -1\n",
    "        elif df.iloc[i]['williams'] < -70: # oversold\n",
    "            df.iloc[i, df.columns.get_loc('W_il')] = 1\n",
    "        else:\n",
    "            df.iloc[i, df.columns.get_loc('W_il')] = 0 # neutral\n",
    "    \n",
    "    df['W_il'] = df.W_il.shift(1)\n",
    "#     df['SMA10_il'] = df.SMA10_il.shift(1)\n",
    "    \n",
    "    # deleting data that is not normalized\n",
    "    del df['open']\n",
    "    del df['close']\n",
    "    del df['sma10']\n",
    "    del df['williams']\n",
    "#     del df['close_per1']\n",
    "    \n",
    "    # reformating\n",
    "    df = df[[\n",
    "            'W_il','SMA10_il','CO_il','CP_ol','close_per1'\n",
    "            ]]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            W_il  SMA10_il  CO_il  CP_ol  close_per1\n",
      "date                                                \n",
      "2021-12-17   0.0       1.0      0      1   -6.110265\n",
      "2021-12-20   1.0       0.0      0      1   -5.872415\n",
      "2021-12-21   0.0       0.0      1      2    6.239070\n",
      "2021-12-22   0.0       0.0      0      0    1.984991\n",
      "2021-12-23  -1.0       1.0      1      0    1.898880\n",
      "2021-12-27   0.0       1.0      1      0    2.896196\n",
      "2021-12-28   1.0       1.0      0      0   -0.007553\n",
      "2021-12-29   0.0       1.0      1      0   -0.166026\n",
      "2021-12-30   0.0       1.0      1      0   -0.763470\n",
      "2021-12-31  -1.0       1.0      0      0   -0.706126\n",
      "            W_il  SMA10_il  CO_il  CP_ol  close_per1\n",
      "date                                                \n",
      "2021-12-17   0.0       1.0      0      1   -6.110265\n",
      "2021-12-20   0.0       1.0      0      1   -5.872415\n",
      "2021-12-21   1.0       0.0      1      2    6.239070\n",
      "2021-12-22   0.0       0.0      0      0    1.984991\n",
      "2021-12-23   0.0       0.0      1      0    1.898880\n",
      "2021-12-27  -1.0       1.0      1      0    2.896196\n",
      "2021-12-28   0.0       1.0      0      0   -0.007553\n",
      "2021-12-29   1.0       1.0      1      0   -0.166026\n",
      "2021-12-30   0.0       1.0      1      0   -0.763470\n",
      "2021-12-31   0.0       1.0      0      0   -0.706126\n"
     ]
    }
   ],
   "source": [
    "# # df = set_data(ticker)\n",
    "# # print(data.tail(5))\n",
    "# print(df.tail(10))\n",
    "# df['W_il'] = df.W_il.shift(1)\n",
    "# df['SMA10_il'] = df.SMA10_il.shift(1)\n",
    "# # df['W_il'] = df['W_il'].shift(1)\n",
    "# # df['SMA_il'] = df['SMA_il'].shift(1)\n",
    "# # df['W_il'].shift(1)\n",
    "# # df['SMA_il'].shift(1)\n",
    "# print(df.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_train(tickers, SEQ_LEN, SHIFT):\n",
    "    Sequential_data = []\n",
    "    for ticker in tickers:\n",
    "        df = set_data(ticker)[0:-SHIFT]\n",
    "        \n",
    "        del df['close_per1']\n",
    "\n",
    "        sequential_data = []  # this is a list that will CONTAIN the sequences\n",
    "        prev_days = deque(maxlen=SEQ_LEN)  # These will be our actual sequences. They are made with deque, which keeps the maximum length by popping out older values as new ones come in\n",
    "        \n",
    "        for i in df.values:  # iterate over the values\n",
    "            prev_days.append([n for n in i[:-1]])  # store all but the target\n",
    "            if len(prev_days) == SEQ_LEN:  # make sure we have 60 sequences!\n",
    "                sequential_data.append([np.array(prev_days), i[-1]])  # append those bad boys!\n",
    "        \n",
    "        \n",
    "        random.shuffle(sequential_data)  # shuffle for good measure.\n",
    "        \n",
    "        buy = []; notbuy = []; maybe = []\n",
    "        \n",
    "        for seq, target in sequential_data:  # iterate over the sequential data\n",
    "            if target == 0:\n",
    "                maybe.append([seq, target])\n",
    "            elif target == 1:\n",
    "                notbuy.append([seq, target]) \n",
    "            elif target == 2:\n",
    "                buy.append([seq, target])  \n",
    "        \n",
    "        # suffle data\n",
    "        random.shuffle(buy)\n",
    "        random.shuffle(notbuy)\n",
    "        random.shuffle(maybe)\n",
    "        \n",
    "        lower = min(len(buy), len(notbuy), len(maybe))  # what's the shorter length?\n",
    "        \n",
    "        # make sure lists are only up to the shortest length.\n",
    "        buy = buy[:lower]  \n",
    "        notbuy = notbuy[:lower]\n",
    "        maybe = maybe[:lower]\n",
    "        \n",
    "        sequential_data = buy+notbuy+maybe # add them together\n",
    "        random.shuffle(sequential_data)  # another shuffle, so the model doesn't get confused with all 1 class then the other.\n",
    "    \n",
    "        Sequential_data = Sequential_data + sequential_data\n",
    "        \n",
    "    random.shuffle(Sequential_data)\n",
    "    X = []; y = []\n",
    "    for seq, target in Sequential_data:  # going over our new sequential data\n",
    "        X.append(seq)  # X is the sequences\n",
    "        y.append(target)  # y is the targets/labels (buys vs sell/notbuy)\n",
    "\n",
    "    return np.array(X).astype(\"float64\"), np.array(y).astype(\"uint8\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_test(tickers, SEQ_LEN, SHIFT):\n",
    "    Sequential_data = []\n",
    "    for ticker in tickers:\n",
    "        df = set_data(ticker)[-SHIFT:]\n",
    "        \n",
    "        del df['close_per1']\n",
    "\n",
    "        sequential_data = []  # this is a list that will CONTAIN the sequences\n",
    "        prev_days = deque(maxlen=SEQ_LEN)  # These will be our actual sequences. They are made with deque, which keeps the maximum length by popping out older values as new ones come in\n",
    "        \n",
    "        for i in df.values:  # iterate over the values\n",
    "            prev_days.append([n for n in i[:-1]])  # store all but the target\n",
    "            if len(prev_days) == SEQ_LEN:  # make sure we have 60 sequences!\n",
    "                sequential_data.append([np.array(prev_days), i[-1]])  # append those bad boys!\n",
    "        \n",
    "        \n",
    "        random.shuffle(sequential_data)  # shuffle for good measure.\n",
    "        \n",
    "        buy = []; notbuy = []; maybe = []\n",
    "        \n",
    "        for seq, target in sequential_data:  # iterate over the sequential data\n",
    "            if target == 0:\n",
    "                maybe.append([seq, target])\n",
    "            elif target == 1:\n",
    "                notbuy.append([seq, target]) \n",
    "            elif target == 2:\n",
    "                buy.append([seq, target])  \n",
    "        \n",
    "        # suffle data\n",
    "        random.shuffle(buy)\n",
    "        random.shuffle(notbuy)\n",
    "        random.shuffle(maybe)\n",
    "        \n",
    "        lower = min(len(buy), len(notbuy), len(maybe))  # what's the shorter length?\n",
    "        \n",
    "        # make sure lists are only up to the shortest length.\n",
    "        buy = buy[:lower]  \n",
    "        notbuy = notbuy[:lower]\n",
    "        maybe = maybe[:lower]\n",
    "        \n",
    "        sequential_data = buy+notbuy+maybe # add them together\n",
    "        random.shuffle(sequential_data)  # another shuffle, so the model doesn't get confused with all 1 class then the other.\n",
    "    \n",
    "        Sequential_data = Sequential_data + sequential_data\n",
    "        \n",
    "    random.shuffle(Sequential_data)\n",
    "    X = []; y = []\n",
    "    for seq, target in Sequential_data:  # going over our new sequential data\n",
    "        X.append(seq)  # X is the sequences\n",
    "        y.append(target)  # y is the targets/labels (buys vs sell/notbuy)\n",
    "\n",
    "    return np.array(X).astype(\"float64\"), np.array(y).astype(\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 2  # how long of a preceeding sequence to collect for RNN\n",
    "# FUTURE_PERIOD_PREDICT = 3  # how far into the future are we trying to predict?\n",
    "SHIFT = 150  # how far to shift the data so it can be back testest\n",
    "BATCH_SIZE = 64 # how many batches? Try smaller batch if you're getting OOM (out of memory) errors.\n",
    "EPOCHS = 750 # how many passes through our data\n",
    "\n",
    "\n",
    "tickers_train = [ticker]\n",
    "tickers_test = [ticker]\n",
    "\n",
    "train_x, train_y = process_train(tickers_train, SEQ_LEN,SHIFT)\n",
    "validation_x, validation_y = process_test(tickers_test, SEQ_LEN, SHIFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.  1.  1.]\n",
      " [-1.  1.  0.]]\n",
      "training data length: 162\n",
      "validation data length: 27\n"
     ]
    }
   ],
   "source": [
    "print(train_x[0])\n",
    "print('training data length: %d' % (len(train_x)))\n",
    "print('validation data length: %d' % (len(validation_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "length of train data:  162\n",
      "length of validation data:  27\n",
      "\n",
      "Epoch 1/750\n",
      "3/3 [==============================] - 3s 295ms/step - loss: 1.1574 - accuracy: 0.5000 - val_loss: 1.0958 - val_accuracy: 0.5556\n",
      "Epoch 2/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.1325 - accuracy: 0.5123 - val_loss: 1.0957 - val_accuracy: 0.5556\n",
      "Epoch 3/750\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.1522 - accuracy: 0.4691 - val_loss: 1.0957 - val_accuracy: 0.4444\n",
      "Epoch 4/750\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.1448 - accuracy: 0.4938 - val_loss: 1.0956 - val_accuracy: 0.4444\n",
      "Epoch 5/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.1352 - accuracy: 0.5000 - val_loss: 1.0955 - val_accuracy: 0.4444\n",
      "Epoch 6/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.1299 - accuracy: 0.4938 - val_loss: 1.0954 - val_accuracy: 0.4444\n",
      "Epoch 7/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.1286 - accuracy: 0.4938 - val_loss: 1.0953 - val_accuracy: 0.4444\n",
      "Epoch 8/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.1138 - accuracy: 0.5000 - val_loss: 1.0952 - val_accuracy: 0.4444\n",
      "Epoch 9/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.1221 - accuracy: 0.4938 - val_loss: 1.0951 - val_accuracy: 0.4444\n",
      "Epoch 10/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.1157 - accuracy: 0.5123 - val_loss: 1.0950 - val_accuracy: 0.4074\n",
      "Epoch 11/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.1005 - accuracy: 0.5000 - val_loss: 1.0949 - val_accuracy: 0.4074\n",
      "Epoch 12/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.1005 - accuracy: 0.5000 - val_loss: 1.0948 - val_accuracy: 0.4074\n",
      "Epoch 13/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.0950 - accuracy: 0.4938 - val_loss: 1.0947 - val_accuracy: 0.4074\n",
      "Epoch 14/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.0948 - accuracy: 0.4815 - val_loss: 1.0946 - val_accuracy: 0.4074\n",
      "Epoch 15/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.0828 - accuracy: 0.4938 - val_loss: 1.0945 - val_accuracy: 0.4074\n",
      "Epoch 16/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.0987 - accuracy: 0.5062 - val_loss: 1.0943 - val_accuracy: 0.3704\n",
      "Epoch 17/750\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.0811 - accuracy: 0.5000 - val_loss: 1.0942 - val_accuracy: 0.3704\n",
      "Epoch 18/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.0735 - accuracy: 0.5000 - val_loss: 1.0941 - val_accuracy: 0.3704\n",
      "Epoch 19/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.0832 - accuracy: 0.4877 - val_loss: 1.0940 - val_accuracy: 0.3704\n",
      "Epoch 20/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.0585 - accuracy: 0.5000 - val_loss: 1.0939 - val_accuracy: 0.3333\n",
      "Epoch 21/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.0758 - accuracy: 0.4938 - val_loss: 1.0937 - val_accuracy: 0.3333\n",
      "Epoch 22/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.0617 - accuracy: 0.4877 - val_loss: 1.0936 - val_accuracy: 0.3333\n",
      "Epoch 23/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.0563 - accuracy: 0.5062 - val_loss: 1.0935 - val_accuracy: 0.3333\n",
      "Epoch 24/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.0471 - accuracy: 0.5000 - val_loss: 1.0933 - val_accuracy: 0.3333\n",
      "Epoch 25/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.0508 - accuracy: 0.5000 - val_loss: 1.0932 - val_accuracy: 0.3333\n",
      "Epoch 26/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.0367 - accuracy: 0.4938 - val_loss: 1.0930 - val_accuracy: 0.3704\n",
      "Epoch 27/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.0373 - accuracy: 0.5062 - val_loss: 1.0929 - val_accuracy: 0.3704\n",
      "Epoch 28/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.0310 - accuracy: 0.5123 - val_loss: 1.0927 - val_accuracy: 0.3704\n",
      "Epoch 29/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.0257 - accuracy: 0.4877 - val_loss: 1.0926 - val_accuracy: 0.3704\n",
      "Epoch 30/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.0265 - accuracy: 0.5000 - val_loss: 1.0924 - val_accuracy: 0.3704\n",
      "Epoch 31/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.0335 - accuracy: 0.5123 - val_loss: 1.0922 - val_accuracy: 0.3704\n",
      "Epoch 32/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.0269 - accuracy: 0.5000 - val_loss: 1.0920 - val_accuracy: 0.3704\n",
      "Epoch 33/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.0283 - accuracy: 0.5000 - val_loss: 1.0919 - val_accuracy: 0.3704\n",
      "Epoch 34/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.0126 - accuracy: 0.5000 - val_loss: 1.0917 - val_accuracy: 0.3704\n",
      "Epoch 35/750\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.0184 - accuracy: 0.5123 - val_loss: 1.0915 - val_accuracy: 0.3704\n",
      "Epoch 36/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.0064 - accuracy: 0.5062 - val_loss: 1.0913 - val_accuracy: 0.3704\n",
      "Epoch 37/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.0090 - accuracy: 0.5185 - val_loss: 1.0911 - val_accuracy: 0.3704\n",
      "Epoch 38/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.0146 - accuracy: 0.5062 - val_loss: 1.0909 - val_accuracy: 0.3704\n",
      "Epoch 39/750\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.9932 - accuracy: 0.5370 - val_loss: 1.0907 - val_accuracy: 0.3704\n",
      "Epoch 40/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9999 - accuracy: 0.5123 - val_loss: 1.0904 - val_accuracy: 0.3704\n",
      "Epoch 41/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9977 - accuracy: 0.5123 - val_loss: 1.0902 - val_accuracy: 0.3704\n",
      "Epoch 42/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.0003 - accuracy: 0.5185 - val_loss: 1.0900 - val_accuracy: 0.3704\n",
      "Epoch 43/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.9908 - accuracy: 0.5370 - val_loss: 1.0897 - val_accuracy: 0.3704\n",
      "Epoch 44/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9925 - accuracy: 0.5185 - val_loss: 1.0895 - val_accuracy: 0.3704\n",
      "Epoch 45/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9902 - accuracy: 0.5247 - val_loss: 1.0892 - val_accuracy: 0.3704\n",
      "Epoch 46/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9853 - accuracy: 0.5370 - val_loss: 1.0890 - val_accuracy: 0.3704\n",
      "Epoch 47/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9856 - accuracy: 0.5370 - val_loss: 1.0887 - val_accuracy: 0.3704\n",
      "Epoch 48/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9944 - accuracy: 0.5370 - val_loss: 1.0884 - val_accuracy: 0.3704\n",
      "Epoch 49/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9787 - accuracy: 0.5370 - val_loss: 1.0881 - val_accuracy: 0.3704\n",
      "Epoch 50/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9725 - accuracy: 0.5185 - val_loss: 1.0878 - val_accuracy: 0.3704\n",
      "Epoch 51/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9718 - accuracy: 0.5309 - val_loss: 1.0875 - val_accuracy: 0.3704\n",
      "Epoch 52/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9720 - accuracy: 0.5617 - val_loss: 1.0872 - val_accuracy: 0.3704\n",
      "Epoch 53/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9799 - accuracy: 0.5556 - val_loss: 1.0869 - val_accuracy: 0.3704\n",
      "Epoch 54/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9645 - accuracy: 0.5617 - val_loss: 1.0866 - val_accuracy: 0.3704\n",
      "Epoch 55/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9721 - accuracy: 0.5617 - val_loss: 1.0862 - val_accuracy: 0.3704\n",
      "Epoch 56/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9633 - accuracy: 0.5617 - val_loss: 1.0859 - val_accuracy: 0.3704\n",
      "Epoch 57/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.9629 - accuracy: 0.5556 - val_loss: 1.0855 - val_accuracy: 0.3704\n",
      "Epoch 58/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.9637 - accuracy: 0.5864 - val_loss: 1.0852 - val_accuracy: 0.3704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.9602 - accuracy: 0.5802 - val_loss: 1.0848 - val_accuracy: 0.3704\n",
      "Epoch 60/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.9582 - accuracy: 0.5741 - val_loss: 1.0844 - val_accuracy: 0.3704\n",
      "Epoch 61/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9668 - accuracy: 0.5679 - val_loss: 1.0841 - val_accuracy: 0.3704\n",
      "Epoch 62/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.9516 - accuracy: 0.5679 - val_loss: 1.0837 - val_accuracy: 0.3704\n",
      "Epoch 63/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.9473 - accuracy: 0.5679 - val_loss: 1.0833 - val_accuracy: 0.3704\n",
      "Epoch 64/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9582 - accuracy: 0.5617 - val_loss: 1.0829 - val_accuracy: 0.3704\n",
      "Epoch 65/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.9486 - accuracy: 0.5864 - val_loss: 1.0824 - val_accuracy: 0.3704\n",
      "Epoch 66/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.9564 - accuracy: 0.5679 - val_loss: 1.0820 - val_accuracy: 0.3704\n",
      "Epoch 67/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.9398 - accuracy: 0.5741 - val_loss: 1.0815 - val_accuracy: 0.3704\n",
      "Epoch 68/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9461 - accuracy: 0.5864 - val_loss: 1.0811 - val_accuracy: 0.3704\n",
      "Epoch 69/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.9480 - accuracy: 0.5679 - val_loss: 1.0806 - val_accuracy: 0.3704\n",
      "Epoch 70/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9445 - accuracy: 0.5864 - val_loss: 1.0801 - val_accuracy: 0.3704\n",
      "Epoch 71/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.9404 - accuracy: 0.5741 - val_loss: 1.0796 - val_accuracy: 0.3704\n",
      "Epoch 72/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9367 - accuracy: 0.5741 - val_loss: 1.0791 - val_accuracy: 0.3704\n",
      "Epoch 73/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9452 - accuracy: 0.5802 - val_loss: 1.0786 - val_accuracy: 0.3704\n",
      "Epoch 74/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9575 - accuracy: 0.5617 - val_loss: 1.0780 - val_accuracy: 0.3704\n",
      "Epoch 75/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9368 - accuracy: 0.5802 - val_loss: 1.0775 - val_accuracy: 0.3704\n",
      "Epoch 76/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9369 - accuracy: 0.5741 - val_loss: 1.0769 - val_accuracy: 0.3704\n",
      "Epoch 77/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9467 - accuracy: 0.5741 - val_loss: 1.0763 - val_accuracy: 0.3704\n",
      "Epoch 78/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9334 - accuracy: 0.5926 - val_loss: 1.0757 - val_accuracy: 0.3704\n",
      "Epoch 79/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9372 - accuracy: 0.5802 - val_loss: 1.0751 - val_accuracy: 0.3704\n",
      "Epoch 80/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9314 - accuracy: 0.5679 - val_loss: 1.0745 - val_accuracy: 0.3704\n",
      "Epoch 81/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9326 - accuracy: 0.5802 - val_loss: 1.0739 - val_accuracy: 0.3704\n",
      "Epoch 82/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9286 - accuracy: 0.5802 - val_loss: 1.0732 - val_accuracy: 0.3704\n",
      "Epoch 83/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9265 - accuracy: 0.5617 - val_loss: 1.0725 - val_accuracy: 0.3704\n",
      "Epoch 84/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9299 - accuracy: 0.5864 - val_loss: 1.0719 - val_accuracy: 0.3704\n",
      "Epoch 85/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9218 - accuracy: 0.5802 - val_loss: 1.0712 - val_accuracy: 0.3704\n",
      "Epoch 86/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9206 - accuracy: 0.6049 - val_loss: 1.0705 - val_accuracy: 0.4074\n",
      "Epoch 87/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9200 - accuracy: 0.5802 - val_loss: 1.0697 - val_accuracy: 0.4074\n",
      "Epoch 88/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9200 - accuracy: 0.5988 - val_loss: 1.0690 - val_accuracy: 0.4074\n",
      "Epoch 89/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9220 - accuracy: 0.5802 - val_loss: 1.0683 - val_accuracy: 0.4074\n",
      "Epoch 90/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9231 - accuracy: 0.5679 - val_loss: 1.0675 - val_accuracy: 0.3704\n",
      "Epoch 91/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9194 - accuracy: 0.5926 - val_loss: 1.0667 - val_accuracy: 0.3704\n",
      "Epoch 92/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.9170 - accuracy: 0.5926 - val_loss: 1.0659 - val_accuracy: 0.3704\n",
      "Epoch 93/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9092 - accuracy: 0.5926 - val_loss: 1.0651 - val_accuracy: 0.3704\n",
      "Epoch 94/750\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.9149 - accuracy: 0.5864 - val_loss: 1.0643 - val_accuracy: 0.3704\n",
      "Epoch 95/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9161 - accuracy: 0.5802 - val_loss: 1.0635 - val_accuracy: 0.3704\n",
      "Epoch 96/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9090 - accuracy: 0.5802 - val_loss: 1.0627 - val_accuracy: 0.3704\n",
      "Epoch 97/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9134 - accuracy: 0.5988 - val_loss: 1.0619 - val_accuracy: 0.3704\n",
      "Epoch 98/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9126 - accuracy: 0.5741 - val_loss: 1.0610 - val_accuracy: 0.4074\n",
      "Epoch 99/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9072 - accuracy: 0.5864 - val_loss: 1.0602 - val_accuracy: 0.4074\n",
      "Epoch 100/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9105 - accuracy: 0.5741 - val_loss: 1.0593 - val_accuracy: 0.4074\n",
      "Epoch 101/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9016 - accuracy: 0.5679 - val_loss: 1.0585 - val_accuracy: 0.4074\n",
      "Epoch 102/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9137 - accuracy: 0.5864 - val_loss: 1.0576 - val_accuracy: 0.4074\n",
      "Epoch 103/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9057 - accuracy: 0.5864 - val_loss: 1.0567 - val_accuracy: 0.4074\n",
      "Epoch 104/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9037 - accuracy: 0.5988 - val_loss: 1.0557 - val_accuracy: 0.4074\n",
      "Epoch 105/750\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.8982 - accuracy: 0.5926 - val_loss: 1.0548 - val_accuracy: 0.4074\n",
      "Epoch 106/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9046 - accuracy: 0.6111 - val_loss: 1.0538 - val_accuracy: 0.4074\n",
      "Epoch 107/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8999 - accuracy: 0.5988 - val_loss: 1.0529 - val_accuracy: 0.4074\n",
      "Epoch 108/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9043 - accuracy: 0.5926 - val_loss: 1.0519 - val_accuracy: 0.4074\n",
      "Epoch 109/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.9004 - accuracy: 0.5926 - val_loss: 1.0509 - val_accuracy: 0.4074\n",
      "Epoch 110/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9029 - accuracy: 0.5864 - val_loss: 1.0499 - val_accuracy: 0.4074\n",
      "Epoch 111/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8890 - accuracy: 0.5926 - val_loss: 1.0489 - val_accuracy: 0.4074\n",
      "Epoch 112/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8989 - accuracy: 0.5864 - val_loss: 1.0478 - val_accuracy: 0.4074\n",
      "Epoch 113/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8912 - accuracy: 0.6173 - val_loss: 1.0468 - val_accuracy: 0.4074\n",
      "Epoch 114/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8983 - accuracy: 0.5926 - val_loss: 1.0457 - val_accuracy: 0.4074\n",
      "Epoch 115/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9026 - accuracy: 0.5864 - val_loss: 1.0445 - val_accuracy: 0.4074\n",
      "Epoch 116/750\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.8936 - accuracy: 0.5926 - val_loss: 1.0435 - val_accuracy: 0.4074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9012 - accuracy: 0.5864 - val_loss: 1.0424 - val_accuracy: 0.4074\n",
      "Epoch 118/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.8824 - accuracy: 0.5926 - val_loss: 1.0412 - val_accuracy: 0.4074\n",
      "Epoch 119/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9032 - accuracy: 0.5864 - val_loss: 1.0401 - val_accuracy: 0.4074\n",
      "Epoch 120/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9021 - accuracy: 0.5802 - val_loss: 1.0389 - val_accuracy: 0.4074\n",
      "Epoch 121/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.9005 - accuracy: 0.5988 - val_loss: 1.0378 - val_accuracy: 0.4074\n",
      "Epoch 122/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.8894 - accuracy: 0.5802 - val_loss: 1.0366 - val_accuracy: 0.4074\n",
      "Epoch 123/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8937 - accuracy: 0.5988 - val_loss: 1.0354 - val_accuracy: 0.4074\n",
      "Epoch 124/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.8909 - accuracy: 0.5802 - val_loss: 1.0342 - val_accuracy: 0.4074\n",
      "Epoch 125/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.8952 - accuracy: 0.5988 - val_loss: 1.0331 - val_accuracy: 0.4074\n",
      "Epoch 126/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8830 - accuracy: 0.5926 - val_loss: 1.0319 - val_accuracy: 0.4074\n",
      "Epoch 127/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.8899 - accuracy: 0.5864 - val_loss: 1.0307 - val_accuracy: 0.4074\n",
      "Epoch 128/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8926 - accuracy: 0.5988 - val_loss: 1.0294 - val_accuracy: 0.4074\n",
      "Epoch 129/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8815 - accuracy: 0.5988 - val_loss: 1.0282 - val_accuracy: 0.4074\n",
      "Epoch 130/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8874 - accuracy: 0.5926 - val_loss: 1.0269 - val_accuracy: 0.4074\n",
      "Epoch 131/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.8803 - accuracy: 0.6111 - val_loss: 1.0256 - val_accuracy: 0.4074\n",
      "Epoch 132/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.8802 - accuracy: 0.5864 - val_loss: 1.0243 - val_accuracy: 0.4074\n",
      "Epoch 133/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.8945 - accuracy: 0.5802 - val_loss: 1.0230 - val_accuracy: 0.4074\n",
      "Epoch 134/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.8784 - accuracy: 0.5926 - val_loss: 1.0217 - val_accuracy: 0.4074\n",
      "Epoch 135/750\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8775 - accuracy: 0.5802 - val_loss: 1.0205 - val_accuracy: 0.4074\n",
      "Epoch 136/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.8935 - accuracy: 0.5988 - val_loss: 1.0193 - val_accuracy: 0.4074\n",
      "Epoch 137/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8748 - accuracy: 0.5926 - val_loss: 1.0180 - val_accuracy: 0.4074\n",
      "Epoch 138/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.8828 - accuracy: 0.6111 - val_loss: 1.0167 - val_accuracy: 0.4074\n",
      "Epoch 139/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8873 - accuracy: 0.5864 - val_loss: 1.0155 - val_accuracy: 0.4074\n",
      "Epoch 140/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.8799 - accuracy: 0.5679 - val_loss: 1.0142 - val_accuracy: 0.4074\n",
      "Epoch 141/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8900 - accuracy: 0.5802 - val_loss: 1.0129 - val_accuracy: 0.4074\n",
      "Epoch 142/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.8876 - accuracy: 0.5864 - val_loss: 1.0115 - val_accuracy: 0.4074\n",
      "Epoch 143/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8795 - accuracy: 0.5864 - val_loss: 1.0102 - val_accuracy: 0.4074\n",
      "Epoch 144/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.8747 - accuracy: 0.5741 - val_loss: 1.0088 - val_accuracy: 0.4074\n",
      "Epoch 145/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8665 - accuracy: 0.5926 - val_loss: 1.0074 - val_accuracy: 0.4074\n",
      "Epoch 146/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.8758 - accuracy: 0.5864 - val_loss: 1.0059 - val_accuracy: 0.4074\n",
      "Epoch 147/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.8850 - accuracy: 0.5988 - val_loss: 1.0043 - val_accuracy: 0.4074\n",
      "Epoch 148/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.8651 - accuracy: 0.5988 - val_loss: 1.0029 - val_accuracy: 0.4074\n",
      "Epoch 149/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.8665 - accuracy: 0.5741 - val_loss: 1.0013 - val_accuracy: 0.4074\n",
      "Epoch 150/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8750 - accuracy: 0.5926 - val_loss: 0.9997 - val_accuracy: 0.4074\n",
      "Epoch 151/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.8741 - accuracy: 0.5988 - val_loss: 0.9981 - val_accuracy: 0.4074\n",
      "Epoch 152/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8715 - accuracy: 0.5864 - val_loss: 0.9967 - val_accuracy: 0.4815\n",
      "Epoch 153/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8637 - accuracy: 0.5864 - val_loss: 0.9951 - val_accuracy: 0.4815\n",
      "Epoch 154/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8700 - accuracy: 0.5988 - val_loss: 0.9936 - val_accuracy: 0.4815\n",
      "Epoch 155/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8694 - accuracy: 0.5926 - val_loss: 0.9921 - val_accuracy: 0.4815\n",
      "Epoch 156/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8653 - accuracy: 0.5988 - val_loss: 0.9906 - val_accuracy: 0.4815\n",
      "Epoch 157/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8685 - accuracy: 0.6049 - val_loss: 0.9891 - val_accuracy: 0.4815\n",
      "Epoch 158/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8707 - accuracy: 0.5802 - val_loss: 0.9875 - val_accuracy: 0.4815\n",
      "Epoch 159/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8688 - accuracy: 0.6420 - val_loss: 0.9859 - val_accuracy: 0.5185\n",
      "Epoch 160/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8643 - accuracy: 0.6049 - val_loss: 0.9844 - val_accuracy: 0.5185\n",
      "Epoch 161/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.8693 - accuracy: 0.5926 - val_loss: 0.9829 - val_accuracy: 0.5185\n",
      "Epoch 162/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8584 - accuracy: 0.6049 - val_loss: 0.9813 - val_accuracy: 0.5185\n",
      "Epoch 163/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8645 - accuracy: 0.6111 - val_loss: 0.9798 - val_accuracy: 0.5185\n",
      "Epoch 164/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8635 - accuracy: 0.5864 - val_loss: 0.9783 - val_accuracy: 0.5185\n",
      "Epoch 165/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8611 - accuracy: 0.5864 - val_loss: 0.9768 - val_accuracy: 0.5185\n",
      "Epoch 166/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8712 - accuracy: 0.5988 - val_loss: 0.9752 - val_accuracy: 0.5185\n",
      "Epoch 167/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8631 - accuracy: 0.6173 - val_loss: 0.9734 - val_accuracy: 0.5926\n",
      "Epoch 168/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8657 - accuracy: 0.5926 - val_loss: 0.9719 - val_accuracy: 0.5926\n",
      "Epoch 169/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8605 - accuracy: 0.5988 - val_loss: 0.9703 - val_accuracy: 0.5926\n",
      "Epoch 170/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8518 - accuracy: 0.5926 - val_loss: 0.9687 - val_accuracy: 0.5926\n",
      "Epoch 171/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8658 - accuracy: 0.5926 - val_loss: 0.9670 - val_accuracy: 0.5926\n",
      "Epoch 172/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.8688 - accuracy: 0.6049 - val_loss: 0.9654 - val_accuracy: 0.5926\n",
      "Epoch 173/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8635 - accuracy: 0.6235 - val_loss: 0.9638 - val_accuracy: 0.5926\n",
      "Epoch 174/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8642 - accuracy: 0.5864 - val_loss: 0.9621 - val_accuracy: 0.5926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8589 - accuracy: 0.6049 - val_loss: 0.9604 - val_accuracy: 0.5926\n",
      "Epoch 176/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8520 - accuracy: 0.6111 - val_loss: 0.9588 - val_accuracy: 0.5926\n",
      "Epoch 177/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.8647 - accuracy: 0.5926 - val_loss: 0.9572 - val_accuracy: 0.5926\n",
      "Epoch 178/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.8620 - accuracy: 0.6049 - val_loss: 0.9557 - val_accuracy: 0.5926\n",
      "Epoch 179/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8645 - accuracy: 0.5926 - val_loss: 0.9542 - val_accuracy: 0.5926\n",
      "Epoch 180/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8506 - accuracy: 0.6235 - val_loss: 0.9527 - val_accuracy: 0.5556\n",
      "Epoch 181/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8504 - accuracy: 0.6111 - val_loss: 0.9511 - val_accuracy: 0.5556\n",
      "Epoch 182/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8657 - accuracy: 0.6111 - val_loss: 0.9496 - val_accuracy: 0.5556\n",
      "Epoch 183/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8518 - accuracy: 0.5926 - val_loss: 0.9481 - val_accuracy: 0.5556\n",
      "Epoch 184/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8572 - accuracy: 0.5926 - val_loss: 0.9466 - val_accuracy: 0.5556\n",
      "Epoch 185/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.8640 - accuracy: 0.5802 - val_loss: 0.9450 - val_accuracy: 0.5556\n",
      "Epoch 186/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8530 - accuracy: 0.6049 - val_loss: 0.9435 - val_accuracy: 0.5926\n",
      "Epoch 187/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8535 - accuracy: 0.5988 - val_loss: 0.9419 - val_accuracy: 0.5926\n",
      "Epoch 188/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8544 - accuracy: 0.5988 - val_loss: 0.9403 - val_accuracy: 0.5926\n",
      "Epoch 189/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8519 - accuracy: 0.6111 - val_loss: 0.9386 - val_accuracy: 0.5926\n",
      "Epoch 190/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8426 - accuracy: 0.6111 - val_loss: 0.9370 - val_accuracy: 0.5926\n",
      "Epoch 191/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8500 - accuracy: 0.6296 - val_loss: 0.9354 - val_accuracy: 0.5926\n",
      "Epoch 192/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8632 - accuracy: 0.6049 - val_loss: 0.9340 - val_accuracy: 0.5926\n",
      "Epoch 193/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8554 - accuracy: 0.5988 - val_loss: 0.9324 - val_accuracy: 0.5926\n",
      "Epoch 194/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8476 - accuracy: 0.6481 - val_loss: 0.9308 - val_accuracy: 0.5926\n",
      "Epoch 195/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8524 - accuracy: 0.5926 - val_loss: 0.9294 - val_accuracy: 0.5926\n",
      "Epoch 196/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8471 - accuracy: 0.6049 - val_loss: 0.9279 - val_accuracy: 0.5926\n",
      "Epoch 197/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8460 - accuracy: 0.6173 - val_loss: 0.9263 - val_accuracy: 0.5926\n",
      "Epoch 198/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.8639 - accuracy: 0.6235 - val_loss: 0.9247 - val_accuracy: 0.5926\n",
      "Epoch 199/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.8505 - accuracy: 0.6173 - val_loss: 0.9232 - val_accuracy: 0.5926\n",
      "Epoch 200/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8453 - accuracy: 0.5988 - val_loss: 0.9217 - val_accuracy: 0.5926\n",
      "Epoch 201/750\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.8598 - accuracy: 0.6296 - val_loss: 0.9201 - val_accuracy: 0.5926\n",
      "Epoch 202/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.8455 - accuracy: 0.6358 - val_loss: 0.9184 - val_accuracy: 0.5926\n",
      "Epoch 203/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.8387 - accuracy: 0.6420 - val_loss: 0.9168 - val_accuracy: 0.5926\n",
      "Epoch 204/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.8450 - accuracy: 0.6667 - val_loss: 0.9153 - val_accuracy: 0.5926\n",
      "Epoch 205/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8388 - accuracy: 0.6111 - val_loss: 0.9138 - val_accuracy: 0.5926\n",
      "Epoch 206/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8482 - accuracy: 0.6358 - val_loss: 0.9123 - val_accuracy: 0.5926\n",
      "Epoch 207/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.8319 - accuracy: 0.6481 - val_loss: 0.9107 - val_accuracy: 0.5926\n",
      "Epoch 208/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8455 - accuracy: 0.6235 - val_loss: 0.9094 - val_accuracy: 0.5926\n",
      "Epoch 209/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8369 - accuracy: 0.6420 - val_loss: 0.9080 - val_accuracy: 0.5926\n",
      "Epoch 210/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.8305 - accuracy: 0.6235 - val_loss: 0.9064 - val_accuracy: 0.5926\n",
      "Epoch 211/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.8391 - accuracy: 0.6296 - val_loss: 0.9049 - val_accuracy: 0.5926\n",
      "Epoch 212/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.8393 - accuracy: 0.6420 - val_loss: 0.9034 - val_accuracy: 0.5926\n",
      "Epoch 213/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.8287 - accuracy: 0.6543 - val_loss: 0.9019 - val_accuracy: 0.5926\n",
      "Epoch 214/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.8438 - accuracy: 0.5988 - val_loss: 0.9004 - val_accuracy: 0.5926\n",
      "Epoch 215/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8304 - accuracy: 0.6420 - val_loss: 0.8988 - val_accuracy: 0.5926\n",
      "Epoch 216/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.8326 - accuracy: 0.6358 - val_loss: 0.8974 - val_accuracy: 0.5926\n",
      "Epoch 217/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8419 - accuracy: 0.6481 - val_loss: 0.8960 - val_accuracy: 0.5926\n",
      "Epoch 218/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8497 - accuracy: 0.6111 - val_loss: 0.8948 - val_accuracy: 0.5926\n",
      "Epoch 219/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8469 - accuracy: 0.6235 - val_loss: 0.8934 - val_accuracy: 0.5926\n",
      "Epoch 220/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8233 - accuracy: 0.6790 - val_loss: 0.8921 - val_accuracy: 0.5926\n",
      "Epoch 221/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8280 - accuracy: 0.6543 - val_loss: 0.8908 - val_accuracy: 0.5926\n",
      "Epoch 222/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8348 - accuracy: 0.6605 - val_loss: 0.8896 - val_accuracy: 0.5926\n",
      "Epoch 223/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8442 - accuracy: 0.6543 - val_loss: 0.8884 - val_accuracy: 0.5926\n",
      "Epoch 224/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8334 - accuracy: 0.6235 - val_loss: 0.8873 - val_accuracy: 0.6296\n",
      "Epoch 225/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8328 - accuracy: 0.6111 - val_loss: 0.8860 - val_accuracy: 0.6296\n",
      "Epoch 226/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8380 - accuracy: 0.6543 - val_loss: 0.8848 - val_accuracy: 0.6296\n",
      "Epoch 227/750\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.8391 - accuracy: 0.6420 - val_loss: 0.8835 - val_accuracy: 0.6296\n",
      "Epoch 228/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8365 - accuracy: 0.6481 - val_loss: 0.8826 - val_accuracy: 0.6296\n",
      "Epoch 229/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8294 - accuracy: 0.6296 - val_loss: 0.8815 - val_accuracy: 0.6296\n",
      "Epoch 230/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8336 - accuracy: 0.6420 - val_loss: 0.8804 - val_accuracy: 0.6296\n",
      "Epoch 231/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8310 - accuracy: 0.6296 - val_loss: 0.8793 - val_accuracy: 0.6296\n",
      "Epoch 232/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8399 - accuracy: 0.6173 - val_loss: 0.8781 - val_accuracy: 0.6296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8321 - accuracy: 0.6481 - val_loss: 0.8770 - val_accuracy: 0.6296\n",
      "Epoch 234/750\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.8216 - accuracy: 0.6420 - val_loss: 0.8759 - val_accuracy: 0.6296\n",
      "Epoch 235/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8335 - accuracy: 0.6543 - val_loss: 0.8749 - val_accuracy: 0.6296\n",
      "Epoch 236/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8267 - accuracy: 0.6605 - val_loss: 0.8738 - val_accuracy: 0.6296\n",
      "Epoch 237/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8329 - accuracy: 0.6358 - val_loss: 0.8728 - val_accuracy: 0.6296\n",
      "Epoch 238/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8210 - accuracy: 0.6420 - val_loss: 0.8718 - val_accuracy: 0.6296\n",
      "Epoch 239/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.8337 - accuracy: 0.6420 - val_loss: 0.8709 - val_accuracy: 0.6296\n",
      "Epoch 240/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8284 - accuracy: 0.6543 - val_loss: 0.8699 - val_accuracy: 0.6296\n",
      "Epoch 241/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8226 - accuracy: 0.6728 - val_loss: 0.8691 - val_accuracy: 0.6296\n",
      "Epoch 242/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8235 - accuracy: 0.6420 - val_loss: 0.8681 - val_accuracy: 0.6296\n",
      "Epoch 243/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8326 - accuracy: 0.6481 - val_loss: 0.8669 - val_accuracy: 0.6296\n",
      "Epoch 244/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8311 - accuracy: 0.6296 - val_loss: 0.8656 - val_accuracy: 0.6296\n",
      "Epoch 245/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8207 - accuracy: 0.6605 - val_loss: 0.8646 - val_accuracy: 0.6296\n",
      "Epoch 246/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8261 - accuracy: 0.6358 - val_loss: 0.8636 - val_accuracy: 0.6296\n",
      "Epoch 247/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8133 - accuracy: 0.6605 - val_loss: 0.8625 - val_accuracy: 0.6296\n",
      "Epoch 248/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8229 - accuracy: 0.6667 - val_loss: 0.8617 - val_accuracy: 0.6296\n",
      "Epoch 249/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8208 - accuracy: 0.6790 - val_loss: 0.8605 - val_accuracy: 0.6296\n",
      "Epoch 250/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8400 - accuracy: 0.6235 - val_loss: 0.8594 - val_accuracy: 0.6296\n",
      "Epoch 251/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8224 - accuracy: 0.6543 - val_loss: 0.8582 - val_accuracy: 0.6296\n",
      "Epoch 252/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8249 - accuracy: 0.6543 - val_loss: 0.8574 - val_accuracy: 0.6296\n",
      "Epoch 253/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8241 - accuracy: 0.6605 - val_loss: 0.8565 - val_accuracy: 0.6296\n",
      "Epoch 254/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8122 - accuracy: 0.6358 - val_loss: 0.8558 - val_accuracy: 0.6667\n",
      "Epoch 255/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8183 - accuracy: 0.6605 - val_loss: 0.8548 - val_accuracy: 0.6667\n",
      "Epoch 256/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8244 - accuracy: 0.6481 - val_loss: 0.8541 - val_accuracy: 0.6667\n",
      "Epoch 257/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8187 - accuracy: 0.6605 - val_loss: 0.8535 - val_accuracy: 0.6667\n",
      "Epoch 258/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8214 - accuracy: 0.6667 - val_loss: 0.8527 - val_accuracy: 0.6667\n",
      "Epoch 259/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8196 - accuracy: 0.6605 - val_loss: 0.8519 - val_accuracy: 0.6667\n",
      "Epoch 260/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8259 - accuracy: 0.6543 - val_loss: 0.8514 - val_accuracy: 0.6667\n",
      "Epoch 261/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8219 - accuracy: 0.6358 - val_loss: 0.8506 - val_accuracy: 0.6667\n",
      "Epoch 262/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8175 - accuracy: 0.6605 - val_loss: 0.8499 - val_accuracy: 0.6667\n",
      "Epoch 263/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8141 - accuracy: 0.6605 - val_loss: 0.8492 - val_accuracy: 0.6667\n",
      "Epoch 264/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8082 - accuracy: 0.6790 - val_loss: 0.8485 - val_accuracy: 0.6667\n",
      "Epoch 265/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8135 - accuracy: 0.6605 - val_loss: 0.8479 - val_accuracy: 0.6667\n",
      "Epoch 266/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8167 - accuracy: 0.6481 - val_loss: 0.8472 - val_accuracy: 0.6667\n",
      "Epoch 267/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8229 - accuracy: 0.6605 - val_loss: 0.8465 - val_accuracy: 0.6667\n",
      "Epoch 268/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.8203 - accuracy: 0.6667 - val_loss: 0.8460 - val_accuracy: 0.6667\n",
      "Epoch 269/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8097 - accuracy: 0.6728 - val_loss: 0.8453 - val_accuracy: 0.6667\n",
      "Epoch 270/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8176 - accuracy: 0.6667 - val_loss: 0.8444 - val_accuracy: 0.6667\n",
      "Epoch 271/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8156 - accuracy: 0.6481 - val_loss: 0.8435 - val_accuracy: 0.6667\n",
      "Epoch 272/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8257 - accuracy: 0.6481 - val_loss: 0.8427 - val_accuracy: 0.6667\n",
      "Epoch 273/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8213 - accuracy: 0.6358 - val_loss: 0.8420 - val_accuracy: 0.6667\n",
      "Epoch 274/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8111 - accuracy: 0.6667 - val_loss: 0.8412 - val_accuracy: 0.6667\n",
      "Epoch 275/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8150 - accuracy: 0.6605 - val_loss: 0.8405 - val_accuracy: 0.6667\n",
      "Epoch 276/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8078 - accuracy: 0.6667 - val_loss: 0.8399 - val_accuracy: 0.6667\n",
      "Epoch 277/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8038 - accuracy: 0.6728 - val_loss: 0.8394 - val_accuracy: 0.6667\n",
      "Epoch 278/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8132 - accuracy: 0.6543 - val_loss: 0.8391 - val_accuracy: 0.6667\n",
      "Epoch 279/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8213 - accuracy: 0.6790 - val_loss: 0.8385 - val_accuracy: 0.6667\n",
      "Epoch 280/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8111 - accuracy: 0.6481 - val_loss: 0.8381 - val_accuracy: 0.6667\n",
      "Epoch 281/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8108 - accuracy: 0.6790 - val_loss: 0.8372 - val_accuracy: 0.6667\n",
      "Epoch 282/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8150 - accuracy: 0.6543 - val_loss: 0.8367 - val_accuracy: 0.6667\n",
      "Epoch 283/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8166 - accuracy: 0.6605 - val_loss: 0.8362 - val_accuracy: 0.6667\n",
      "Epoch 284/750\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.8132 - accuracy: 0.6667 - val_loss: 0.8356 - val_accuracy: 0.6667\n",
      "Epoch 285/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8216 - accuracy: 0.6790 - val_loss: 0.8350 - val_accuracy: 0.6667\n",
      "Epoch 286/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8100 - accuracy: 0.6790 - val_loss: 0.8345 - val_accuracy: 0.6667\n",
      "Epoch 287/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8065 - accuracy: 0.6481 - val_loss: 0.8339 - val_accuracy: 0.6667\n",
      "Epoch 288/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8027 - accuracy: 0.6790 - val_loss: 0.8333 - val_accuracy: 0.6667\n",
      "Epoch 289/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8229 - accuracy: 0.6543 - val_loss: 0.8325 - val_accuracy: 0.6667\n",
      "Epoch 290/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8200 - accuracy: 0.6605 - val_loss: 0.8318 - val_accuracy: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 291/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8102 - accuracy: 0.6852 - val_loss: 0.8310 - val_accuracy: 0.6667\n",
      "Epoch 292/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8256 - accuracy: 0.6481 - val_loss: 0.8302 - val_accuracy: 0.6667\n",
      "Epoch 293/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8122 - accuracy: 0.6728 - val_loss: 0.8297 - val_accuracy: 0.6667\n",
      "Epoch 294/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8049 - accuracy: 0.6667 - val_loss: 0.8290 - val_accuracy: 0.6667\n",
      "Epoch 295/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8037 - accuracy: 0.6543 - val_loss: 0.8284 - val_accuracy: 0.6667\n",
      "Epoch 296/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8076 - accuracy: 0.6605 - val_loss: 0.8278 - val_accuracy: 0.6667\n",
      "Epoch 297/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8151 - accuracy: 0.6790 - val_loss: 0.8270 - val_accuracy: 0.6667\n",
      "Epoch 298/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8014 - accuracy: 0.6790 - val_loss: 0.8263 - val_accuracy: 0.6667\n",
      "Epoch 299/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8015 - accuracy: 0.6605 - val_loss: 0.8258 - val_accuracy: 0.6667\n",
      "Epoch 300/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8109 - accuracy: 0.6728 - val_loss: 0.8254 - val_accuracy: 0.6667\n",
      "Epoch 301/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8035 - accuracy: 0.6481 - val_loss: 0.8250 - val_accuracy: 0.6667\n",
      "Epoch 302/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8002 - accuracy: 0.6667 - val_loss: 0.8246 - val_accuracy: 0.6667\n",
      "Epoch 303/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.8014 - accuracy: 0.6667 - val_loss: 0.8243 - val_accuracy: 0.6667\n",
      "Epoch 304/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7967 - accuracy: 0.6605 - val_loss: 0.8239 - val_accuracy: 0.6667\n",
      "Epoch 305/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8009 - accuracy: 0.6605 - val_loss: 0.8234 - val_accuracy: 0.6667\n",
      "Epoch 306/750\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.8125 - accuracy: 0.6420 - val_loss: 0.8230 - val_accuracy: 0.6667\n",
      "Epoch 307/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8060 - accuracy: 0.6667 - val_loss: 0.8226 - val_accuracy: 0.6667\n",
      "Epoch 308/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8014 - accuracy: 0.6790 - val_loss: 0.8222 - val_accuracy: 0.6667\n",
      "Epoch 309/750\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.8102 - accuracy: 0.6728 - val_loss: 0.8219 - val_accuracy: 0.6667\n",
      "Epoch 310/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8025 - accuracy: 0.6543 - val_loss: 0.8217 - val_accuracy: 0.6667\n",
      "Epoch 311/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8049 - accuracy: 0.6667 - val_loss: 0.8216 - val_accuracy: 0.6667\n",
      "Epoch 312/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8174 - accuracy: 0.6481 - val_loss: 0.8211 - val_accuracy: 0.6667\n",
      "Epoch 313/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7968 - accuracy: 0.6605 - val_loss: 0.8207 - val_accuracy: 0.6667\n",
      "Epoch 314/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7896 - accuracy: 0.6728 - val_loss: 0.8200 - val_accuracy: 0.6667\n",
      "Epoch 315/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8093 - accuracy: 0.6728 - val_loss: 0.8195 - val_accuracy: 0.6667\n",
      "Epoch 316/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7990 - accuracy: 0.6667 - val_loss: 0.8189 - val_accuracy: 0.6667\n",
      "Epoch 317/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8051 - accuracy: 0.6605 - val_loss: 0.8182 - val_accuracy: 0.6667\n",
      "Epoch 318/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8044 - accuracy: 0.6543 - val_loss: 0.8178 - val_accuracy: 0.6667\n",
      "Epoch 319/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7962 - accuracy: 0.6728 - val_loss: 0.8175 - val_accuracy: 0.6667\n",
      "Epoch 320/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7967 - accuracy: 0.6667 - val_loss: 0.8173 - val_accuracy: 0.6667\n",
      "Epoch 321/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7930 - accuracy: 0.6852 - val_loss: 0.8168 - val_accuracy: 0.6667\n",
      "Epoch 322/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8092 - accuracy: 0.6420 - val_loss: 0.8165 - val_accuracy: 0.6667\n",
      "Epoch 323/750\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.7924 - accuracy: 0.6667 - val_loss: 0.8159 - val_accuracy: 0.6667\n",
      "Epoch 324/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8040 - accuracy: 0.6605 - val_loss: 0.8155 - val_accuracy: 0.6667\n",
      "Epoch 325/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7957 - accuracy: 0.7037 - val_loss: 0.8152 - val_accuracy: 0.6667\n",
      "Epoch 326/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7920 - accuracy: 0.6543 - val_loss: 0.8151 - val_accuracy: 0.6667\n",
      "Epoch 327/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8066 - accuracy: 0.6605 - val_loss: 0.8150 - val_accuracy: 0.6667\n",
      "Epoch 328/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7997 - accuracy: 0.6852 - val_loss: 0.8148 - val_accuracy: 0.6667\n",
      "Epoch 329/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7961 - accuracy: 0.6543 - val_loss: 0.8147 - val_accuracy: 0.6667\n",
      "Epoch 330/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7991 - accuracy: 0.6728 - val_loss: 0.8145 - val_accuracy: 0.6667\n",
      "Epoch 331/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8052 - accuracy: 0.6420 - val_loss: 0.8147 - val_accuracy: 0.6667\n",
      "Epoch 332/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7881 - accuracy: 0.6852 - val_loss: 0.8146 - val_accuracy: 0.6667\n",
      "Epoch 333/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7951 - accuracy: 0.6667 - val_loss: 0.8145 - val_accuracy: 0.6667\n",
      "Epoch 334/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7894 - accuracy: 0.6605 - val_loss: 0.8143 - val_accuracy: 0.6667\n",
      "Epoch 335/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7858 - accuracy: 0.6667 - val_loss: 0.8141 - val_accuracy: 0.6667\n",
      "Epoch 336/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8065 - accuracy: 0.6605 - val_loss: 0.8140 - val_accuracy: 0.6667\n",
      "Epoch 337/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7965 - accuracy: 0.6605 - val_loss: 0.8137 - val_accuracy: 0.6667\n",
      "Epoch 338/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7893 - accuracy: 0.6852 - val_loss: 0.8131 - val_accuracy: 0.6667\n",
      "Epoch 339/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7883 - accuracy: 0.6790 - val_loss: 0.8127 - val_accuracy: 0.6667\n",
      "Epoch 340/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7913 - accuracy: 0.6790 - val_loss: 0.8126 - val_accuracy: 0.6667\n",
      "Epoch 341/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7876 - accuracy: 0.6790 - val_loss: 0.8125 - val_accuracy: 0.6667\n",
      "Epoch 342/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7932 - accuracy: 0.6852 - val_loss: 0.8123 - val_accuracy: 0.6667\n",
      "Epoch 343/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7932 - accuracy: 0.6605 - val_loss: 0.8118 - val_accuracy: 0.6667\n",
      "Epoch 344/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7936 - accuracy: 0.6790 - val_loss: 0.8115 - val_accuracy: 0.6667\n",
      "Epoch 345/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7979 - accuracy: 0.6481 - val_loss: 0.8114 - val_accuracy: 0.6667\n",
      "Epoch 346/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7869 - accuracy: 0.6914 - val_loss: 0.8111 - val_accuracy: 0.6667\n",
      "Epoch 347/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7816 - accuracy: 0.6728 - val_loss: 0.8112 - val_accuracy: 0.6667\n",
      "Epoch 348/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7832 - accuracy: 0.6728 - val_loss: 0.8109 - val_accuracy: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7971 - accuracy: 0.6543 - val_loss: 0.8106 - val_accuracy: 0.6667\n",
      "Epoch 350/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7723 - accuracy: 0.6728 - val_loss: 0.8104 - val_accuracy: 0.6667\n",
      "Epoch 351/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7961 - accuracy: 0.6358 - val_loss: 0.8098 - val_accuracy: 0.6667\n",
      "Epoch 352/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7930 - accuracy: 0.6667 - val_loss: 0.8098 - val_accuracy: 0.6667\n",
      "Epoch 353/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7917 - accuracy: 0.6420 - val_loss: 0.8095 - val_accuracy: 0.6667\n",
      "Epoch 354/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7873 - accuracy: 0.6667 - val_loss: 0.8095 - val_accuracy: 0.6667\n",
      "Epoch 355/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7898 - accuracy: 0.6728 - val_loss: 0.8095 - val_accuracy: 0.6667\n",
      "Epoch 356/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7928 - accuracy: 0.6605 - val_loss: 0.8095 - val_accuracy: 0.6667\n",
      "Epoch 357/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7803 - accuracy: 0.6728 - val_loss: 0.8094 - val_accuracy: 0.6667\n",
      "Epoch 358/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7788 - accuracy: 0.6790 - val_loss: 0.8096 - val_accuracy: 0.6667\n",
      "Epoch 359/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7787 - accuracy: 0.6790 - val_loss: 0.8095 - val_accuracy: 0.6667\n",
      "Epoch 360/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7932 - accuracy: 0.6790 - val_loss: 0.8094 - val_accuracy: 0.6667\n",
      "Epoch 361/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7918 - accuracy: 0.6543 - val_loss: 0.8093 - val_accuracy: 0.6667\n",
      "Epoch 362/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7960 - accuracy: 0.6605 - val_loss: 0.8090 - val_accuracy: 0.6667\n",
      "Epoch 363/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7876 - accuracy: 0.6543 - val_loss: 0.8089 - val_accuracy: 0.6667\n",
      "Epoch 364/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7823 - accuracy: 0.6667 - val_loss: 0.8088 - val_accuracy: 0.6667\n",
      "Epoch 365/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7835 - accuracy: 0.6605 - val_loss: 0.8084 - val_accuracy: 0.6667\n",
      "Epoch 366/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7829 - accuracy: 0.6543 - val_loss: 0.8083 - val_accuracy: 0.6667\n",
      "Epoch 367/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7807 - accuracy: 0.6852 - val_loss: 0.8082 - val_accuracy: 0.6667\n",
      "Epoch 368/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7764 - accuracy: 0.6543 - val_loss: 0.8080 - val_accuracy: 0.6667\n",
      "Epoch 369/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7926 - accuracy: 0.6790 - val_loss: 0.8078 - val_accuracy: 0.6667\n",
      "Epoch 370/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7802 - accuracy: 0.6543 - val_loss: 0.8081 - val_accuracy: 0.6667\n",
      "Epoch 371/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7826 - accuracy: 0.6667 - val_loss: 0.8080 - val_accuracy: 0.6667\n",
      "Epoch 372/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7734 - accuracy: 0.6790 - val_loss: 0.8080 - val_accuracy: 0.6667\n",
      "Epoch 373/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7968 - accuracy: 0.6543 - val_loss: 0.8079 - val_accuracy: 0.6667\n",
      "Epoch 374/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7885 - accuracy: 0.6605 - val_loss: 0.8077 - val_accuracy: 0.6667\n",
      "Epoch 375/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7865 - accuracy: 0.6790 - val_loss: 0.8073 - val_accuracy: 0.6667\n",
      "Epoch 376/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7769 - accuracy: 0.6728 - val_loss: 0.8066 - val_accuracy: 0.6667\n",
      "Epoch 377/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7855 - accuracy: 0.6790 - val_loss: 0.8058 - val_accuracy: 0.6667\n",
      "Epoch 378/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7768 - accuracy: 0.6605 - val_loss: 0.8050 - val_accuracy: 0.6667\n",
      "Epoch 379/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7922 - accuracy: 0.6728 - val_loss: 0.8046 - val_accuracy: 0.6667\n",
      "Epoch 380/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7811 - accuracy: 0.6667 - val_loss: 0.8041 - val_accuracy: 0.6667\n",
      "Epoch 381/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7793 - accuracy: 0.6667 - val_loss: 0.8035 - val_accuracy: 0.6667\n",
      "Epoch 382/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7873 - accuracy: 0.6667 - val_loss: 0.8029 - val_accuracy: 0.7037\n",
      "Epoch 383/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7851 - accuracy: 0.6667 - val_loss: 0.8021 - val_accuracy: 0.7037\n",
      "Epoch 384/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7780 - accuracy: 0.6852 - val_loss: 0.8017 - val_accuracy: 0.7037\n",
      "Epoch 385/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7958 - accuracy: 0.6605 - val_loss: 0.8012 - val_accuracy: 0.7037\n",
      "Epoch 386/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7779 - accuracy: 0.6605 - val_loss: 0.8007 - val_accuracy: 0.7037\n",
      "Epoch 387/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7806 - accuracy: 0.6728 - val_loss: 0.8001 - val_accuracy: 0.7037\n",
      "Epoch 388/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7789 - accuracy: 0.6790 - val_loss: 0.7992 - val_accuracy: 0.7037\n",
      "Epoch 389/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7783 - accuracy: 0.6790 - val_loss: 0.7983 - val_accuracy: 0.7037\n",
      "Epoch 390/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7805 - accuracy: 0.6667 - val_loss: 0.7976 - val_accuracy: 0.7037\n",
      "Epoch 391/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7762 - accuracy: 0.6790 - val_loss: 0.7969 - val_accuracy: 0.7037\n",
      "Epoch 392/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7816 - accuracy: 0.6728 - val_loss: 0.7964 - val_accuracy: 0.7037\n",
      "Epoch 393/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7842 - accuracy: 0.6667 - val_loss: 0.7959 - val_accuracy: 0.7037\n",
      "Epoch 394/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7842 - accuracy: 0.6296 - val_loss: 0.7956 - val_accuracy: 0.7037\n",
      "Epoch 395/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7854 - accuracy: 0.6728 - val_loss: 0.7955 - val_accuracy: 0.7037\n",
      "Epoch 396/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7674 - accuracy: 0.6852 - val_loss: 0.7952 - val_accuracy: 0.7037\n",
      "Epoch 397/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7872 - accuracy: 0.6914 - val_loss: 0.7950 - val_accuracy: 0.7037\n",
      "Epoch 398/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7761 - accuracy: 0.6852 - val_loss: 0.7948 - val_accuracy: 0.7037\n",
      "Epoch 399/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7681 - accuracy: 0.6975 - val_loss: 0.7948 - val_accuracy: 0.7037\n",
      "Epoch 400/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7812 - accuracy: 0.6790 - val_loss: 0.7948 - val_accuracy: 0.7037\n",
      "Epoch 401/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7750 - accuracy: 0.6728 - val_loss: 0.7945 - val_accuracy: 0.7037\n",
      "Epoch 402/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7683 - accuracy: 0.6914 - val_loss: 0.7942 - val_accuracy: 0.7037\n",
      "Epoch 403/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7771 - accuracy: 0.6728 - val_loss: 0.7943 - val_accuracy: 0.7037\n",
      "Epoch 404/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7742 - accuracy: 0.6605 - val_loss: 0.7943 - val_accuracy: 0.7037\n",
      "Epoch 405/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7766 - accuracy: 0.6852 - val_loss: 0.7941 - val_accuracy: 0.7037\n",
      "Epoch 406/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7632 - accuracy: 0.6790 - val_loss: 0.7941 - val_accuracy: 0.7037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 407/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7741 - accuracy: 0.6852 - val_loss: 0.7939 - val_accuracy: 0.7037\n",
      "Epoch 408/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7800 - accuracy: 0.6728 - val_loss: 0.7936 - val_accuracy: 0.7037\n",
      "Epoch 409/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7760 - accuracy: 0.6728 - val_loss: 0.7931 - val_accuracy: 0.7037\n",
      "Epoch 410/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7735 - accuracy: 0.6790 - val_loss: 0.7929 - val_accuracy: 0.7037\n",
      "Epoch 411/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7806 - accuracy: 0.6605 - val_loss: 0.7926 - val_accuracy: 0.7037\n",
      "Epoch 412/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7685 - accuracy: 0.6605 - val_loss: 0.7923 - val_accuracy: 0.7037\n",
      "Epoch 413/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7696 - accuracy: 0.6852 - val_loss: 0.7924 - val_accuracy: 0.7037\n",
      "Epoch 414/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7715 - accuracy: 0.6852 - val_loss: 0.7925 - val_accuracy: 0.7037\n",
      "Epoch 415/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7710 - accuracy: 0.6852 - val_loss: 0.7922 - val_accuracy: 0.7037\n",
      "Epoch 416/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7696 - accuracy: 0.6914 - val_loss: 0.7922 - val_accuracy: 0.7037\n",
      "Epoch 417/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7868 - accuracy: 0.6667 - val_loss: 0.7921 - val_accuracy: 0.7037\n",
      "Epoch 418/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7704 - accuracy: 0.6790 - val_loss: 0.7917 - val_accuracy: 0.7037\n",
      "Epoch 419/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7618 - accuracy: 0.7037 - val_loss: 0.7914 - val_accuracy: 0.7037\n",
      "Epoch 420/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7723 - accuracy: 0.6790 - val_loss: 0.7912 - val_accuracy: 0.7037\n",
      "Epoch 421/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7788 - accuracy: 0.6543 - val_loss: 0.7908 - val_accuracy: 0.7037\n",
      "Epoch 422/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7645 - accuracy: 0.6852 - val_loss: 0.7907 - val_accuracy: 0.7037\n",
      "Epoch 423/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7891 - accuracy: 0.6605 - val_loss: 0.7904 - val_accuracy: 0.7037\n",
      "Epoch 424/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7660 - accuracy: 0.6728 - val_loss: 0.7903 - val_accuracy: 0.7037\n",
      "Epoch 425/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7775 - accuracy: 0.6728 - val_loss: 0.7901 - val_accuracy: 0.7037\n",
      "Epoch 426/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7682 - accuracy: 0.6852 - val_loss: 0.7899 - val_accuracy: 0.7037\n",
      "Epoch 427/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7728 - accuracy: 0.6728 - val_loss: 0.7899 - val_accuracy: 0.7037\n",
      "Epoch 428/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7705 - accuracy: 0.6667 - val_loss: 0.7899 - val_accuracy: 0.7037\n",
      "Epoch 429/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7685 - accuracy: 0.6728 - val_loss: 0.7899 - val_accuracy: 0.7037\n",
      "Epoch 430/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7613 - accuracy: 0.6790 - val_loss: 0.7896 - val_accuracy: 0.7037\n",
      "Epoch 431/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7648 - accuracy: 0.6728 - val_loss: 0.7895 - val_accuracy: 0.7037\n",
      "Epoch 432/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7643 - accuracy: 0.6728 - val_loss: 0.7895 - val_accuracy: 0.7037\n",
      "Epoch 433/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7778 - accuracy: 0.6667 - val_loss: 0.7895 - val_accuracy: 0.7037\n",
      "Epoch 434/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7659 - accuracy: 0.6790 - val_loss: 0.7894 - val_accuracy: 0.7037\n",
      "Epoch 435/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7719 - accuracy: 0.6790 - val_loss: 0.7889 - val_accuracy: 0.7037\n",
      "Epoch 436/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7645 - accuracy: 0.6667 - val_loss: 0.7886 - val_accuracy: 0.7037\n",
      "Epoch 437/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7762 - accuracy: 0.6914 - val_loss: 0.7885 - val_accuracy: 0.7037\n",
      "Epoch 438/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7723 - accuracy: 0.6667 - val_loss: 0.7885 - val_accuracy: 0.7037\n",
      "Epoch 439/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7570 - accuracy: 0.6975 - val_loss: 0.7885 - val_accuracy: 0.7037\n",
      "Epoch 440/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7753 - accuracy: 0.6605 - val_loss: 0.7885 - val_accuracy: 0.7037\n",
      "Epoch 441/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7733 - accuracy: 0.6543 - val_loss: 0.7884 - val_accuracy: 0.7037\n",
      "Epoch 442/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7694 - accuracy: 0.6728 - val_loss: 0.7881 - val_accuracy: 0.7037\n",
      "Epoch 443/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7666 - accuracy: 0.6667 - val_loss: 0.7879 - val_accuracy: 0.7037\n",
      "Epoch 444/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7624 - accuracy: 0.6728 - val_loss: 0.7875 - val_accuracy: 0.7037\n",
      "Epoch 445/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7654 - accuracy: 0.6667 - val_loss: 0.7873 - val_accuracy: 0.7037\n",
      "Epoch 446/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7613 - accuracy: 0.6667 - val_loss: 0.7876 - val_accuracy: 0.7037\n",
      "Epoch 447/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7655 - accuracy: 0.6728 - val_loss: 0.7878 - val_accuracy: 0.7037\n",
      "Epoch 448/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7669 - accuracy: 0.6790 - val_loss: 0.7878 - val_accuracy: 0.7037\n",
      "Epoch 449/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7666 - accuracy: 0.6914 - val_loss: 0.7880 - val_accuracy: 0.7037\n",
      "Epoch 450/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7641 - accuracy: 0.6852 - val_loss: 0.7882 - val_accuracy: 0.7037\n",
      "Epoch 451/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7588 - accuracy: 0.6728 - val_loss: 0.7884 - val_accuracy: 0.7037\n",
      "Epoch 452/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7546 - accuracy: 0.6728 - val_loss: 0.7886 - val_accuracy: 0.7037\n",
      "Epoch 453/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7771 - accuracy: 0.6667 - val_loss: 0.7888 - val_accuracy: 0.7037\n",
      "Epoch 454/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7668 - accuracy: 0.6667 - val_loss: 0.7891 - val_accuracy: 0.7037\n",
      "Epoch 455/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7582 - accuracy: 0.6667 - val_loss: 0.7895 - val_accuracy: 0.7037\n",
      "Epoch 456/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7658 - accuracy: 0.6667 - val_loss: 0.7900 - val_accuracy: 0.7037\n",
      "Epoch 457/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7634 - accuracy: 0.6667 - val_loss: 0.7904 - val_accuracy: 0.7037\n",
      "Epoch 458/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7681 - accuracy: 0.6790 - val_loss: 0.7907 - val_accuracy: 0.7037\n",
      "Epoch 459/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7612 - accuracy: 0.6728 - val_loss: 0.7907 - val_accuracy: 0.7037\n",
      "Epoch 460/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7618 - accuracy: 0.6728 - val_loss: 0.7906 - val_accuracy: 0.7037\n",
      "Epoch 461/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7647 - accuracy: 0.6790 - val_loss: 0.7905 - val_accuracy: 0.7037\n",
      "Epoch 462/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7501 - accuracy: 0.6790 - val_loss: 0.7904 - val_accuracy: 0.7037\n",
      "Epoch 463/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7564 - accuracy: 0.6790 - val_loss: 0.7903 - val_accuracy: 0.7037\n",
      "Epoch 464/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7701 - accuracy: 0.6605 - val_loss: 0.7901 - val_accuracy: 0.7037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 465/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7637 - accuracy: 0.6914 - val_loss: 0.7898 - val_accuracy: 0.7037\n",
      "Epoch 466/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7638 - accuracy: 0.6852 - val_loss: 0.7894 - val_accuracy: 0.7037\n",
      "Epoch 467/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7566 - accuracy: 0.6605 - val_loss: 0.7891 - val_accuracy: 0.7037\n",
      "Epoch 468/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7697 - accuracy: 0.6790 - val_loss: 0.7887 - val_accuracy: 0.7037\n",
      "Epoch 469/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7553 - accuracy: 0.6728 - val_loss: 0.7880 - val_accuracy: 0.7037\n",
      "Epoch 470/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7518 - accuracy: 0.6667 - val_loss: 0.7876 - val_accuracy: 0.7037\n",
      "Epoch 471/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7580 - accuracy: 0.6728 - val_loss: 0.7874 - val_accuracy: 0.7037\n",
      "Epoch 472/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7702 - accuracy: 0.6852 - val_loss: 0.7868 - val_accuracy: 0.7037\n",
      "Epoch 473/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7599 - accuracy: 0.6790 - val_loss: 0.7864 - val_accuracy: 0.7037\n",
      "Epoch 474/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7509 - accuracy: 0.6914 - val_loss: 0.7863 - val_accuracy: 0.7037\n",
      "Epoch 475/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7579 - accuracy: 0.6790 - val_loss: 0.7861 - val_accuracy: 0.7037\n",
      "Epoch 476/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7679 - accuracy: 0.6728 - val_loss: 0.7861 - val_accuracy: 0.7037\n",
      "Epoch 477/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7734 - accuracy: 0.6543 - val_loss: 0.7859 - val_accuracy: 0.7037\n",
      "Epoch 478/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7534 - accuracy: 0.6852 - val_loss: 0.7856 - val_accuracy: 0.7037\n",
      "Epoch 479/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7686 - accuracy: 0.6728 - val_loss: 0.7854 - val_accuracy: 0.7037\n",
      "Epoch 480/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7584 - accuracy: 0.6790 - val_loss: 0.7852 - val_accuracy: 0.7037\n",
      "Epoch 481/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7576 - accuracy: 0.6852 - val_loss: 0.7848 - val_accuracy: 0.7037\n",
      "Epoch 482/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7505 - accuracy: 0.6914 - val_loss: 0.7847 - val_accuracy: 0.7037\n",
      "Epoch 483/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7698 - accuracy: 0.6852 - val_loss: 0.7843 - val_accuracy: 0.7037\n",
      "Epoch 484/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7636 - accuracy: 0.6852 - val_loss: 0.7839 - val_accuracy: 0.7037\n",
      "Epoch 485/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7616 - accuracy: 0.6667 - val_loss: 0.7836 - val_accuracy: 0.7037\n",
      "Epoch 486/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7570 - accuracy: 0.6790 - val_loss: 0.7836 - val_accuracy: 0.7037\n",
      "Epoch 487/750\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.7679 - accuracy: 0.6728 - val_loss: 0.7838 - val_accuracy: 0.7037\n",
      "Epoch 488/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7676 - accuracy: 0.6852 - val_loss: 0.7839 - val_accuracy: 0.7037\n",
      "Epoch 489/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7511 - accuracy: 0.6728 - val_loss: 0.7837 - val_accuracy: 0.7037\n",
      "Epoch 490/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7610 - accuracy: 0.6728 - val_loss: 0.7834 - val_accuracy: 0.7037\n",
      "Epoch 491/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7633 - accuracy: 0.6914 - val_loss: 0.7831 - val_accuracy: 0.7037\n",
      "Epoch 492/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7722 - accuracy: 0.6728 - val_loss: 0.7829 - val_accuracy: 0.7037\n",
      "Epoch 493/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7537 - accuracy: 0.6605 - val_loss: 0.7825 - val_accuracy: 0.7037\n",
      "Epoch 494/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7494 - accuracy: 0.6852 - val_loss: 0.7821 - val_accuracy: 0.7037\n",
      "Epoch 495/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7582 - accuracy: 0.6728 - val_loss: 0.7817 - val_accuracy: 0.7037\n",
      "Epoch 496/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7528 - accuracy: 0.6667 - val_loss: 0.7811 - val_accuracy: 0.7037\n",
      "Epoch 497/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7452 - accuracy: 0.6790 - val_loss: 0.7807 - val_accuracy: 0.7037\n",
      "Epoch 498/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7544 - accuracy: 0.6790 - val_loss: 0.7803 - val_accuracy: 0.7037\n",
      "Epoch 499/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7527 - accuracy: 0.6852 - val_loss: 0.7800 - val_accuracy: 0.7037\n",
      "Epoch 500/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7643 - accuracy: 0.6975 - val_loss: 0.7797 - val_accuracy: 0.7037\n",
      "Epoch 501/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7520 - accuracy: 0.6914 - val_loss: 0.7795 - val_accuracy: 0.7037\n",
      "Epoch 502/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7641 - accuracy: 0.6790 - val_loss: 0.7793 - val_accuracy: 0.7037\n",
      "Epoch 503/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7491 - accuracy: 0.6914 - val_loss: 0.7793 - val_accuracy: 0.7037\n",
      "Epoch 504/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7488 - accuracy: 0.6852 - val_loss: 0.7793 - val_accuracy: 0.7037\n",
      "Epoch 505/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7632 - accuracy: 0.7037 - val_loss: 0.7792 - val_accuracy: 0.7037\n",
      "Epoch 506/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7621 - accuracy: 0.6728 - val_loss: 0.7792 - val_accuracy: 0.7037\n",
      "Epoch 507/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7528 - accuracy: 0.6852 - val_loss: 0.7790 - val_accuracy: 0.7037\n",
      "Epoch 508/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7628 - accuracy: 0.6728 - val_loss: 0.7788 - val_accuracy: 0.7037\n",
      "Epoch 509/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7638 - accuracy: 0.6790 - val_loss: 0.7786 - val_accuracy: 0.7037\n",
      "Epoch 510/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7658 - accuracy: 0.6790 - val_loss: 0.7784 - val_accuracy: 0.7037\n",
      "Epoch 511/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7530 - accuracy: 0.6914 - val_loss: 0.7785 - val_accuracy: 0.7037\n",
      "Epoch 512/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7409 - accuracy: 0.6852 - val_loss: 0.7787 - val_accuracy: 0.7037\n",
      "Epoch 513/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7574 - accuracy: 0.6852 - val_loss: 0.7786 - val_accuracy: 0.7037\n",
      "Epoch 514/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7620 - accuracy: 0.6605 - val_loss: 0.7787 - val_accuracy: 0.7037\n",
      "Epoch 515/750\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.7513 - accuracy: 0.6728 - val_loss: 0.7787 - val_accuracy: 0.7037\n",
      "Epoch 516/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7572 - accuracy: 0.6790 - val_loss: 0.7785 - val_accuracy: 0.7037\n",
      "Epoch 517/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7499 - accuracy: 0.6790 - val_loss: 0.7783 - val_accuracy: 0.7037\n",
      "Epoch 518/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7592 - accuracy: 0.6728 - val_loss: 0.7782 - val_accuracy: 0.7037\n",
      "Epoch 519/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7700 - accuracy: 0.6728 - val_loss: 0.7781 - val_accuracy: 0.7037\n",
      "Epoch 520/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7536 - accuracy: 0.6914 - val_loss: 0.7780 - val_accuracy: 0.7037\n",
      "Epoch 521/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7511 - accuracy: 0.6790 - val_loss: 0.7779 - val_accuracy: 0.7037\n",
      "Epoch 522/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7412 - accuracy: 0.6728 - val_loss: 0.7778 - val_accuracy: 0.7037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 523/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7702 - accuracy: 0.6543 - val_loss: 0.7777 - val_accuracy: 0.7037\n",
      "Epoch 524/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7707 - accuracy: 0.6605 - val_loss: 0.7774 - val_accuracy: 0.7037\n",
      "Epoch 525/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7530 - accuracy: 0.6728 - val_loss: 0.7775 - val_accuracy: 0.7037\n",
      "Epoch 526/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7448 - accuracy: 0.6790 - val_loss: 0.7775 - val_accuracy: 0.7037\n",
      "Epoch 527/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7549 - accuracy: 0.6667 - val_loss: 0.7774 - val_accuracy: 0.7037\n",
      "Epoch 528/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7528 - accuracy: 0.6852 - val_loss: 0.7776 - val_accuracy: 0.7037\n",
      "Epoch 529/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7467 - accuracy: 0.6728 - val_loss: 0.7776 - val_accuracy: 0.7037\n",
      "Epoch 530/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7457 - accuracy: 0.6790 - val_loss: 0.7776 - val_accuracy: 0.7037\n",
      "Epoch 531/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7561 - accuracy: 0.6667 - val_loss: 0.7774 - val_accuracy: 0.7037\n",
      "Epoch 532/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7563 - accuracy: 0.6605 - val_loss: 0.7772 - val_accuracy: 0.7037\n",
      "Epoch 533/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7521 - accuracy: 0.6605 - val_loss: 0.7770 - val_accuracy: 0.7037\n",
      "Epoch 534/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7425 - accuracy: 0.6852 - val_loss: 0.7767 - val_accuracy: 0.7037\n",
      "Epoch 535/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7440 - accuracy: 0.6975 - val_loss: 0.7767 - val_accuracy: 0.7037\n",
      "Epoch 536/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7588 - accuracy: 0.6790 - val_loss: 0.7764 - val_accuracy: 0.7037\n",
      "Epoch 537/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7460 - accuracy: 0.6728 - val_loss: 0.7765 - val_accuracy: 0.7037\n",
      "Epoch 538/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7438 - accuracy: 0.6852 - val_loss: 0.7765 - val_accuracy: 0.7037\n",
      "Epoch 539/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7482 - accuracy: 0.6728 - val_loss: 0.7765 - val_accuracy: 0.7037\n",
      "Epoch 540/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7602 - accuracy: 0.6728 - val_loss: 0.7764 - val_accuracy: 0.7037\n",
      "Epoch 541/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7413 - accuracy: 0.6790 - val_loss: 0.7764 - val_accuracy: 0.7037\n",
      "Epoch 542/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7454 - accuracy: 0.6852 - val_loss: 0.7759 - val_accuracy: 0.7037\n",
      "Epoch 543/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7418 - accuracy: 0.6852 - val_loss: 0.7757 - val_accuracy: 0.7037\n",
      "Epoch 544/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7453 - accuracy: 0.6852 - val_loss: 0.7755 - val_accuracy: 0.7037\n",
      "Epoch 545/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7432 - accuracy: 0.6852 - val_loss: 0.7753 - val_accuracy: 0.7037\n",
      "Epoch 546/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7458 - accuracy: 0.6852 - val_loss: 0.7752 - val_accuracy: 0.7037\n",
      "Epoch 547/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7463 - accuracy: 0.6667 - val_loss: 0.7753 - val_accuracy: 0.7037\n",
      "Epoch 548/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7454 - accuracy: 0.6667 - val_loss: 0.7754 - val_accuracy: 0.7037\n",
      "Epoch 549/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7426 - accuracy: 0.6728 - val_loss: 0.7753 - val_accuracy: 0.7037\n",
      "Epoch 550/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7393 - accuracy: 0.6852 - val_loss: 0.7749 - val_accuracy: 0.7037\n",
      "Epoch 551/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7363 - accuracy: 0.6852 - val_loss: 0.7749 - val_accuracy: 0.7037\n",
      "Epoch 552/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7343 - accuracy: 0.6790 - val_loss: 0.7746 - val_accuracy: 0.7037\n",
      "Epoch 553/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7580 - accuracy: 0.6728 - val_loss: 0.7745 - val_accuracy: 0.7037\n",
      "Epoch 554/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7438 - accuracy: 0.6852 - val_loss: 0.7742 - val_accuracy: 0.7037\n",
      "Epoch 555/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7512 - accuracy: 0.6790 - val_loss: 0.7737 - val_accuracy: 0.7037\n",
      "Epoch 556/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7358 - accuracy: 0.6728 - val_loss: 0.7736 - val_accuracy: 0.7037\n",
      "Epoch 557/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7414 - accuracy: 0.6852 - val_loss: 0.7734 - val_accuracy: 0.7037\n",
      "Epoch 558/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7433 - accuracy: 0.6852 - val_loss: 0.7730 - val_accuracy: 0.7037\n",
      "Epoch 559/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7590 - accuracy: 0.6605 - val_loss: 0.7727 - val_accuracy: 0.7037\n",
      "Epoch 560/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7496 - accuracy: 0.6914 - val_loss: 0.7724 - val_accuracy: 0.7037\n",
      "Epoch 561/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7637 - accuracy: 0.6728 - val_loss: 0.7725 - val_accuracy: 0.7037\n",
      "Epoch 562/750\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.7421 - accuracy: 0.6975 - val_loss: 0.7725 - val_accuracy: 0.7037\n",
      "Epoch 563/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7461 - accuracy: 0.6852 - val_loss: 0.7726 - val_accuracy: 0.7037\n",
      "Epoch 564/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7484 - accuracy: 0.6790 - val_loss: 0.7724 - val_accuracy: 0.7037\n",
      "Epoch 565/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7516 - accuracy: 0.6852 - val_loss: 0.7722 - val_accuracy: 0.7037\n",
      "Epoch 566/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7394 - accuracy: 0.6790 - val_loss: 0.7725 - val_accuracy: 0.7037\n",
      "Epoch 567/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7382 - accuracy: 0.6914 - val_loss: 0.7724 - val_accuracy: 0.7037\n",
      "Epoch 568/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7522 - accuracy: 0.6914 - val_loss: 0.7725 - val_accuracy: 0.7037\n",
      "Epoch 569/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7392 - accuracy: 0.6852 - val_loss: 0.7725 - val_accuracy: 0.7037\n",
      "Epoch 570/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7529 - accuracy: 0.6790 - val_loss: 0.7723 - val_accuracy: 0.7037\n",
      "Epoch 571/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7682 - accuracy: 0.6481 - val_loss: 0.7721 - val_accuracy: 0.7037\n",
      "Epoch 572/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7367 - accuracy: 0.6852 - val_loss: 0.7720 - val_accuracy: 0.7037\n",
      "Epoch 573/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7426 - accuracy: 0.6790 - val_loss: 0.7717 - val_accuracy: 0.7037\n",
      "Epoch 574/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7898 - accuracy: 0.6667 - val_loss: 0.7719 - val_accuracy: 0.7037\n",
      "Epoch 575/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7311 - accuracy: 0.6914 - val_loss: 0.7719 - val_accuracy: 0.7037\n",
      "Epoch 576/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7419 - accuracy: 0.6852 - val_loss: 0.7719 - val_accuracy: 0.7037\n",
      "Epoch 577/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7445 - accuracy: 0.6667 - val_loss: 0.7722 - val_accuracy: 0.7037\n",
      "Epoch 578/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7362 - accuracy: 0.6852 - val_loss: 0.7725 - val_accuracy: 0.7037\n",
      "Epoch 579/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7448 - accuracy: 0.6667 - val_loss: 0.7725 - val_accuracy: 0.7037\n",
      "Epoch 580/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7442 - accuracy: 0.6852 - val_loss: 0.7727 - val_accuracy: 0.7037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 581/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7382 - accuracy: 0.6790 - val_loss: 0.7727 - val_accuracy: 0.7037\n",
      "Epoch 582/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7572 - accuracy: 0.6481 - val_loss: 0.7727 - val_accuracy: 0.7037\n",
      "Epoch 583/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7384 - accuracy: 0.6914 - val_loss: 0.7727 - val_accuracy: 0.7037\n",
      "Epoch 584/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7444 - accuracy: 0.6852 - val_loss: 0.7725 - val_accuracy: 0.7037\n",
      "Epoch 585/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7480 - accuracy: 0.6667 - val_loss: 0.7726 - val_accuracy: 0.7037\n",
      "Epoch 586/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7596 - accuracy: 0.6667 - val_loss: 0.7729 - val_accuracy: 0.7037\n",
      "Epoch 587/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7563 - accuracy: 0.6543 - val_loss: 0.7727 - val_accuracy: 0.7037\n",
      "Epoch 588/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7354 - accuracy: 0.6790 - val_loss: 0.7726 - val_accuracy: 0.7037\n",
      "Epoch 589/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7355 - accuracy: 0.6852 - val_loss: 0.7723 - val_accuracy: 0.7037\n",
      "Epoch 590/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7393 - accuracy: 0.6852 - val_loss: 0.7722 - val_accuracy: 0.7037\n",
      "Epoch 591/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7455 - accuracy: 0.6852 - val_loss: 0.7722 - val_accuracy: 0.7037\n",
      "Epoch 592/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7382 - accuracy: 0.6852 - val_loss: 0.7720 - val_accuracy: 0.7037\n",
      "Epoch 593/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7364 - accuracy: 0.6605 - val_loss: 0.7720 - val_accuracy: 0.7037\n",
      "Epoch 594/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7322 - accuracy: 0.6852 - val_loss: 0.7718 - val_accuracy: 0.7037\n",
      "Epoch 595/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7387 - accuracy: 0.6790 - val_loss: 0.7719 - val_accuracy: 0.7037\n",
      "Epoch 596/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7394 - accuracy: 0.7037 - val_loss: 0.7720 - val_accuracy: 0.7037\n",
      "Epoch 597/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7275 - accuracy: 0.6975 - val_loss: 0.7721 - val_accuracy: 0.7037\n",
      "Epoch 598/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7330 - accuracy: 0.6852 - val_loss: 0.7722 - val_accuracy: 0.7037\n",
      "Epoch 599/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7538 - accuracy: 0.6728 - val_loss: 0.7721 - val_accuracy: 0.7037\n",
      "Epoch 600/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7473 - accuracy: 0.6728 - val_loss: 0.7720 - val_accuracy: 0.7037\n",
      "Epoch 601/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7393 - accuracy: 0.6975 - val_loss: 0.7716 - val_accuracy: 0.7037\n",
      "Epoch 602/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7488 - accuracy: 0.6481 - val_loss: 0.7714 - val_accuracy: 0.7037\n",
      "Epoch 603/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7509 - accuracy: 0.6790 - val_loss: 0.7711 - val_accuracy: 0.7037\n",
      "Epoch 604/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7415 - accuracy: 0.6914 - val_loss: 0.7707 - val_accuracy: 0.7037\n",
      "Epoch 605/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7509 - accuracy: 0.6543 - val_loss: 0.7702 - val_accuracy: 0.7037\n",
      "Epoch 606/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7347 - accuracy: 0.6914 - val_loss: 0.7697 - val_accuracy: 0.7037\n",
      "Epoch 607/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7419 - accuracy: 0.6790 - val_loss: 0.7692 - val_accuracy: 0.7037\n",
      "Epoch 608/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7408 - accuracy: 0.6975 - val_loss: 0.7691 - val_accuracy: 0.7037\n",
      "Epoch 609/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7465 - accuracy: 0.6852 - val_loss: 0.7689 - val_accuracy: 0.7037\n",
      "Epoch 610/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7689 - accuracy: 0.6667 - val_loss: 0.7688 - val_accuracy: 0.7037\n",
      "Epoch 611/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7342 - accuracy: 0.6790 - val_loss: 0.7690 - val_accuracy: 0.7037\n",
      "Epoch 612/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7480 - accuracy: 0.6728 - val_loss: 0.7687 - val_accuracy: 0.7037\n",
      "Epoch 613/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7279 - accuracy: 0.6914 - val_loss: 0.7688 - val_accuracy: 0.7037\n",
      "Epoch 614/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7326 - accuracy: 0.6728 - val_loss: 0.7688 - val_accuracy: 0.7037\n",
      "Epoch 615/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7375 - accuracy: 0.6914 - val_loss: 0.7689 - val_accuracy: 0.7037\n",
      "Epoch 616/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7322 - accuracy: 0.6728 - val_loss: 0.7690 - val_accuracy: 0.7037\n",
      "Epoch 617/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7338 - accuracy: 0.6790 - val_loss: 0.7692 - val_accuracy: 0.7037\n",
      "Epoch 618/750\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.7417 - accuracy: 0.6728 - val_loss: 0.7689 - val_accuracy: 0.7037\n",
      "Epoch 619/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7374 - accuracy: 0.6852 - val_loss: 0.7690 - val_accuracy: 0.7037\n",
      "Epoch 620/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7393 - accuracy: 0.6790 - val_loss: 0.7690 - val_accuracy: 0.7037\n",
      "Epoch 621/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7421 - accuracy: 0.6852 - val_loss: 0.7689 - val_accuracy: 0.7037\n",
      "Epoch 622/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7344 - accuracy: 0.6790 - val_loss: 0.7687 - val_accuracy: 0.7037\n",
      "Epoch 623/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7464 - accuracy: 0.6914 - val_loss: 0.7685 - val_accuracy: 0.7037\n",
      "Epoch 624/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7592 - accuracy: 0.6667 - val_loss: 0.7685 - val_accuracy: 0.7037\n",
      "Epoch 625/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7355 - accuracy: 0.6914 - val_loss: 0.7685 - val_accuracy: 0.7037\n",
      "Epoch 626/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7291 - accuracy: 0.6790 - val_loss: 0.7682 - val_accuracy: 0.7037\n",
      "Epoch 627/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7545 - accuracy: 0.6605 - val_loss: 0.7680 - val_accuracy: 0.7037\n",
      "Epoch 628/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7454 - accuracy: 0.6728 - val_loss: 0.7680 - val_accuracy: 0.7037\n",
      "Epoch 629/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7410 - accuracy: 0.6790 - val_loss: 0.7680 - val_accuracy: 0.7037\n",
      "Epoch 630/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7376 - accuracy: 0.6852 - val_loss: 0.7680 - val_accuracy: 0.7037\n",
      "Epoch 631/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7209 - accuracy: 0.6914 - val_loss: 0.7683 - val_accuracy: 0.7037\n",
      "Epoch 632/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7585 - accuracy: 0.6728 - val_loss: 0.7684 - val_accuracy: 0.7037\n",
      "Epoch 633/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7356 - accuracy: 0.6790 - val_loss: 0.7684 - val_accuracy: 0.7037\n",
      "Epoch 634/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7180 - accuracy: 0.7037 - val_loss: 0.7684 - val_accuracy: 0.7037\n",
      "Epoch 635/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7356 - accuracy: 0.6728 - val_loss: 0.7684 - val_accuracy: 0.7037\n",
      "Epoch 636/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7444 - accuracy: 0.6852 - val_loss: 0.7684 - val_accuracy: 0.7037\n",
      "Epoch 637/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7282 - accuracy: 0.7037 - val_loss: 0.7683 - val_accuracy: 0.7037\n",
      "Epoch 638/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7321 - accuracy: 0.6790 - val_loss: 0.7679 - val_accuracy: 0.7037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 639/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7387 - accuracy: 0.6790 - val_loss: 0.7677 - val_accuracy: 0.7037\n",
      "Epoch 640/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7295 - accuracy: 0.6728 - val_loss: 0.7674 - val_accuracy: 0.7037\n",
      "Epoch 641/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7356 - accuracy: 0.6728 - val_loss: 0.7673 - val_accuracy: 0.7037\n",
      "Epoch 642/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7480 - accuracy: 0.6543 - val_loss: 0.7670 - val_accuracy: 0.7037\n",
      "Epoch 643/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7398 - accuracy: 0.6728 - val_loss: 0.7667 - val_accuracy: 0.7037\n",
      "Epoch 644/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7383 - accuracy: 0.6914 - val_loss: 0.7667 - val_accuracy: 0.7037\n",
      "Epoch 645/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7392 - accuracy: 0.6852 - val_loss: 0.7666 - val_accuracy: 0.7037\n",
      "Epoch 646/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7314 - accuracy: 0.6728 - val_loss: 0.7669 - val_accuracy: 0.7037\n",
      "Epoch 647/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7326 - accuracy: 0.6975 - val_loss: 0.7671 - val_accuracy: 0.7037\n",
      "Epoch 648/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7540 - accuracy: 0.6728 - val_loss: 0.7670 - val_accuracy: 0.7037\n",
      "Epoch 649/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7274 - accuracy: 0.6790 - val_loss: 0.7670 - val_accuracy: 0.7037\n",
      "Epoch 650/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7249 - accuracy: 0.6852 - val_loss: 0.7668 - val_accuracy: 0.7037\n",
      "Epoch 651/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7344 - accuracy: 0.6728 - val_loss: 0.7670 - val_accuracy: 0.7037\n",
      "Epoch 652/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7357 - accuracy: 0.6914 - val_loss: 0.7669 - val_accuracy: 0.7037\n",
      "Epoch 653/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7418 - accuracy: 0.6728 - val_loss: 0.7670 - val_accuracy: 0.7037\n",
      "Epoch 654/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7346 - accuracy: 0.6914 - val_loss: 0.7669 - val_accuracy: 0.7037\n",
      "Epoch 655/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7385 - accuracy: 0.6790 - val_loss: 0.7671 - val_accuracy: 0.7037\n",
      "Epoch 656/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7283 - accuracy: 0.6790 - val_loss: 0.7670 - val_accuracy: 0.7037\n",
      "Epoch 657/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7314 - accuracy: 0.6852 - val_loss: 0.7670 - val_accuracy: 0.7037\n",
      "Epoch 658/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7255 - accuracy: 0.6852 - val_loss: 0.7667 - val_accuracy: 0.7037\n",
      "Epoch 659/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7284 - accuracy: 0.6852 - val_loss: 0.7664 - val_accuracy: 0.7037\n",
      "Epoch 660/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7338 - accuracy: 0.6852 - val_loss: 0.7659 - val_accuracy: 0.7037\n",
      "Epoch 661/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7359 - accuracy: 0.6667 - val_loss: 0.7654 - val_accuracy: 0.7037\n",
      "Epoch 662/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7293 - accuracy: 0.6852 - val_loss: 0.7650 - val_accuracy: 0.7037\n",
      "Epoch 663/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7356 - accuracy: 0.6852 - val_loss: 0.7644 - val_accuracy: 0.7037\n",
      "Epoch 664/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7474 - accuracy: 0.6852 - val_loss: 0.7642 - val_accuracy: 0.7037\n",
      "Epoch 665/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7318 - accuracy: 0.6790 - val_loss: 0.7637 - val_accuracy: 0.7037\n",
      "Epoch 666/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7407 - accuracy: 0.6975 - val_loss: 0.7631 - val_accuracy: 0.7037\n",
      "Epoch 667/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7195 - accuracy: 0.6914 - val_loss: 0.7628 - val_accuracy: 0.7037\n",
      "Epoch 668/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7351 - accuracy: 0.6790 - val_loss: 0.7626 - val_accuracy: 0.7037\n",
      "Epoch 669/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7260 - accuracy: 0.6852 - val_loss: 0.7624 - val_accuracy: 0.7037\n",
      "Epoch 670/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7341 - accuracy: 0.6728 - val_loss: 0.7622 - val_accuracy: 0.7037\n",
      "Epoch 671/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7251 - accuracy: 0.6790 - val_loss: 0.7622 - val_accuracy: 0.7037\n",
      "Epoch 672/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7304 - accuracy: 0.6975 - val_loss: 0.7622 - val_accuracy: 0.7037\n",
      "Epoch 673/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7419 - accuracy: 0.6852 - val_loss: 0.7620 - val_accuracy: 0.7037\n",
      "Epoch 674/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7281 - accuracy: 0.6852 - val_loss: 0.7620 - val_accuracy: 0.7037\n",
      "Epoch 675/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7405 - accuracy: 0.6852 - val_loss: 0.7620 - val_accuracy: 0.7037\n",
      "Epoch 676/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7527 - accuracy: 0.6605 - val_loss: 0.7622 - val_accuracy: 0.7037\n",
      "Epoch 677/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7132 - accuracy: 0.6914 - val_loss: 0.7621 - val_accuracy: 0.7037\n",
      "Epoch 678/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7253 - accuracy: 0.6852 - val_loss: 0.7623 - val_accuracy: 0.7037\n",
      "Epoch 679/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7286 - accuracy: 0.6728 - val_loss: 0.7626 - val_accuracy: 0.7037\n",
      "Epoch 680/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7578 - accuracy: 0.6358 - val_loss: 0.7627 - val_accuracy: 0.7037\n",
      "Epoch 681/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7336 - accuracy: 0.6790 - val_loss: 0.7627 - val_accuracy: 0.7037\n",
      "Epoch 682/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7340 - accuracy: 0.6852 - val_loss: 0.7626 - val_accuracy: 0.7037\n",
      "Epoch 683/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7303 - accuracy: 0.6975 - val_loss: 0.7627 - val_accuracy: 0.7037\n",
      "Epoch 684/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7414 - accuracy: 0.6667 - val_loss: 0.7629 - val_accuracy: 0.7037\n",
      "Epoch 685/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7297 - accuracy: 0.6790 - val_loss: 0.7630 - val_accuracy: 0.7037\n",
      "Epoch 686/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7403 - accuracy: 0.6790 - val_loss: 0.7631 - val_accuracy: 0.7037\n",
      "Epoch 687/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7323 - accuracy: 0.6790 - val_loss: 0.7632 - val_accuracy: 0.7037\n",
      "Epoch 688/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7417 - accuracy: 0.6667 - val_loss: 0.7633 - val_accuracy: 0.7037\n",
      "Epoch 689/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7379 - accuracy: 0.6852 - val_loss: 0.7636 - val_accuracy: 0.7037\n",
      "Epoch 690/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7303 - accuracy: 0.6605 - val_loss: 0.7635 - val_accuracy: 0.7037\n",
      "Epoch 691/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7295 - accuracy: 0.6790 - val_loss: 0.7632 - val_accuracy: 0.7037\n",
      "Epoch 692/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7332 - accuracy: 0.6790 - val_loss: 0.7632 - val_accuracy: 0.7037\n",
      "Epoch 693/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7250 - accuracy: 0.6790 - val_loss: 0.7633 - val_accuracy: 0.7037\n",
      "Epoch 694/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7249 - accuracy: 0.6667 - val_loss: 0.7632 - val_accuracy: 0.7037\n",
      "Epoch 695/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7269 - accuracy: 0.6914 - val_loss: 0.7628 - val_accuracy: 0.7037\n",
      "Epoch 696/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7323 - accuracy: 0.6728 - val_loss: 0.7628 - val_accuracy: 0.7037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 697/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7294 - accuracy: 0.6914 - val_loss: 0.7626 - val_accuracy: 0.7037\n",
      "Epoch 698/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7340 - accuracy: 0.6790 - val_loss: 0.7627 - val_accuracy: 0.7037\n",
      "Epoch 699/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7243 - accuracy: 0.6852 - val_loss: 0.7628 - val_accuracy: 0.7037\n",
      "Epoch 700/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7417 - accuracy: 0.6790 - val_loss: 0.7627 - val_accuracy: 0.7037\n",
      "Epoch 701/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7308 - accuracy: 0.6790 - val_loss: 0.7627 - val_accuracy: 0.7037\n",
      "Epoch 702/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7249 - accuracy: 0.6852 - val_loss: 0.7627 - val_accuracy: 0.7037\n",
      "Epoch 703/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7288 - accuracy: 0.6852 - val_loss: 0.7627 - val_accuracy: 0.7037\n",
      "Epoch 704/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7226 - accuracy: 0.6790 - val_loss: 0.7628 - val_accuracy: 0.7037\n",
      "Epoch 705/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7228 - accuracy: 0.6975 - val_loss: 0.7627 - val_accuracy: 0.7037\n",
      "Epoch 706/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7255 - accuracy: 0.6728 - val_loss: 0.7626 - val_accuracy: 0.7037\n",
      "Epoch 707/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7269 - accuracy: 0.6852 - val_loss: 0.7626 - val_accuracy: 0.7037\n",
      "Epoch 708/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7187 - accuracy: 0.6852 - val_loss: 0.7625 - val_accuracy: 0.7037\n",
      "Epoch 709/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7359 - accuracy: 0.6790 - val_loss: 0.7627 - val_accuracy: 0.7037\n",
      "Epoch 710/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7322 - accuracy: 0.6790 - val_loss: 0.7627 - val_accuracy: 0.7037\n",
      "Epoch 711/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7176 - accuracy: 0.6790 - val_loss: 0.7629 - val_accuracy: 0.7037\n",
      "Epoch 712/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7165 - accuracy: 0.6852 - val_loss: 0.7631 - val_accuracy: 0.7037\n",
      "Epoch 713/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7304 - accuracy: 0.6852 - val_loss: 0.7632 - val_accuracy: 0.7037\n",
      "Epoch 714/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7766 - accuracy: 0.6296 - val_loss: 0.7635 - val_accuracy: 0.7037\n",
      "Epoch 715/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7533 - accuracy: 0.6605 - val_loss: 0.7638 - val_accuracy: 0.7037\n",
      "Epoch 716/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7191 - accuracy: 0.7099 - val_loss: 0.7645 - val_accuracy: 0.7037\n",
      "Epoch 717/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7319 - accuracy: 0.6728 - val_loss: 0.7648 - val_accuracy: 0.7037\n",
      "Epoch 718/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7246 - accuracy: 0.6667 - val_loss: 0.7648 - val_accuracy: 0.7037\n",
      "Epoch 719/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7353 - accuracy: 0.6728 - val_loss: 0.7647 - val_accuracy: 0.7037\n",
      "Epoch 720/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7191 - accuracy: 0.6790 - val_loss: 0.7645 - val_accuracy: 0.7037\n",
      "Epoch 721/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7252 - accuracy: 0.6790 - val_loss: 0.7644 - val_accuracy: 0.7037\n",
      "Epoch 722/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7246 - accuracy: 0.6852 - val_loss: 0.7644 - val_accuracy: 0.7037\n",
      "Epoch 723/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7212 - accuracy: 0.6790 - val_loss: 0.7640 - val_accuracy: 0.7037\n",
      "Epoch 724/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7269 - accuracy: 0.6852 - val_loss: 0.7640 - val_accuracy: 0.7037\n",
      "Epoch 725/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7247 - accuracy: 0.6852 - val_loss: 0.7640 - val_accuracy: 0.7037\n",
      "Epoch 726/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7338 - accuracy: 0.6790 - val_loss: 0.7641 - val_accuracy: 0.7037\n",
      "Epoch 727/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7297 - accuracy: 0.6790 - val_loss: 0.7642 - val_accuracy: 0.7037\n",
      "Epoch 728/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7297 - accuracy: 0.6790 - val_loss: 0.7641 - val_accuracy: 0.7037\n",
      "Epoch 729/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7350 - accuracy: 0.6728 - val_loss: 0.7640 - val_accuracy: 0.7037\n",
      "Epoch 730/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7263 - accuracy: 0.6667 - val_loss: 0.7637 - val_accuracy: 0.7037\n",
      "Epoch 731/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7335 - accuracy: 0.6667 - val_loss: 0.7633 - val_accuracy: 0.7037\n",
      "Epoch 732/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7265 - accuracy: 0.6975 - val_loss: 0.7631 - val_accuracy: 0.7037\n",
      "Epoch 733/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7310 - accuracy: 0.6790 - val_loss: 0.7629 - val_accuracy: 0.7037\n",
      "Epoch 734/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7184 - accuracy: 0.6790 - val_loss: 0.7628 - val_accuracy: 0.7037\n",
      "Epoch 735/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7280 - accuracy: 0.6852 - val_loss: 0.7623 - val_accuracy: 0.7037\n",
      "Epoch 736/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7230 - accuracy: 0.6852 - val_loss: 0.7618 - val_accuracy: 0.7037\n",
      "Epoch 737/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7237 - accuracy: 0.6790 - val_loss: 0.7615 - val_accuracy: 0.7037\n",
      "Epoch 738/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7170 - accuracy: 0.6790 - val_loss: 0.7612 - val_accuracy: 0.7037\n",
      "Epoch 739/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7266 - accuracy: 0.6790 - val_loss: 0.7610 - val_accuracy: 0.7037\n",
      "Epoch 740/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7136 - accuracy: 0.6914 - val_loss: 0.7605 - val_accuracy: 0.7037\n",
      "Epoch 741/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7189 - accuracy: 0.6790 - val_loss: 0.7601 - val_accuracy: 0.7037\n",
      "Epoch 742/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7233 - accuracy: 0.6914 - val_loss: 0.7598 - val_accuracy: 0.7037\n",
      "Epoch 743/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7266 - accuracy: 0.6914 - val_loss: 0.7594 - val_accuracy: 0.7037\n",
      "Epoch 744/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7218 - accuracy: 0.6790 - val_loss: 0.7590 - val_accuracy: 0.7037\n",
      "Epoch 745/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7393 - accuracy: 0.6605 - val_loss: 0.7590 - val_accuracy: 0.7037\n",
      "Epoch 746/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7191 - accuracy: 0.7037 - val_loss: 0.7589 - val_accuracy: 0.7037\n",
      "Epoch 747/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7352 - accuracy: 0.6790 - val_loss: 0.7587 - val_accuracy: 0.7037\n",
      "Epoch 748/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7211 - accuracy: 0.6790 - val_loss: 0.7588 - val_accuracy: 0.7037\n",
      "Epoch 749/750\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7263 - accuracy: 0.6852 - val_loss: 0.7588 - val_accuracy: 0.7037\n",
      "Epoch 750/750\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7260 - accuracy: 0.6852 - val_loss: 0.7588 - val_accuracy: 0.7037\n",
      "\n",
      "\n",
      "Test loss: 0.7588381767272949\n",
      "Test accuracy: 0.7037037014961243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Building the RNN ##\n",
    "print()\n",
    "print(\"length of train data: \", len(train_x))\n",
    "print(\"length of validation data: \", len(validation_x))\n",
    "print()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(train_x.shape[1:]), activation='tanh', return_sequences=True))\n",
    "# model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(LSTM(64, activation='tanh'))\n",
    "# model.add(Dropout(0.3))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(64, activation='tanh'))\n",
    "# model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.00001, decay=1e-6)\n",
    "# opt = tf.keras.optimizers.Adam(learning_rate=0.0001, decay=1e-6)\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=opt,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_x, train_y,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(validation_x, validation_y)\n",
    ")\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "# Score model\n",
    "score = model.evaluate(validation_x, validation_y, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.7588381767272949\n",
      "Test accuracy: 0.7037037014961243\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(10,7))\n",
    "plt.xlabel('epoch')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_test_buys(tickers, SEQ_LEN, SHIFT):\n",
    "    Sequential_data = []\n",
    "    for ticker in tickers:\n",
    "        df = set_data(ticker)[-SHIFT:]\n",
    "\n",
    "        sequential_data = []  # this is a list that will CONTAIN the sequences\n",
    "        prev_days = deque(maxlen=SEQ_LEN)  # These will be our actual sequences. They are made with deque, which keeps the maximum length by popping out older values as new ones come in\n",
    "        \n",
    "        for i in df.values:  # iterate over the values\n",
    "            prev_days.append([n for n in i[:-2]])  # store all but the target\n",
    "            if len(prev_days) == SEQ_LEN:  # make sure we have 60 sequences!\n",
    "                sequential_data.append([np.array(prev_days), i[-2], i[-1]])  # append those bad boys!\n",
    "        \n",
    "        Sequential_data = Sequential_data + sequential_data\n",
    "        \n",
    "    X = []; y = []; z = []\n",
    "    for seq, target, actual in Sequential_data:  # going over our new sequential data\n",
    "        X.append(seq)  # X is the sequences\n",
    "        y.append(target)  # y is the targets/labels (buys vs sell/notbuy)\n",
    "        z.append(actual)\n",
    "\n",
    "    return np.array(X).astype(\"float64\"), np.array(y).astype(\"uint8\"), np.array(z).astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_trading_days = 100\n",
    "test_x, test_y, test_z = process_test_buys(tickers_test, SEQ_LEN, last_trading_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []; total = 0\n",
    "for i, j in zip(output, test_z):\n",
    "    if np.argmax(i) == 2:\n",
    "        total += 1\n",
    "#         results.append([i,j])\n",
    "        results.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trading period. The last 100 trading days.\n",
      "Average daily return: 1.512388 percent, over 29 trades.\n",
      "You started with $5000 and finished with $7607 after 29 trades.\n"
     ]
    }
   ],
   "source": [
    "print('Trading period. The last %d trading days.' % (last_trading_days))\n",
    "print('Average daily return: %f percent, over %d trades.' % (np.average(results), len(results)))\n",
    "start = 5000\n",
    "finish = start\n",
    "for i in results:\n",
    "    finish = finish + (i/100) * finish\n",
    "    \n",
    "print('You started with $%d and finished with $%d after %d trades.' % (start, finish, len(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.347376935288459, -1.5694116217555676, -2.2103989018587344, -2.2268716518957676, 3.1595210480641622, -3.909364410873828, -0.5628833462154925, -0.5422291794853207, 4.26302747306484, 7.179760700093607, 5.41504115382172, 4.204014801309497, 0.10475245871657268, 0.8335003685586262, 0.6304627786145156, -0.06263956455113684, -1.2897125600689563, 4.043363727909655, 4.305987434505565, 1.04535839203721, -3.2955254715018367, 8.421855178188121, -4.726440274769306, 3.8091279399722566, 5.167216721138401, 0.3401550511611173, 0.8462584169203646, 6.239069927025254, 1.8988795854689489]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []; total = 0\n",
    "for i, j in zip(output, test_z):\n",
    "    if i[2] > 0.6:\n",
    "        total += 1\n",
    "#         results.append([i,j])\n",
    "        results.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trading period. The last 100 trading days.\n",
      "Average daily return: 1.047097 percent, over 15 trades.\n",
      "You started with $5000 and finished with $5798 after 15 trades.\n"
     ]
    }
   ],
   "source": [
    "print('Trading period. The last %d trading days.' % (last_trading_days))\n",
    "print('Average daily return: %f percent, over %d trades.' % (np.average(results), len(results)))\n",
    "start = 5000\n",
    "finish = start\n",
    "for i in results:\n",
    "    finish = finish + (i/100) * finish\n",
    "    \n",
    "print('You started with $%d and finished with $%d after %d trades.' % (start, finish, len(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.2103989018587344, -3.909364410873828, -0.5628833462154925, -0.5422291794853207, 4.26302747306484, 0.8335003685586262, 0.6304627786145156, -1.2897125600689563, 4.043363727909655, -3.2955254715018367, 8.421855178188121, 0.3401550511611173, 0.8462584169203646, 6.239069927025254, 1.8988795854689489]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if os.path.isfile('FAS_model.h5') is False:\n",
    "    model.save('FAS_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = load_model('FAS_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

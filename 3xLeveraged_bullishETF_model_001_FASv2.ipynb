{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "import random\n",
    "from collections import deque\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, BatchNormalization, Flatten, Activation\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ModelCheckpoint\n",
    "import time\n",
    "import statistics\n",
    "from sklearn import preprocessing\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = \"FAS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDB(ticker):\n",
    "    tick = ticker\n",
    "    # Load data\n",
    "    data = yf.Ticker(tick)\n",
    "    df = data.history(period=\"5y\", interval=\"1d\")\n",
    "#     df = data.history(start=\"2018-12-01\", end=\"2020-03-01\")\n",
    "#     start=\"2017-01-01\", end=\"2017-04-30\"\n",
    "    \n",
    "    # add data points\n",
    "    df['close_per1'] = df.ta.percent_return(1)*100\n",
    "    df['sma10'] = df.ta.sma(length=10)\n",
    "    df['williams'] = df.ta.willr()\n",
    "\n",
    "\n",
    "    df = df[[\n",
    "            'open','close','sma10','williams','close_per1'\n",
    "            ]]\n",
    "\n",
    "    df = df.dropna()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.272248603590672\n",
      "                 open      close      sma10   williams  close_per1\n",
      "date                                                              \n",
      "2017-01-20  39.440818  39.537014  40.232526 -70.000233    1.256465\n",
      "2017-01-23  39.383103  39.344627  40.028588 -75.882355   -0.486599\n",
      "2017-01-24  39.613984  40.354702  40.004539 -44.999845    2.567249\n",
      "2017-01-25  41.345528  41.653358  40.106508  -5.294093    3.218104\n",
      "2017-01-26  41.768794  41.778416  40.187314  -7.967055    0.300233\n",
      "2017-01-27  41.730318  41.124275  40.254652 -26.648366   -1.565738\n",
      "2017-01-30  40.450887  40.412407  40.213286 -46.978300   -1.731017\n",
      "2017-01-31  39.941050  39.921810  40.295053 -60.989038   -1.213976\n",
      "2017-02-01  40.575947  39.671696  40.284472 -68.131946   -0.626511\n",
      "2017-02-02  39.344624  39.681313  40.347962 -67.857303    0.024241\n",
      "2017-02-03  41.056932  41.634113  40.557672 -12.088123    4.921210\n",
      "2017-02-06  41.076173  41.249329  40.748142 -23.077021   -0.924205\n",
      "2017-02-07  41.643742  41.047318  40.817403 -30.085905   -0.489732\n",
      "2017-02-08  40.710618  40.643280  40.716396 -43.880862   -0.984321\n",
      "2017-02-09  40.999217  41.903473  40.728901  -4.776111    3.100618\n",
      "                  open       close       sma10   williams  close_per1\n",
      "date                                                                 \n",
      "2021-12-09  128.366048  128.954254  126.545640 -56.115638   -1.312275\n",
      "2021-12-10  131.257188  129.392899  126.514735 -54.484835    0.340155\n",
      "2021-12-13  128.136754  124.806976  125.889652 -71.534484   -3.544184\n",
      "2021-12-14  124.039324  127.229538  126.481835 -62.527828    1.941047\n",
      "2021-12-15  127.787815  128.306229  127.581460 -37.275862    0.846258\n",
      "2021-12-16  132.553203  131.994904  128.061984 -18.544870    2.874899\n",
      "2021-12-17  129.891364  123.929665  128.337139 -62.800876   -6.110265\n",
      "2021-12-20  118.167347  116.652000  127.422945 -80.913390   -5.872415\n",
      "2021-12-21  120.019997  123.930000  126.586546 -49.459968    6.239070\n",
      "2021-12-22  123.639999  126.389999  126.158646 -38.828560    1.984991\n",
      "2021-12-23  128.460007  128.789993  126.142220 -28.456477    1.898880\n",
      "2021-12-27  129.820007  132.520004  126.454931 -12.336443    2.896196\n",
      "2021-12-28  132.479996  132.509995  127.225233 -13.113711   -0.007553\n",
      "2021-12-29  133.600006  132.289993  127.731278 -14.056528   -0.166026\n",
      "2021-12-30  133.139999  132.619995  128.162655 -12.642303    0.249453\n"
     ]
    }
   ],
   "source": [
    "data = getDB(ticker)\n",
    "print(data['close_per1'].std())\n",
    "print(data.head(15))\n",
    "print(data.tail(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_data(ticker):\n",
    "    df = getDB(ticker)\n",
    "\n",
    "    df['CP_ol'] = 0\n",
    "    df['CO_il'] = 0\n",
    "    df['SMA10_il'] = 0\n",
    "    df['W_il'] = 0\n",
    "    \n",
    "    value = df['close_per1'].std()\n",
    "    \n",
    "    # setting the outputs in the df\n",
    "    for i in range(len(df)):\n",
    "        if df.iloc[i]['close_per1'] > value:\n",
    "            df.iloc[i, df.columns.get_loc('CP_ol')] = 2\n",
    "        elif df.iloc[i]['close_per1'] < -value:\n",
    "            df.iloc[i, df.columns.get_loc('CP_ol')] = 1\n",
    "        else:\n",
    "            df.iloc[i, df.columns.get_loc('CP_ol')] = 0\n",
    "    \n",
    "    # setting the inputs in the df\n",
    "    for i in range(len(df)-1):\n",
    "        try:\n",
    "            if df.iloc[i]['close'] < df.iloc[i+1]['open']:\n",
    "                df.iloc[i+1, df.columns.get_loc('CO_il')] = 1\n",
    "            else:\n",
    "                df.iloc[i+1, df.columns.get_loc('CO_il')] = 0\n",
    "        except:\n",
    "            df.iloc[i+1, df.columns.get_loc('CO_il')] = np.nan\n",
    "            \n",
    "    \n",
    "    # setting the inputs in the df\n",
    "    for i in range(len(df)):\n",
    "        try:\n",
    "            if df.iloc[i]['close'] > df.iloc[i]['sma10']:\n",
    "                df.iloc[i, df.columns.get_loc('SMA10_il')] = 1\n",
    "            else:\n",
    "                df.iloc[i, df.columns.get_loc('SMA10_il')] = 0\n",
    "        except:\n",
    "            df.iloc[i, df.columns.get_loc('SMA10_il')] = np.nan\n",
    "            \n",
    "    \n",
    "    # setting the inputs in the df\n",
    "    for i in range(len(df)):\n",
    "        if df.iloc[i]['williams'] > -30: # overbought\n",
    "            df.iloc[i, df.columns.get_loc('W_il')] = -1\n",
    "        elif df.iloc[i]['williams'] < -70: # oversold\n",
    "            df.iloc[i, df.columns.get_loc('W_il')] = 1\n",
    "        else:\n",
    "            df.iloc[i, df.columns.get_loc('W_il')] = 0 # neutral\n",
    "    \n",
    "    \n",
    "    # deleting data that is not normalized\n",
    "    del df['open']\n",
    "    del df['close']\n",
    "    del df['sma10']\n",
    "    del df['williams']\n",
    "#     del df['close_per1']\n",
    "    \n",
    "    # reformating\n",
    "    df = df[[\n",
    "            'W_il','SMA10_il','CO_il','CP_ol','close_per1'\n",
    "            ]]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 open      close      sma10   williams  close_per1\n",
      "date                                                              \n",
      "2017-01-20  39.440818  39.537014  40.232526 -70.000233    1.256465\n",
      "2017-01-23  39.383103  39.344627  40.028588 -75.882355   -0.486599\n",
      "2017-01-24  39.613984  40.354702  40.004539 -44.999845    2.567249\n",
      "2017-01-25  41.345528  41.653358  40.106508  -5.294093    3.218104\n",
      "2017-01-26  41.768794  41.778416  40.187314  -7.967055    0.300233\n",
      "                  open       close       sma10   williams  close_per1\n",
      "date                                                                 \n",
      "2021-12-23  128.460007  128.789993  126.142220 -28.456477    1.898880\n",
      "2021-12-27  129.820007  132.520004  126.454931 -12.336443    2.896196\n",
      "2021-12-28  132.479996  132.509995  127.225233 -13.113711   -0.007553\n",
      "2021-12-29  133.600006  132.289993  127.731278 -14.056528   -0.166026\n",
      "2021-12-30  133.139999  132.619995  128.162655 -12.642303    0.249453\n"
     ]
    }
   ],
   "source": [
    "df = set_data(ticker)\n",
    "print(data.head())\n",
    "print(data.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_train(tickers, SEQ_LEN, SHIFT):\n",
    "    Sequential_data = []\n",
    "    for ticker in tickers:\n",
    "        df = set_data(ticker)[0:-SHIFT]\n",
    "        \n",
    "        del df['close_per1']\n",
    "        \n",
    "        df.head()\n",
    "\n",
    "        sequential_data = []  # this is a list that will CONTAIN the sequences\n",
    "        prev_days = deque(maxlen=SEQ_LEN)  # These will be our actual sequences. They are made with deque, which keeps the maximum length by popping out older values as new ones come in\n",
    "        \n",
    "        for i in df.values:  # iterate over the values\n",
    "            prev_days.append([n for n in i[:-1]])  # store all but the target\n",
    "            if len(prev_days) == SEQ_LEN:  # make sure we have 60 sequences!\n",
    "                sequential_data.append([np.array(prev_days), i[-1]])  # append those bad boys!\n",
    "        \n",
    "        \n",
    "        random.shuffle(sequential_data)  # shuffle for good measure.\n",
    "        \n",
    "        buy = []; notbuy = []; maybe = []\n",
    "        \n",
    "        for seq, target in sequential_data:  # iterate over the sequential data\n",
    "            if target == 0:\n",
    "                maybe.append([seq, target])\n",
    "            elif target == 1:\n",
    "                notbuy.append([seq, target]) \n",
    "            elif target == 2:\n",
    "                buy.append([seq, target])  \n",
    "        \n",
    "        # suffle data\n",
    "        random.shuffle(buy)\n",
    "        random.shuffle(notbuy)\n",
    "        random.shuffle(maybe)\n",
    "        \n",
    "        lower = min(len(buy), len(notbuy), len(maybe))  # what's the shorter length?\n",
    "        \n",
    "        # make sure lists are only up to the shortest length.\n",
    "        buy = buy[:lower]  \n",
    "        notbuy = notbuy[:lower]\n",
    "        maybe = maybe[:lower]\n",
    "        \n",
    "        sequential_data = buy+notbuy+maybe # add them together\n",
    "        random.shuffle(sequential_data)  # another shuffle, so the model doesn't get confused with all 1 class then the other.\n",
    "    \n",
    "        Sequential_data = Sequential_data + sequential_data\n",
    "        \n",
    "    random.shuffle(Sequential_data)\n",
    "    X = []; y = []\n",
    "    for seq, target in Sequential_data:  # going over our new sequential data\n",
    "        X.append(seq)  # X is the sequences\n",
    "        y.append(target)  # y is the targets/labels (buys vs sell/notbuy)\n",
    "\n",
    "    return np.array(X).astype(\"float64\"), np.array(y).astype(\"uint8\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_test(tickers, SEQ_LEN, SHIFT):\n",
    "    Sequential_data = []\n",
    "    for ticker in tickers:\n",
    "        df = set_data(ticker)[-SHIFT:]\n",
    "        \n",
    "        del df['close_per1']\n",
    "        df.head()\n",
    "\n",
    "        sequential_data = []  # this is a list that will CONTAIN the sequences\n",
    "        prev_days = deque(maxlen=SEQ_LEN)  # These will be our actual sequences. They are made with deque, which keeps the maximum length by popping out older values as new ones come in\n",
    "        \n",
    "        for i in df.values:  # iterate over the values\n",
    "            prev_days.append([n for n in i[:-1]])  # store all but the target\n",
    "            if len(prev_days) == SEQ_LEN:  # make sure we have 60 sequences!\n",
    "                sequential_data.append([np.array(prev_days), i[-1]])  # append those bad boys!\n",
    "        \n",
    "        \n",
    "        random.shuffle(sequential_data)  # shuffle for good measure.\n",
    "        \n",
    "        buy = []; notbuy = []; maybe = []\n",
    "        \n",
    "        for seq, target in sequential_data:  # iterate over the sequential data\n",
    "            if target == 0:\n",
    "                maybe.append([seq, target])\n",
    "            elif target == 1:\n",
    "                notbuy.append([seq, target]) \n",
    "            elif target == 2:\n",
    "                buy.append([seq, target])  \n",
    "        \n",
    "        # suffle data\n",
    "        random.shuffle(buy)\n",
    "        random.shuffle(notbuy)\n",
    "        random.shuffle(maybe)\n",
    "        \n",
    "        lower = min(len(buy), len(notbuy), len(maybe))  # what's the shorter length?\n",
    "        \n",
    "        # make sure lists are only up to the shortest length.\n",
    "        buy = buy[:lower]  \n",
    "        notbuy = notbuy[:lower]\n",
    "        maybe = maybe[:lower]\n",
    "        \n",
    "        sequential_data = buy+notbuy+maybe # add them together\n",
    "        random.shuffle(sequential_data)  # another shuffle, so the model doesn't get confused with all 1 class then the other.\n",
    "    \n",
    "        Sequential_data = Sequential_data + sequential_data\n",
    "        \n",
    "    random.shuffle(Sequential_data)\n",
    "    X = []; y = []\n",
    "    for seq, target in Sequential_data:  # going over our new sequential data\n",
    "        X.append(seq)  # X is the sequences\n",
    "        y.append(target)  # y is the targets/labels (buys vs sell/notbuy)\n",
    "\n",
    "    return np.array(X).astype(\"float64\"), np.array(y).astype(\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 2  # how long of a preceeding sequence to collect for RNN\n",
    "# FUTURE_PERIOD_PREDICT = 3  # how far into the future are we trying to predict?\n",
    "SHIFT = 150  # how far to shift the data so it can be back testest\n",
    "BATCH_SIZE = 64 # how many batches? Try smaller batch if you're getting OOM (out of memory) errors.\n",
    "EPOCHS = 750 # how many passes through our data\n",
    "\n",
    "\n",
    "tickers_train = [ticker]\n",
    "tickers_test = [ticker]\n",
    "\n",
    "train_x, train_y = process_train(tickers_train, SEQ_LEN,SHIFT)\n",
    "validation_x, validation_y = process_test(tickers_test, SEQ_LEN, SHIFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.  1.  1.]\n",
      " [-1.  1.  1.]]\n",
      "training data length: 279\n",
      "validation data length: 39\n"
     ]
    }
   ],
   "source": [
    "print(train_x[0])\n",
    "print('training data length: %d' % (len(train_x)))\n",
    "print('validation data length: %d' % (len(validation_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "length of train data:  279\n",
      "length of validation data:  39\n",
      "\n",
      "Epoch 1/750\n",
      "5/5 [==============================] - 3s 154ms/step - loss: 1.2055 - accuracy: 0.4229 - val_loss: 1.0976 - val_accuracy: 0.3846\n",
      "Epoch 2/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.1898 - accuracy: 0.4409 - val_loss: 1.0975 - val_accuracy: 0.3590\n",
      "Epoch 3/750\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.1848 - accuracy: 0.4337 - val_loss: 1.0974 - val_accuracy: 0.3590\n",
      "Epoch 4/750\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.1723 - accuracy: 0.4229 - val_loss: 1.0974 - val_accuracy: 0.3077\n",
      "Epoch 5/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.1548 - accuracy: 0.4301 - val_loss: 1.0973 - val_accuracy: 0.3333\n",
      "Epoch 6/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.1433 - accuracy: 0.4444 - val_loss: 1.0972 - val_accuracy: 0.3333\n",
      "Epoch 7/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.1266 - accuracy: 0.4409 - val_loss: 1.0971 - val_accuracy: 0.3333\n",
      "Epoch 8/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.1243 - accuracy: 0.4552 - val_loss: 1.0970 - val_accuracy: 0.3333\n",
      "Epoch 9/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.1246 - accuracy: 0.4373 - val_loss: 1.0969 - val_accuracy: 0.3333\n",
      "Epoch 10/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.1131 - accuracy: 0.4409 - val_loss: 1.0968 - val_accuracy: 0.3333\n",
      "Epoch 11/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.1007 - accuracy: 0.4444 - val_loss: 1.0968 - val_accuracy: 0.3333\n",
      "Epoch 12/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0898 - accuracy: 0.4588 - val_loss: 1.0967 - val_accuracy: 0.3333\n",
      "Epoch 13/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.0833 - accuracy: 0.4624 - val_loss: 1.0966 - val_accuracy: 0.3333\n",
      "Epoch 14/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0725 - accuracy: 0.4588 - val_loss: 1.0965 - val_accuracy: 0.3333\n",
      "Epoch 15/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0705 - accuracy: 0.4516 - val_loss: 1.0964 - val_accuracy: 0.3333\n",
      "Epoch 16/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0571 - accuracy: 0.4552 - val_loss: 1.0963 - val_accuracy: 0.3333\n",
      "Epoch 17/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0525 - accuracy: 0.4803 - val_loss: 1.0962 - val_accuracy: 0.3333\n",
      "Epoch 18/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.0558 - accuracy: 0.4659 - val_loss: 1.0961 - val_accuracy: 0.3333\n",
      "Epoch 19/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0535 - accuracy: 0.4767 - val_loss: 1.0960 - val_accuracy: 0.3333\n",
      "Epoch 20/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0429 - accuracy: 0.4695 - val_loss: 1.0959 - val_accuracy: 0.3333\n",
      "Epoch 21/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0256 - accuracy: 0.4982 - val_loss: 1.0957 - val_accuracy: 0.3333\n",
      "Epoch 22/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.0271 - accuracy: 0.4875 - val_loss: 1.0956 - val_accuracy: 0.3333\n",
      "Epoch 23/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0278 - accuracy: 0.4803 - val_loss: 1.0955 - val_accuracy: 0.3333\n",
      "Epoch 24/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0229 - accuracy: 0.4946 - val_loss: 1.0954 - val_accuracy: 0.3333\n",
      "Epoch 25/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0129 - accuracy: 0.4910 - val_loss: 1.0952 - val_accuracy: 0.3333\n",
      "Epoch 26/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0166 - accuracy: 0.5018 - val_loss: 1.0951 - val_accuracy: 0.3333\n",
      "Epoch 27/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0067 - accuracy: 0.4910 - val_loss: 1.0949 - val_accuracy: 0.3333\n",
      "Epoch 28/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9988 - accuracy: 0.5018 - val_loss: 1.0947 - val_accuracy: 0.3333\n",
      "Epoch 29/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9938 - accuracy: 0.5197 - val_loss: 1.0946 - val_accuracy: 0.3333\n",
      "Epoch 30/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9936 - accuracy: 0.5125 - val_loss: 1.0944 - val_accuracy: 0.3333\n",
      "Epoch 31/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9807 - accuracy: 0.5197 - val_loss: 1.0942 - val_accuracy: 0.3333\n",
      "Epoch 32/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9841 - accuracy: 0.5233 - val_loss: 1.0940 - val_accuracy: 0.3333\n",
      "Epoch 33/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9793 - accuracy: 0.5448 - val_loss: 1.0938 - val_accuracy: 0.3333\n",
      "Epoch 34/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9773 - accuracy: 0.5556 - val_loss: 1.0936 - val_accuracy: 0.3333\n",
      "Epoch 35/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9652 - accuracy: 0.5735 - val_loss: 1.0933 - val_accuracy: 0.3333\n",
      "Epoch 36/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9759 - accuracy: 0.5842 - val_loss: 1.0931 - val_accuracy: 0.3333\n",
      "Epoch 37/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9752 - accuracy: 0.5806 - val_loss: 1.0928 - val_accuracy: 0.3333\n",
      "Epoch 38/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9700 - accuracy: 0.5627 - val_loss: 1.0925 - val_accuracy: 0.3333\n",
      "Epoch 39/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9611 - accuracy: 0.5842 - val_loss: 1.0922 - val_accuracy: 0.3333\n",
      "Epoch 40/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9641 - accuracy: 0.5914 - val_loss: 1.0919 - val_accuracy: 0.3333\n",
      "Epoch 41/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9543 - accuracy: 0.5520 - val_loss: 1.0915 - val_accuracy: 0.3333\n",
      "Epoch 42/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9555 - accuracy: 0.5842 - val_loss: 1.0911 - val_accuracy: 0.3333\n",
      "Epoch 43/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9502 - accuracy: 0.5771 - val_loss: 1.0907 - val_accuracy: 0.3333\n",
      "Epoch 44/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9467 - accuracy: 0.5771 - val_loss: 1.0902 - val_accuracy: 0.3333\n",
      "Epoch 45/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9543 - accuracy: 0.5735 - val_loss: 1.0898 - val_accuracy: 0.3333\n",
      "Epoch 46/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9437 - accuracy: 0.5878 - val_loss: 1.0893 - val_accuracy: 0.3333\n",
      "Epoch 47/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9446 - accuracy: 0.5663 - val_loss: 1.0889 - val_accuracy: 0.3333\n",
      "Epoch 48/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9355 - accuracy: 0.5950 - val_loss: 1.0884 - val_accuracy: 0.3333\n",
      "Epoch 49/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9353 - accuracy: 0.5914 - val_loss: 1.0879 - val_accuracy: 0.3333\n",
      "Epoch 50/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9363 - accuracy: 0.5950 - val_loss: 1.0873 - val_accuracy: 0.3333\n",
      "Epoch 51/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9331 - accuracy: 0.6022 - val_loss: 1.0867 - val_accuracy: 0.3333\n",
      "Epoch 52/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9300 - accuracy: 0.5556 - val_loss: 1.0861 - val_accuracy: 0.3333\n",
      "Epoch 53/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9359 - accuracy: 0.5842 - val_loss: 1.0854 - val_accuracy: 0.3333\n",
      "Epoch 54/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9280 - accuracy: 0.5842 - val_loss: 1.0847 - val_accuracy: 0.3333\n",
      "Epoch 55/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9296 - accuracy: 0.5735 - val_loss: 1.0840 - val_accuracy: 0.3333\n",
      "Epoch 56/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9284 - accuracy: 0.5914 - val_loss: 1.0832 - val_accuracy: 0.3333\n",
      "Epoch 57/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9245 - accuracy: 0.6201 - val_loss: 1.0825 - val_accuracy: 0.3333\n",
      "Epoch 58/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9274 - accuracy: 0.5842 - val_loss: 1.0816 - val_accuracy: 0.3333\n",
      "Epoch 59/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9181 - accuracy: 0.5986 - val_loss: 1.0807 - val_accuracy: 0.3333\n",
      "Epoch 60/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9281 - accuracy: 0.5771 - val_loss: 1.0798 - val_accuracy: 0.3590\n",
      "Epoch 61/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9226 - accuracy: 0.5771 - val_loss: 1.0789 - val_accuracy: 0.3590\n",
      "Epoch 62/750\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.9245 - accuracy: 0.5663 - val_loss: 1.0778 - val_accuracy: 0.3590\n",
      "Epoch 63/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9259 - accuracy: 0.5735 - val_loss: 1.0767 - val_accuracy: 0.3846\n",
      "Epoch 64/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9136 - accuracy: 0.5950 - val_loss: 1.0756 - val_accuracy: 0.3846\n",
      "Epoch 65/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9188 - accuracy: 0.5878 - val_loss: 1.0744 - val_accuracy: 0.3846\n",
      "Epoch 66/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9155 - accuracy: 0.6093 - val_loss: 1.0732 - val_accuracy: 0.3846\n",
      "Epoch 67/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9064 - accuracy: 0.5914 - val_loss: 1.0719 - val_accuracy: 0.3846\n",
      "Epoch 68/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9194 - accuracy: 0.5699 - val_loss: 1.0706 - val_accuracy: 0.3846\n",
      "Epoch 69/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9150 - accuracy: 0.5914 - val_loss: 1.0692 - val_accuracy: 0.3846\n",
      "Epoch 70/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9133 - accuracy: 0.5842 - val_loss: 1.0677 - val_accuracy: 0.3846\n",
      "Epoch 71/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9167 - accuracy: 0.5771 - val_loss: 1.0662 - val_accuracy: 0.3846\n",
      "Epoch 72/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9094 - accuracy: 0.5950 - val_loss: 1.0647 - val_accuracy: 0.3846\n",
      "Epoch 73/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9110 - accuracy: 0.5520 - val_loss: 1.0633 - val_accuracy: 0.3846\n",
      "Epoch 74/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9133 - accuracy: 0.5950 - val_loss: 1.0615 - val_accuracy: 0.3846\n",
      "Epoch 75/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9056 - accuracy: 0.6022 - val_loss: 1.0598 - val_accuracy: 0.3846\n",
      "Epoch 76/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9064 - accuracy: 0.5914 - val_loss: 1.0579 - val_accuracy: 0.4103\n",
      "Epoch 77/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9002 - accuracy: 0.5878 - val_loss: 1.0562 - val_accuracy: 0.4103\n",
      "Epoch 78/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8925 - accuracy: 0.5986 - val_loss: 1.0543 - val_accuracy: 0.4615\n",
      "Epoch 79/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9029 - accuracy: 0.5950 - val_loss: 1.0524 - val_accuracy: 0.4615\n",
      "Epoch 80/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8968 - accuracy: 0.5914 - val_loss: 1.0504 - val_accuracy: 0.4615\n",
      "Epoch 81/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8985 - accuracy: 0.5986 - val_loss: 1.0483 - val_accuracy: 0.4615\n",
      "Epoch 82/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9046 - accuracy: 0.5986 - val_loss: 1.0459 - val_accuracy: 0.4615\n",
      "Epoch 83/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8947 - accuracy: 0.5878 - val_loss: 1.0436 - val_accuracy: 0.4359\n",
      "Epoch 84/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8930 - accuracy: 0.6093 - val_loss: 1.0413 - val_accuracy: 0.5385\n",
      "Epoch 85/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8954 - accuracy: 0.6057 - val_loss: 1.0389 - val_accuracy: 0.5385\n",
      "Epoch 86/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8877 - accuracy: 0.6093 - val_loss: 1.0365 - val_accuracy: 0.5385\n",
      "Epoch 87/750\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.8899 - accuracy: 0.5914 - val_loss: 1.0340 - val_accuracy: 0.5385\n",
      "Epoch 88/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8985 - accuracy: 0.6022 - val_loss: 1.0316 - val_accuracy: 0.5385\n",
      "Epoch 89/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8877 - accuracy: 0.5914 - val_loss: 1.0291 - val_accuracy: 0.5385\n",
      "Epoch 90/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8885 - accuracy: 0.5950 - val_loss: 1.0264 - val_accuracy: 0.5385\n",
      "Epoch 91/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8805 - accuracy: 0.6201 - val_loss: 1.0238 - val_accuracy: 0.5385\n",
      "Epoch 92/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8858 - accuracy: 0.6129 - val_loss: 1.0210 - val_accuracy: 0.5385\n",
      "Epoch 93/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8868 - accuracy: 0.6022 - val_loss: 1.0179 - val_accuracy: 0.5385\n",
      "Epoch 94/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8805 - accuracy: 0.6057 - val_loss: 1.0149 - val_accuracy: 0.5385\n",
      "Epoch 95/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8789 - accuracy: 0.6165 - val_loss: 1.0121 - val_accuracy: 0.5641\n",
      "Epoch 96/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8841 - accuracy: 0.6093 - val_loss: 1.0091 - val_accuracy: 0.5641\n",
      "Epoch 97/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8779 - accuracy: 0.6129 - val_loss: 1.0062 - val_accuracy: 0.5897\n",
      "Epoch 98/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8821 - accuracy: 0.5806 - val_loss: 1.0033 - val_accuracy: 0.5897\n",
      "Epoch 99/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8862 - accuracy: 0.6057 - val_loss: 1.0003 - val_accuracy: 0.5897\n",
      "Epoch 100/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8763 - accuracy: 0.5986 - val_loss: 0.9973 - val_accuracy: 0.5897\n",
      "Epoch 101/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8744 - accuracy: 0.6308 - val_loss: 0.9943 - val_accuracy: 0.5897\n",
      "Epoch 102/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8761 - accuracy: 0.6272 - val_loss: 0.9913 - val_accuracy: 0.5897\n",
      "Epoch 103/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8753 - accuracy: 0.6165 - val_loss: 0.9881 - val_accuracy: 0.5897\n",
      "Epoch 104/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8719 - accuracy: 0.6237 - val_loss: 0.9849 - val_accuracy: 0.5897\n",
      "Epoch 105/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8701 - accuracy: 0.6380 - val_loss: 0.9818 - val_accuracy: 0.5897\n",
      "Epoch 106/750\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.8658 - accuracy: 0.6272 - val_loss: 0.9787 - val_accuracy: 0.5897\n",
      "Epoch 107/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8809 - accuracy: 0.5986 - val_loss: 0.9757 - val_accuracy: 0.5897\n",
      "Epoch 108/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8717 - accuracy: 0.6022 - val_loss: 0.9726 - val_accuracy: 0.5897\n",
      "Epoch 109/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8758 - accuracy: 0.6237 - val_loss: 0.9696 - val_accuracy: 0.5897\n",
      "Epoch 110/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8684 - accuracy: 0.6452 - val_loss: 0.9664 - val_accuracy: 0.5897\n",
      "Epoch 111/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8685 - accuracy: 0.6201 - val_loss: 0.9633 - val_accuracy: 0.5897\n",
      "Epoch 112/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8626 - accuracy: 0.6272 - val_loss: 0.9603 - val_accuracy: 0.5385\n",
      "Epoch 113/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8616 - accuracy: 0.6559 - val_loss: 0.9574 - val_accuracy: 0.5385\n",
      "Epoch 114/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8644 - accuracy: 0.6237 - val_loss: 0.9546 - val_accuracy: 0.5385\n",
      "Epoch 115/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8776 - accuracy: 0.6344 - val_loss: 0.9517 - val_accuracy: 0.5385\n",
      "Epoch 116/750\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.8643 - accuracy: 0.6308 - val_loss: 0.9489 - val_accuracy: 0.5385\n",
      "Epoch 117/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8645 - accuracy: 0.6093 - val_loss: 0.9462 - val_accuracy: 0.5385\n",
      "Epoch 118/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8626 - accuracy: 0.6416 - val_loss: 0.9436 - val_accuracy: 0.5385\n",
      "Epoch 119/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8599 - accuracy: 0.6487 - val_loss: 0.9414 - val_accuracy: 0.5385\n",
      "Epoch 120/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8673 - accuracy: 0.6237 - val_loss: 0.9391 - val_accuracy: 0.5641\n",
      "Epoch 121/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8690 - accuracy: 0.6308 - val_loss: 0.9368 - val_accuracy: 0.5641\n",
      "Epoch 122/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8604 - accuracy: 0.6344 - val_loss: 0.9343 - val_accuracy: 0.5641\n",
      "Epoch 123/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8624 - accuracy: 0.6559 - val_loss: 0.9317 - val_accuracy: 0.5641\n",
      "Epoch 124/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8592 - accuracy: 0.6380 - val_loss: 0.9294 - val_accuracy: 0.5641\n",
      "Epoch 125/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8602 - accuracy: 0.6344 - val_loss: 0.9269 - val_accuracy: 0.5641\n",
      "Epoch 126/750\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.8509 - accuracy: 0.6523 - val_loss: 0.9245 - val_accuracy: 0.5897\n",
      "Epoch 127/750\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.8513 - accuracy: 0.6523 - val_loss: 0.9220 - val_accuracy: 0.6154\n",
      "Epoch 128/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8540 - accuracy: 0.6452 - val_loss: 0.9197 - val_accuracy: 0.6154\n",
      "Epoch 129/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8613 - accuracy: 0.6452 - val_loss: 0.9173 - val_accuracy: 0.6154\n",
      "Epoch 130/750\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.8463 - accuracy: 0.6523 - val_loss: 0.9146 - val_accuracy: 0.6154\n",
      "Epoch 131/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8464 - accuracy: 0.6487 - val_loss: 0.9120 - val_accuracy: 0.6154\n",
      "Epoch 132/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8583 - accuracy: 0.6595 - val_loss: 0.9097 - val_accuracy: 0.6154\n",
      "Epoch 133/750\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.8432 - accuracy: 0.6523 - val_loss: 0.9074 - val_accuracy: 0.6154\n",
      "Epoch 134/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8451 - accuracy: 0.6416 - val_loss: 0.9050 - val_accuracy: 0.6154\n",
      "Epoch 135/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8603 - accuracy: 0.6201 - val_loss: 0.9026 - val_accuracy: 0.6154\n",
      "Epoch 136/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8412 - accuracy: 0.6559 - val_loss: 0.9003 - val_accuracy: 0.6154\n",
      "Epoch 137/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8417 - accuracy: 0.6595 - val_loss: 0.8983 - val_accuracy: 0.6154\n",
      "Epoch 138/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8499 - accuracy: 0.6559 - val_loss: 0.8967 - val_accuracy: 0.6154\n",
      "Epoch 139/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8489 - accuracy: 0.6487 - val_loss: 0.8951 - val_accuracy: 0.6667\n",
      "Epoch 140/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8477 - accuracy: 0.6380 - val_loss: 0.8931 - val_accuracy: 0.6667\n",
      "Epoch 141/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8404 - accuracy: 0.6559 - val_loss: 0.8911 - val_accuracy: 0.6667\n",
      "Epoch 142/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8389 - accuracy: 0.6631 - val_loss: 0.8895 - val_accuracy: 0.6667\n",
      "Epoch 143/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8361 - accuracy: 0.6595 - val_loss: 0.8876 - val_accuracy: 0.6667\n",
      "Epoch 144/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8370 - accuracy: 0.6595 - val_loss: 0.8858 - val_accuracy: 0.6667\n",
      "Epoch 145/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8375 - accuracy: 0.6559 - val_loss: 0.8840 - val_accuracy: 0.6667\n",
      "Epoch 146/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8303 - accuracy: 0.6523 - val_loss: 0.8823 - val_accuracy: 0.6667\n",
      "Epoch 147/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8319 - accuracy: 0.6523 - val_loss: 0.8806 - val_accuracy: 0.6667\n",
      "Epoch 148/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8324 - accuracy: 0.6631 - val_loss: 0.8791 - val_accuracy: 0.6667\n",
      "Epoch 149/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8411 - accuracy: 0.6416 - val_loss: 0.8777 - val_accuracy: 0.6667\n",
      "Epoch 150/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8439 - accuracy: 0.6380 - val_loss: 0.8761 - val_accuracy: 0.6667\n",
      "Epoch 151/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8364 - accuracy: 0.6380 - val_loss: 0.8749 - val_accuracy: 0.6667\n",
      "Epoch 152/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8316 - accuracy: 0.6523 - val_loss: 0.8735 - val_accuracy: 0.6667\n",
      "Epoch 153/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8305 - accuracy: 0.6487 - val_loss: 0.8718 - val_accuracy: 0.6667\n",
      "Epoch 154/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8262 - accuracy: 0.6595 - val_loss: 0.8701 - val_accuracy: 0.6667\n",
      "Epoch 155/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8319 - accuracy: 0.6738 - val_loss: 0.8680 - val_accuracy: 0.6667\n",
      "Epoch 156/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8358 - accuracy: 0.6308 - val_loss: 0.8659 - val_accuracy: 0.6667\n",
      "Epoch 157/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8286 - accuracy: 0.6559 - val_loss: 0.8643 - val_accuracy: 0.6667\n",
      "Epoch 158/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8326 - accuracy: 0.6487 - val_loss: 0.8625 - val_accuracy: 0.6667\n",
      "Epoch 159/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8200 - accuracy: 0.6667 - val_loss: 0.8609 - val_accuracy: 0.6667\n",
      "Epoch 160/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8290 - accuracy: 0.6559 - val_loss: 0.8595 - val_accuracy: 0.6667\n",
      "Epoch 161/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8345 - accuracy: 0.6380 - val_loss: 0.8581 - val_accuracy: 0.6667\n",
      "Epoch 162/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8333 - accuracy: 0.6595 - val_loss: 0.8569 - val_accuracy: 0.6667\n",
      "Epoch 163/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8238 - accuracy: 0.6559 - val_loss: 0.8554 - val_accuracy: 0.6667\n",
      "Epoch 164/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8283 - accuracy: 0.6380 - val_loss: 0.8539 - val_accuracy: 0.6667\n",
      "Epoch 165/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8244 - accuracy: 0.6559 - val_loss: 0.8528 - val_accuracy: 0.6667\n",
      "Epoch 166/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8319 - accuracy: 0.6523 - val_loss: 0.8515 - val_accuracy: 0.6667\n",
      "Epoch 167/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8224 - accuracy: 0.6631 - val_loss: 0.8508 - val_accuracy: 0.6667\n",
      "Epoch 168/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8146 - accuracy: 0.6738 - val_loss: 0.8496 - val_accuracy: 0.6667\n",
      "Epoch 169/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8219 - accuracy: 0.6559 - val_loss: 0.8489 - val_accuracy: 0.6667\n",
      "Epoch 170/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8150 - accuracy: 0.6774 - val_loss: 0.8477 - val_accuracy: 0.6667\n",
      "Epoch 171/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8151 - accuracy: 0.6487 - val_loss: 0.8466 - val_accuracy: 0.6667\n",
      "Epoch 172/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8159 - accuracy: 0.6380 - val_loss: 0.8456 - val_accuracy: 0.6667\n",
      "Epoch 173/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8184 - accuracy: 0.6559 - val_loss: 0.8443 - val_accuracy: 0.6667\n",
      "Epoch 174/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8141 - accuracy: 0.6631 - val_loss: 0.8429 - val_accuracy: 0.6667\n",
      "Epoch 175/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8114 - accuracy: 0.6631 - val_loss: 0.8418 - val_accuracy: 0.6667\n",
      "Epoch 176/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8145 - accuracy: 0.6703 - val_loss: 0.8412 - val_accuracy: 0.6667\n",
      "Epoch 177/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8143 - accuracy: 0.6595 - val_loss: 0.8402 - val_accuracy: 0.6667\n",
      "Epoch 178/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8127 - accuracy: 0.6738 - val_loss: 0.8392 - val_accuracy: 0.6667\n",
      "Epoch 179/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8091 - accuracy: 0.6667 - val_loss: 0.8382 - val_accuracy: 0.6667\n",
      "Epoch 180/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8060 - accuracy: 0.6631 - val_loss: 0.8372 - val_accuracy: 0.6667\n",
      "Epoch 181/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8109 - accuracy: 0.6523 - val_loss: 0.8359 - val_accuracy: 0.6667\n",
      "Epoch 182/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8062 - accuracy: 0.6631 - val_loss: 0.8348 - val_accuracy: 0.6667\n",
      "Epoch 183/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8114 - accuracy: 0.6595 - val_loss: 0.8342 - val_accuracy: 0.6667\n",
      "Epoch 184/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8156 - accuracy: 0.6559 - val_loss: 0.8331 - val_accuracy: 0.6667\n",
      "Epoch 185/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8100 - accuracy: 0.6703 - val_loss: 0.8322 - val_accuracy: 0.6410\n",
      "Epoch 186/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8047 - accuracy: 0.6667 - val_loss: 0.8319 - val_accuracy: 0.6410\n",
      "Epoch 187/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8015 - accuracy: 0.6595 - val_loss: 0.8311 - val_accuracy: 0.6410\n",
      "Epoch 188/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8036 - accuracy: 0.6774 - val_loss: 0.8300 - val_accuracy: 0.6410\n",
      "Epoch 189/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7980 - accuracy: 0.6738 - val_loss: 0.8291 - val_accuracy: 0.6410\n",
      "Epoch 190/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8009 - accuracy: 0.6631 - val_loss: 0.8284 - val_accuracy: 0.6667\n",
      "Epoch 191/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8158 - accuracy: 0.6667 - val_loss: 0.8274 - val_accuracy: 0.6410\n",
      "Epoch 192/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7984 - accuracy: 0.6667 - val_loss: 0.8264 - val_accuracy: 0.6410\n",
      "Epoch 193/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7900 - accuracy: 0.6667 - val_loss: 0.8256 - val_accuracy: 0.6410\n",
      "Epoch 194/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8000 - accuracy: 0.6667 - val_loss: 0.8247 - val_accuracy: 0.6667\n",
      "Epoch 195/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7951 - accuracy: 0.6738 - val_loss: 0.8233 - val_accuracy: 0.6667\n",
      "Epoch 196/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7997 - accuracy: 0.6631 - val_loss: 0.8219 - val_accuracy: 0.6667\n",
      "Epoch 197/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8011 - accuracy: 0.6667 - val_loss: 0.8210 - val_accuracy: 0.6667\n",
      "Epoch 198/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7934 - accuracy: 0.6703 - val_loss: 0.8194 - val_accuracy: 0.6667\n",
      "Epoch 199/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8007 - accuracy: 0.6559 - val_loss: 0.8182 - val_accuracy: 0.6667\n",
      "Epoch 200/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7969 - accuracy: 0.6703 - val_loss: 0.8172 - val_accuracy: 0.6667\n",
      "Epoch 201/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7951 - accuracy: 0.6667 - val_loss: 0.8168 - val_accuracy: 0.6667\n",
      "Epoch 202/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7932 - accuracy: 0.6703 - val_loss: 0.8163 - val_accuracy: 0.6667\n",
      "Epoch 203/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7919 - accuracy: 0.6667 - val_loss: 0.8158 - val_accuracy: 0.6667\n",
      "Epoch 204/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7945 - accuracy: 0.6667 - val_loss: 0.8153 - val_accuracy: 0.6667\n",
      "Epoch 205/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7905 - accuracy: 0.6703 - val_loss: 0.8141 - val_accuracy: 0.6667\n",
      "Epoch 206/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7932 - accuracy: 0.6523 - val_loss: 0.8123 - val_accuracy: 0.6667\n",
      "Epoch 207/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8024 - accuracy: 0.6416 - val_loss: 0.8109 - val_accuracy: 0.6667\n",
      "Epoch 208/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7924 - accuracy: 0.6738 - val_loss: 0.8099 - val_accuracy: 0.6667\n",
      "Epoch 209/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7881 - accuracy: 0.6810 - val_loss: 0.8090 - val_accuracy: 0.6667\n",
      "Epoch 210/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7865 - accuracy: 0.6738 - val_loss: 0.8081 - val_accuracy: 0.6667\n",
      "Epoch 211/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7945 - accuracy: 0.6667 - val_loss: 0.8069 - val_accuracy: 0.6667\n",
      "Epoch 212/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7914 - accuracy: 0.6667 - val_loss: 0.8056 - val_accuracy: 0.6667\n",
      "Epoch 213/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7870 - accuracy: 0.6631 - val_loss: 0.8048 - val_accuracy: 0.6667\n",
      "Epoch 214/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7816 - accuracy: 0.6595 - val_loss: 0.8036 - val_accuracy: 0.6667\n",
      "Epoch 215/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7892 - accuracy: 0.6631 - val_loss: 0.8028 - val_accuracy: 0.6667\n",
      "Epoch 216/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7873 - accuracy: 0.6703 - val_loss: 0.8022 - val_accuracy: 0.6667\n",
      "Epoch 217/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7856 - accuracy: 0.6667 - val_loss: 0.8014 - val_accuracy: 0.6667\n",
      "Epoch 218/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7829 - accuracy: 0.6667 - val_loss: 0.8003 - val_accuracy: 0.6667\n",
      "Epoch 219/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7839 - accuracy: 0.6667 - val_loss: 0.7995 - val_accuracy: 0.6667\n",
      "Epoch 220/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7959 - accuracy: 0.6487 - val_loss: 0.7990 - val_accuracy: 0.6667\n",
      "Epoch 221/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7839 - accuracy: 0.6631 - val_loss: 0.7986 - val_accuracy: 0.6667\n",
      "Epoch 222/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7782 - accuracy: 0.6559 - val_loss: 0.7979 - val_accuracy: 0.6667\n",
      "Epoch 223/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7806 - accuracy: 0.6774 - val_loss: 0.7971 - val_accuracy: 0.6667\n",
      "Epoch 224/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7857 - accuracy: 0.6738 - val_loss: 0.7967 - val_accuracy: 0.6667\n",
      "Epoch 225/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7786 - accuracy: 0.6631 - val_loss: 0.7960 - val_accuracy: 0.6667\n",
      "Epoch 226/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7826 - accuracy: 0.6631 - val_loss: 0.7943 - val_accuracy: 0.6667\n",
      "Epoch 227/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7712 - accuracy: 0.6738 - val_loss: 0.7936 - val_accuracy: 0.6667\n",
      "Epoch 228/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7778 - accuracy: 0.6703 - val_loss: 0.7924 - val_accuracy: 0.6667\n",
      "Epoch 229/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7734 - accuracy: 0.6738 - val_loss: 0.7908 - val_accuracy: 0.6667\n",
      "Epoch 230/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7718 - accuracy: 0.6487 - val_loss: 0.7905 - val_accuracy: 0.6667\n",
      "Epoch 231/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7850 - accuracy: 0.6595 - val_loss: 0.7897 - val_accuracy: 0.6667\n",
      "Epoch 232/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7656 - accuracy: 0.6882 - val_loss: 0.7886 - val_accuracy: 0.6667\n",
      "Epoch 233/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7761 - accuracy: 0.6667 - val_loss: 0.7880 - val_accuracy: 0.6667\n",
      "Epoch 234/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7679 - accuracy: 0.6595 - val_loss: 0.7875 - val_accuracy: 0.6667\n",
      "Epoch 235/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7650 - accuracy: 0.6738 - val_loss: 0.7873 - val_accuracy: 0.6667\n",
      "Epoch 236/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7724 - accuracy: 0.6559 - val_loss: 0.7868 - val_accuracy: 0.6667\n",
      "Epoch 237/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7728 - accuracy: 0.6774 - val_loss: 0.7862 - val_accuracy: 0.6667\n",
      "Epoch 238/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7656 - accuracy: 0.6774 - val_loss: 0.7853 - val_accuracy: 0.6667\n",
      "Epoch 239/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7688 - accuracy: 0.6487 - val_loss: 0.7846 - val_accuracy: 0.6667\n",
      "Epoch 240/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7730 - accuracy: 0.6738 - val_loss: 0.7838 - val_accuracy: 0.6667\n",
      "Epoch 241/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7684 - accuracy: 0.6810 - val_loss: 0.7826 - val_accuracy: 0.6667\n",
      "Epoch 242/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7649 - accuracy: 0.6703 - val_loss: 0.7816 - val_accuracy: 0.6667\n",
      "Epoch 243/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7736 - accuracy: 0.6882 - val_loss: 0.7807 - val_accuracy: 0.6667\n",
      "Epoch 244/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7638 - accuracy: 0.6774 - val_loss: 0.7793 - val_accuracy: 0.6667\n",
      "Epoch 245/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7672 - accuracy: 0.6667 - val_loss: 0.7782 - val_accuracy: 0.6667\n",
      "Epoch 246/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7617 - accuracy: 0.6882 - val_loss: 0.7779 - val_accuracy: 0.6667\n",
      "Epoch 247/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7628 - accuracy: 0.6738 - val_loss: 0.7770 - val_accuracy: 0.6667\n",
      "Epoch 248/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7648 - accuracy: 0.6667 - val_loss: 0.7758 - val_accuracy: 0.6667\n",
      "Epoch 249/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7596 - accuracy: 0.6774 - val_loss: 0.7747 - val_accuracy: 0.6667\n",
      "Epoch 250/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7594 - accuracy: 0.6918 - val_loss: 0.7740 - val_accuracy: 0.6667\n",
      "Epoch 251/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7646 - accuracy: 0.6595 - val_loss: 0.7729 - val_accuracy: 0.6667\n",
      "Epoch 252/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7511 - accuracy: 0.6703 - val_loss: 0.7718 - val_accuracy: 0.6667\n",
      "Epoch 253/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7598 - accuracy: 0.6703 - val_loss: 0.7713 - val_accuracy: 0.6667\n",
      "Epoch 254/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7551 - accuracy: 0.6846 - val_loss: 0.7706 - val_accuracy: 0.6667\n",
      "Epoch 255/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7526 - accuracy: 0.6882 - val_loss: 0.7701 - val_accuracy: 0.6667\n",
      "Epoch 256/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7602 - accuracy: 0.6703 - val_loss: 0.7690 - val_accuracy: 0.6667\n",
      "Epoch 257/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7564 - accuracy: 0.6738 - val_loss: 0.7679 - val_accuracy: 0.6667\n",
      "Epoch 258/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7546 - accuracy: 0.6738 - val_loss: 0.7666 - val_accuracy: 0.6667\n",
      "Epoch 259/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7521 - accuracy: 0.6774 - val_loss: 0.7655 - val_accuracy: 0.6667\n",
      "Epoch 260/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7525 - accuracy: 0.6918 - val_loss: 0.7647 - val_accuracy: 0.6667\n",
      "Epoch 261/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7587 - accuracy: 0.6667 - val_loss: 0.7636 - val_accuracy: 0.6667\n",
      "Epoch 262/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7638 - accuracy: 0.6631 - val_loss: 0.7629 - val_accuracy: 0.6667\n",
      "Epoch 263/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7556 - accuracy: 0.6774 - val_loss: 0.7614 - val_accuracy: 0.7436\n",
      "Epoch 264/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7529 - accuracy: 0.6846 - val_loss: 0.7603 - val_accuracy: 0.7436\n",
      "Epoch 265/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7508 - accuracy: 0.6846 - val_loss: 0.7597 - val_accuracy: 0.7436\n",
      "Epoch 266/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7529 - accuracy: 0.6882 - val_loss: 0.7589 - val_accuracy: 0.7436\n",
      "Epoch 267/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7538 - accuracy: 0.6667 - val_loss: 0.7587 - val_accuracy: 0.7436\n",
      "Epoch 268/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7475 - accuracy: 0.6882 - val_loss: 0.7582 - val_accuracy: 0.7436\n",
      "Epoch 269/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7501 - accuracy: 0.6774 - val_loss: 0.7577 - val_accuracy: 0.7436\n",
      "Epoch 270/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7484 - accuracy: 0.6810 - val_loss: 0.7567 - val_accuracy: 0.7436\n",
      "Epoch 271/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7470 - accuracy: 0.6774 - val_loss: 0.7561 - val_accuracy: 0.7436\n",
      "Epoch 272/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7481 - accuracy: 0.6846 - val_loss: 0.7555 - val_accuracy: 0.7436\n",
      "Epoch 273/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7458 - accuracy: 0.6882 - val_loss: 0.7548 - val_accuracy: 0.7436\n",
      "Epoch 274/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7450 - accuracy: 0.6774 - val_loss: 0.7539 - val_accuracy: 0.7436\n",
      "Epoch 275/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7430 - accuracy: 0.6738 - val_loss: 0.7529 - val_accuracy: 0.7436\n",
      "Epoch 276/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7379 - accuracy: 0.6774 - val_loss: 0.7515 - val_accuracy: 0.7436\n",
      "Epoch 277/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7454 - accuracy: 0.6738 - val_loss: 0.7505 - val_accuracy: 0.7436\n",
      "Epoch 278/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7461 - accuracy: 0.6810 - val_loss: 0.7491 - val_accuracy: 0.7436\n",
      "Epoch 279/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7461 - accuracy: 0.6882 - val_loss: 0.7472 - val_accuracy: 0.7436\n",
      "Epoch 280/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7525 - accuracy: 0.6846 - val_loss: 0.7459 - val_accuracy: 0.7436\n",
      "Epoch 281/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7478 - accuracy: 0.6774 - val_loss: 0.7448 - val_accuracy: 0.7436\n",
      "Epoch 282/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7393 - accuracy: 0.6810 - val_loss: 0.7438 - val_accuracy: 0.7436\n",
      "Epoch 283/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7328 - accuracy: 0.6953 - val_loss: 0.7433 - val_accuracy: 0.7436\n",
      "Epoch 284/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7302 - accuracy: 0.6882 - val_loss: 0.7428 - val_accuracy: 0.7436\n",
      "Epoch 285/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7487 - accuracy: 0.6631 - val_loss: 0.7426 - val_accuracy: 0.7436\n",
      "Epoch 286/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7304 - accuracy: 0.6738 - val_loss: 0.7421 - val_accuracy: 0.7436\n",
      "Epoch 287/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7459 - accuracy: 0.6846 - val_loss: 0.7421 - val_accuracy: 0.7436\n",
      "Epoch 288/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7288 - accuracy: 0.6918 - val_loss: 0.7411 - val_accuracy: 0.7436\n",
      "Epoch 289/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7401 - accuracy: 0.6667 - val_loss: 0.7402 - val_accuracy: 0.7436\n",
      "Epoch 290/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7529 - accuracy: 0.6559 - val_loss: 0.7398 - val_accuracy: 0.7436\n",
      "Epoch 291/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7420 - accuracy: 0.6631 - val_loss: 0.7390 - val_accuracy: 0.7436\n",
      "Epoch 292/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7356 - accuracy: 0.6989 - val_loss: 0.7387 - val_accuracy: 0.7436\n",
      "Epoch 293/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7363 - accuracy: 0.6846 - val_loss: 0.7382 - val_accuracy: 0.7436\n",
      "Epoch 294/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7373 - accuracy: 0.6774 - val_loss: 0.7369 - val_accuracy: 0.7436\n",
      "Epoch 295/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7358 - accuracy: 0.6846 - val_loss: 0.7353 - val_accuracy: 0.7436\n",
      "Epoch 296/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7332 - accuracy: 0.6774 - val_loss: 0.7346 - val_accuracy: 0.7436\n",
      "Epoch 297/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7387 - accuracy: 0.6846 - val_loss: 0.7337 - val_accuracy: 0.7436\n",
      "Epoch 298/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7375 - accuracy: 0.6703 - val_loss: 0.7329 - val_accuracy: 0.7436\n",
      "Epoch 299/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7406 - accuracy: 0.6810 - val_loss: 0.7319 - val_accuracy: 0.7436\n",
      "Epoch 300/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7323 - accuracy: 0.6846 - val_loss: 0.7307 - val_accuracy: 0.7436\n",
      "Epoch 301/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7301 - accuracy: 0.6882 - val_loss: 0.7297 - val_accuracy: 0.7436\n",
      "Epoch 302/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7271 - accuracy: 0.6846 - val_loss: 0.7289 - val_accuracy: 0.7436\n",
      "Epoch 303/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7241 - accuracy: 0.6918 - val_loss: 0.7284 - val_accuracy: 0.7436\n",
      "Epoch 304/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7328 - accuracy: 0.6774 - val_loss: 0.7282 - val_accuracy: 0.7436\n",
      "Epoch 305/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7291 - accuracy: 0.6810 - val_loss: 0.7277 - val_accuracy: 0.7436\n",
      "Epoch 306/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7397 - accuracy: 0.6810 - val_loss: 0.7272 - val_accuracy: 0.7436\n",
      "Epoch 307/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7354 - accuracy: 0.6810 - val_loss: 0.7269 - val_accuracy: 0.7436\n",
      "Epoch 308/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7354 - accuracy: 0.6846 - val_loss: 0.7268 - val_accuracy: 0.7436\n",
      "Epoch 309/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7273 - accuracy: 0.6989 - val_loss: 0.7265 - val_accuracy: 0.7436\n",
      "Epoch 310/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7342 - accuracy: 0.6953 - val_loss: 0.7261 - val_accuracy: 0.7436\n",
      "Epoch 311/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7376 - accuracy: 0.6738 - val_loss: 0.7259 - val_accuracy: 0.7436\n",
      "Epoch 312/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7247 - accuracy: 0.7025 - val_loss: 0.7251 - val_accuracy: 0.7436\n",
      "Epoch 313/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7277 - accuracy: 0.6953 - val_loss: 0.7248 - val_accuracy: 0.7436\n",
      "Epoch 314/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7274 - accuracy: 0.6918 - val_loss: 0.7249 - val_accuracy: 0.7436\n",
      "Epoch 315/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7224 - accuracy: 0.6989 - val_loss: 0.7250 - val_accuracy: 0.7436\n",
      "Epoch 316/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7174 - accuracy: 0.6846 - val_loss: 0.7250 - val_accuracy: 0.7436\n",
      "Epoch 317/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7265 - accuracy: 0.6989 - val_loss: 0.7242 - val_accuracy: 0.7436\n",
      "Epoch 318/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7383 - accuracy: 0.6774 - val_loss: 0.7234 - val_accuracy: 0.7436\n",
      "Epoch 319/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7215 - accuracy: 0.6918 - val_loss: 0.7230 - val_accuracy: 0.7436\n",
      "Epoch 320/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7265 - accuracy: 0.6703 - val_loss: 0.7226 - val_accuracy: 0.7436\n",
      "Epoch 321/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7196 - accuracy: 0.7133 - val_loss: 0.7221 - val_accuracy: 0.7436\n",
      "Epoch 322/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7204 - accuracy: 0.7061 - val_loss: 0.7214 - val_accuracy: 0.7436\n",
      "Epoch 323/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7305 - accuracy: 0.6738 - val_loss: 0.7208 - val_accuracy: 0.7436\n",
      "Epoch 324/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7241 - accuracy: 0.6774 - val_loss: 0.7203 - val_accuracy: 0.7436\n",
      "Epoch 325/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7177 - accuracy: 0.6810 - val_loss: 0.7202 - val_accuracy: 0.7436\n",
      "Epoch 326/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7254 - accuracy: 0.6667 - val_loss: 0.7200 - val_accuracy: 0.7436\n",
      "Epoch 327/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7210 - accuracy: 0.6918 - val_loss: 0.7198 - val_accuracy: 0.7436\n",
      "Epoch 328/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7114 - accuracy: 0.7061 - val_loss: 0.7189 - val_accuracy: 0.7436\n",
      "Epoch 329/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7145 - accuracy: 0.6738 - val_loss: 0.7186 - val_accuracy: 0.7436\n",
      "Epoch 330/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7146 - accuracy: 0.7061 - val_loss: 0.7182 - val_accuracy: 0.7436\n",
      "Epoch 331/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7102 - accuracy: 0.6989 - val_loss: 0.7180 - val_accuracy: 0.7436\n",
      "Epoch 332/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7267 - accuracy: 0.6774 - val_loss: 0.7174 - val_accuracy: 0.7436\n",
      "Epoch 333/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7246 - accuracy: 0.6882 - val_loss: 0.7164 - val_accuracy: 0.7436\n",
      "Epoch 334/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7118 - accuracy: 0.6882 - val_loss: 0.7146 - val_accuracy: 0.7436\n",
      "Epoch 335/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7243 - accuracy: 0.6846 - val_loss: 0.7132 - val_accuracy: 0.7436\n",
      "Epoch 336/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7181 - accuracy: 0.6882 - val_loss: 0.7124 - val_accuracy: 0.7436\n",
      "Epoch 337/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7191 - accuracy: 0.6918 - val_loss: 0.7113 - val_accuracy: 0.7436\n",
      "Epoch 338/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7136 - accuracy: 0.6953 - val_loss: 0.7103 - val_accuracy: 0.7436\n",
      "Epoch 339/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7192 - accuracy: 0.6953 - val_loss: 0.7092 - val_accuracy: 0.7436\n",
      "Epoch 340/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7153 - accuracy: 0.6846 - val_loss: 0.7084 - val_accuracy: 0.7436\n",
      "Epoch 341/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7072 - accuracy: 0.7133 - val_loss: 0.7078 - val_accuracy: 0.7436\n",
      "Epoch 342/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7154 - accuracy: 0.7025 - val_loss: 0.7080 - val_accuracy: 0.7436\n",
      "Epoch 343/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7172 - accuracy: 0.6810 - val_loss: 0.7079 - val_accuracy: 0.7436\n",
      "Epoch 344/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7173 - accuracy: 0.6918 - val_loss: 0.7076 - val_accuracy: 0.7436\n",
      "Epoch 345/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7093 - accuracy: 0.6953 - val_loss: 0.7077 - val_accuracy: 0.7436\n",
      "Epoch 346/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7066 - accuracy: 0.7025 - val_loss: 0.7068 - val_accuracy: 0.7436\n",
      "Epoch 347/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7084 - accuracy: 0.6918 - val_loss: 0.7065 - val_accuracy: 0.7436\n",
      "Epoch 348/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7050 - accuracy: 0.7061 - val_loss: 0.7064 - val_accuracy: 0.7436\n",
      "Epoch 349/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7087 - accuracy: 0.6953 - val_loss: 0.7058 - val_accuracy: 0.7436\n",
      "Epoch 350/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7081 - accuracy: 0.7061 - val_loss: 0.7056 - val_accuracy: 0.7436\n",
      "Epoch 351/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7121 - accuracy: 0.6918 - val_loss: 0.7053 - val_accuracy: 0.7436\n",
      "Epoch 352/750\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.7066 - accuracy: 0.6953 - val_loss: 0.7047 - val_accuracy: 0.7436\n",
      "Epoch 353/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7056 - accuracy: 0.7025 - val_loss: 0.7044 - val_accuracy: 0.7436\n",
      "Epoch 354/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7007 - accuracy: 0.6953 - val_loss: 0.7039 - val_accuracy: 0.7436\n",
      "Epoch 355/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7051 - accuracy: 0.6738 - val_loss: 0.7040 - val_accuracy: 0.7436\n",
      "Epoch 356/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7074 - accuracy: 0.6953 - val_loss: 0.7034 - val_accuracy: 0.7436\n",
      "Epoch 357/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7047 - accuracy: 0.6918 - val_loss: 0.7027 - val_accuracy: 0.7436\n",
      "Epoch 358/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7106 - accuracy: 0.6953 - val_loss: 0.7023 - val_accuracy: 0.7436\n",
      "Epoch 359/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7084 - accuracy: 0.6953 - val_loss: 0.7017 - val_accuracy: 0.7436\n",
      "Epoch 360/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7015 - accuracy: 0.7133 - val_loss: 0.7010 - val_accuracy: 0.7436\n",
      "Epoch 361/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6969 - accuracy: 0.6953 - val_loss: 0.7000 - val_accuracy: 0.7436\n",
      "Epoch 362/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7061 - accuracy: 0.6918 - val_loss: 0.6991 - val_accuracy: 0.7436\n",
      "Epoch 363/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6970 - accuracy: 0.6989 - val_loss: 0.6984 - val_accuracy: 0.7692\n",
      "Epoch 364/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7158 - accuracy: 0.6846 - val_loss: 0.6986 - val_accuracy: 0.7692\n",
      "Epoch 365/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7045 - accuracy: 0.6846 - val_loss: 0.6988 - val_accuracy: 0.7436\n",
      "Epoch 366/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7055 - accuracy: 0.7061 - val_loss: 0.6989 - val_accuracy: 0.7436\n",
      "Epoch 367/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6978 - accuracy: 0.6953 - val_loss: 0.6989 - val_accuracy: 0.7436\n",
      "Epoch 368/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6994 - accuracy: 0.6989 - val_loss: 0.6984 - val_accuracy: 0.7436\n",
      "Epoch 369/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7029 - accuracy: 0.6882 - val_loss: 0.6979 - val_accuracy: 0.7436\n",
      "Epoch 370/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6991 - accuracy: 0.6989 - val_loss: 0.6978 - val_accuracy: 0.7436\n",
      "Epoch 371/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6997 - accuracy: 0.6953 - val_loss: 0.6975 - val_accuracy: 0.7436\n",
      "Epoch 372/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6904 - accuracy: 0.6918 - val_loss: 0.6970 - val_accuracy: 0.7436\n",
      "Epoch 373/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6950 - accuracy: 0.6882 - val_loss: 0.6966 - val_accuracy: 0.7436\n",
      "Epoch 374/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7025 - accuracy: 0.6882 - val_loss: 0.6968 - val_accuracy: 0.7436\n",
      "Epoch 375/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6939 - accuracy: 0.6882 - val_loss: 0.6957 - val_accuracy: 0.7436\n",
      "Epoch 376/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6965 - accuracy: 0.7025 - val_loss: 0.6949 - val_accuracy: 0.7436\n",
      "Epoch 377/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6937 - accuracy: 0.7097 - val_loss: 0.6948 - val_accuracy: 0.7436\n",
      "Epoch 378/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6955 - accuracy: 0.6810 - val_loss: 0.6944 - val_accuracy: 0.7436\n",
      "Epoch 379/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6961 - accuracy: 0.6918 - val_loss: 0.6937 - val_accuracy: 0.7436\n",
      "Epoch 380/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6949 - accuracy: 0.6953 - val_loss: 0.6929 - val_accuracy: 0.7436\n",
      "Epoch 381/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6965 - accuracy: 0.6989 - val_loss: 0.6916 - val_accuracy: 0.7436\n",
      "Epoch 382/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6956 - accuracy: 0.6918 - val_loss: 0.6902 - val_accuracy: 0.7436\n",
      "Epoch 383/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6923 - accuracy: 0.7025 - val_loss: 0.6887 - val_accuracy: 0.7436\n",
      "Epoch 384/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6916 - accuracy: 0.7025 - val_loss: 0.6875 - val_accuracy: 0.7436\n",
      "Epoch 385/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6866 - accuracy: 0.6953 - val_loss: 0.6868 - val_accuracy: 0.7436\n",
      "Epoch 386/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6957 - accuracy: 0.7025 - val_loss: 0.6860 - val_accuracy: 0.7692\n",
      "Epoch 387/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6944 - accuracy: 0.6846 - val_loss: 0.6854 - val_accuracy: 0.7692\n",
      "Epoch 388/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6942 - accuracy: 0.6953 - val_loss: 0.6848 - val_accuracy: 0.7692\n",
      "Epoch 389/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6876 - accuracy: 0.7097 - val_loss: 0.6853 - val_accuracy: 0.7692\n",
      "Epoch 390/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6824 - accuracy: 0.7061 - val_loss: 0.6852 - val_accuracy: 0.7436\n",
      "Epoch 391/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6830 - accuracy: 0.6989 - val_loss: 0.6848 - val_accuracy: 0.7436\n",
      "Epoch 392/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6947 - accuracy: 0.7097 - val_loss: 0.6845 - val_accuracy: 0.7436\n",
      "Epoch 393/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6862 - accuracy: 0.6953 - val_loss: 0.6839 - val_accuracy: 0.7436\n",
      "Epoch 394/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6852 - accuracy: 0.7133 - val_loss: 0.6835 - val_accuracy: 0.7436\n",
      "Epoch 395/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6966 - accuracy: 0.7061 - val_loss: 0.6828 - val_accuracy: 0.7436\n",
      "Epoch 396/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6835 - accuracy: 0.6953 - val_loss: 0.6815 - val_accuracy: 0.7436\n",
      "Epoch 397/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6815 - accuracy: 0.6953 - val_loss: 0.6807 - val_accuracy: 0.7436\n",
      "Epoch 398/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6867 - accuracy: 0.7061 - val_loss: 0.6803 - val_accuracy: 0.7436\n",
      "Epoch 399/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6797 - accuracy: 0.7168 - val_loss: 0.6802 - val_accuracy: 0.7436\n",
      "Epoch 400/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6841 - accuracy: 0.6989 - val_loss: 0.6804 - val_accuracy: 0.7436\n",
      "Epoch 401/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6869 - accuracy: 0.6882 - val_loss: 0.6800 - val_accuracy: 0.7436\n",
      "Epoch 402/750\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.6805 - accuracy: 0.7097 - val_loss: 0.6794 - val_accuracy: 0.7436\n",
      "Epoch 403/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6868 - accuracy: 0.6989 - val_loss: 0.6789 - val_accuracy: 0.7436\n",
      "Epoch 404/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6860 - accuracy: 0.7097 - val_loss: 0.6781 - val_accuracy: 0.7436\n",
      "Epoch 405/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6945 - accuracy: 0.6918 - val_loss: 0.6774 - val_accuracy: 0.7436\n",
      "Epoch 406/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6808 - accuracy: 0.7204 - val_loss: 0.6768 - val_accuracy: 0.7436\n",
      "Epoch 407/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6851 - accuracy: 0.7025 - val_loss: 0.6759 - val_accuracy: 0.7692\n",
      "Epoch 408/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6857 - accuracy: 0.6989 - val_loss: 0.6753 - val_accuracy: 0.7692\n",
      "Epoch 409/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6831 - accuracy: 0.7097 - val_loss: 0.6746 - val_accuracy: 0.7692\n",
      "Epoch 410/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6835 - accuracy: 0.6810 - val_loss: 0.6741 - val_accuracy: 0.7692\n",
      "Epoch 411/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6764 - accuracy: 0.7168 - val_loss: 0.6739 - val_accuracy: 0.7692\n",
      "Epoch 412/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6856 - accuracy: 0.7025 - val_loss: 0.6739 - val_accuracy: 0.7436\n",
      "Epoch 413/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6888 - accuracy: 0.6918 - val_loss: 0.6743 - val_accuracy: 0.7436\n",
      "Epoch 414/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6856 - accuracy: 0.7061 - val_loss: 0.6737 - val_accuracy: 0.7436\n",
      "Epoch 415/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6761 - accuracy: 0.7025 - val_loss: 0.6735 - val_accuracy: 0.7436\n",
      "Epoch 416/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6888 - accuracy: 0.6953 - val_loss: 0.6725 - val_accuracy: 0.7692\n",
      "Epoch 417/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6830 - accuracy: 0.6989 - val_loss: 0.6718 - val_accuracy: 0.7692\n",
      "Epoch 418/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6820 - accuracy: 0.7061 - val_loss: 0.6711 - val_accuracy: 0.7692\n",
      "Epoch 419/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6840 - accuracy: 0.6953 - val_loss: 0.6704 - val_accuracy: 0.7692\n",
      "Epoch 420/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6746 - accuracy: 0.7061 - val_loss: 0.6697 - val_accuracy: 0.7692\n",
      "Epoch 421/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6688 - accuracy: 0.7133 - val_loss: 0.6689 - val_accuracy: 0.7692\n",
      "Epoch 422/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6791 - accuracy: 0.7061 - val_loss: 0.6685 - val_accuracy: 0.7692\n",
      "Epoch 423/750\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.6854 - accuracy: 0.6953 - val_loss: 0.6680 - val_accuracy: 0.7692\n",
      "Epoch 424/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6846 - accuracy: 0.6918 - val_loss: 0.6677 - val_accuracy: 0.7692\n",
      "Epoch 425/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6769 - accuracy: 0.7133 - val_loss: 0.6670 - val_accuracy: 0.7692\n",
      "Epoch 426/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6724 - accuracy: 0.7061 - val_loss: 0.6663 - val_accuracy: 0.7692\n",
      "Epoch 427/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6789 - accuracy: 0.7097 - val_loss: 0.6660 - val_accuracy: 0.7692\n",
      "Epoch 428/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6707 - accuracy: 0.7133 - val_loss: 0.6661 - val_accuracy: 0.7692\n",
      "Epoch 429/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6828 - accuracy: 0.7097 - val_loss: 0.6657 - val_accuracy: 0.7692\n",
      "Epoch 430/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6668 - accuracy: 0.7097 - val_loss: 0.6652 - val_accuracy: 0.7692\n",
      "Epoch 431/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6776 - accuracy: 0.6953 - val_loss: 0.6642 - val_accuracy: 0.7692\n",
      "Epoch 432/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6717 - accuracy: 0.6953 - val_loss: 0.6634 - val_accuracy: 0.7692\n",
      "Epoch 433/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6759 - accuracy: 0.7061 - val_loss: 0.6634 - val_accuracy: 0.7692\n",
      "Epoch 434/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6695 - accuracy: 0.7133 - val_loss: 0.6634 - val_accuracy: 0.7692\n",
      "Epoch 435/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6755 - accuracy: 0.7240 - val_loss: 0.6637 - val_accuracy: 0.7692\n",
      "Epoch 436/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6876 - accuracy: 0.7025 - val_loss: 0.6636 - val_accuracy: 0.7692\n",
      "Epoch 437/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6715 - accuracy: 0.7133 - val_loss: 0.6634 - val_accuracy: 0.7692\n",
      "Epoch 438/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6700 - accuracy: 0.7133 - val_loss: 0.6633 - val_accuracy: 0.7692\n",
      "Epoch 439/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6746 - accuracy: 0.7097 - val_loss: 0.6635 - val_accuracy: 0.7692\n",
      "Epoch 440/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6640 - accuracy: 0.7061 - val_loss: 0.6630 - val_accuracy: 0.7692\n",
      "Epoch 441/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6757 - accuracy: 0.6882 - val_loss: 0.6626 - val_accuracy: 0.7692\n",
      "Epoch 442/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6710 - accuracy: 0.7097 - val_loss: 0.6620 - val_accuracy: 0.7692\n",
      "Epoch 443/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6803 - accuracy: 0.6846 - val_loss: 0.6616 - val_accuracy: 0.7692\n",
      "Epoch 444/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6724 - accuracy: 0.7168 - val_loss: 0.6608 - val_accuracy: 0.7692\n",
      "Epoch 445/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6613 - accuracy: 0.7097 - val_loss: 0.6594 - val_accuracy: 0.7692\n",
      "Epoch 446/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6676 - accuracy: 0.7025 - val_loss: 0.6586 - val_accuracy: 0.7692\n",
      "Epoch 447/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6660 - accuracy: 0.7061 - val_loss: 0.6573 - val_accuracy: 0.7692\n",
      "Epoch 448/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6646 - accuracy: 0.7097 - val_loss: 0.6567 - val_accuracy: 0.7692\n",
      "Epoch 449/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6658 - accuracy: 0.7025 - val_loss: 0.6562 - val_accuracy: 0.7692\n",
      "Epoch 450/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6612 - accuracy: 0.7025 - val_loss: 0.6563 - val_accuracy: 0.7692\n",
      "Epoch 451/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6691 - accuracy: 0.6989 - val_loss: 0.6560 - val_accuracy: 0.7692\n",
      "Epoch 452/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6645 - accuracy: 0.7061 - val_loss: 0.6557 - val_accuracy: 0.7692\n",
      "Epoch 453/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6635 - accuracy: 0.7025 - val_loss: 0.6555 - val_accuracy: 0.7692\n",
      "Epoch 454/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6619 - accuracy: 0.7097 - val_loss: 0.6559 - val_accuracy: 0.7692\n",
      "Epoch 455/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6689 - accuracy: 0.6918 - val_loss: 0.6559 - val_accuracy: 0.7692\n",
      "Epoch 456/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6638 - accuracy: 0.7133 - val_loss: 0.6555 - val_accuracy: 0.7692\n",
      "Epoch 457/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6632 - accuracy: 0.7240 - val_loss: 0.6548 - val_accuracy: 0.7692\n",
      "Epoch 458/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6604 - accuracy: 0.7133 - val_loss: 0.6540 - val_accuracy: 0.7692\n",
      "Epoch 459/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6757 - accuracy: 0.6882 - val_loss: 0.6527 - val_accuracy: 0.7692\n",
      "Epoch 460/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6628 - accuracy: 0.7025 - val_loss: 0.6522 - val_accuracy: 0.7692\n",
      "Epoch 461/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6571 - accuracy: 0.7276 - val_loss: 0.6513 - val_accuracy: 0.7692\n",
      "Epoch 462/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6643 - accuracy: 0.7133 - val_loss: 0.6511 - val_accuracy: 0.7692\n",
      "Epoch 463/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6654 - accuracy: 0.7061 - val_loss: 0.6504 - val_accuracy: 0.7692\n",
      "Epoch 464/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6784 - accuracy: 0.6918 - val_loss: 0.6492 - val_accuracy: 0.7692\n",
      "Epoch 465/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6706 - accuracy: 0.7133 - val_loss: 0.6487 - val_accuracy: 0.7692\n",
      "Epoch 466/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6629 - accuracy: 0.6953 - val_loss: 0.6484 - val_accuracy: 0.7692\n",
      "Epoch 467/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6698 - accuracy: 0.6953 - val_loss: 0.6478 - val_accuracy: 0.7692\n",
      "Epoch 468/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6611 - accuracy: 0.7097 - val_loss: 0.6476 - val_accuracy: 0.7692\n",
      "Epoch 469/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6621 - accuracy: 0.6989 - val_loss: 0.6472 - val_accuracy: 0.7692\n",
      "Epoch 470/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6769 - accuracy: 0.6846 - val_loss: 0.6477 - val_accuracy: 0.7692\n",
      "Epoch 471/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6539 - accuracy: 0.7061 - val_loss: 0.6472 - val_accuracy: 0.7692\n",
      "Epoch 472/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6637 - accuracy: 0.7204 - val_loss: 0.6470 - val_accuracy: 0.7692\n",
      "Epoch 473/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6678 - accuracy: 0.7204 - val_loss: 0.6467 - val_accuracy: 0.7692\n",
      "Epoch 474/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6629 - accuracy: 0.7133 - val_loss: 0.6460 - val_accuracy: 0.7692\n",
      "Epoch 475/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6645 - accuracy: 0.6846 - val_loss: 0.6453 - val_accuracy: 0.7692\n",
      "Epoch 476/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6664 - accuracy: 0.7097 - val_loss: 0.6458 - val_accuracy: 0.7692\n",
      "Epoch 477/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6705 - accuracy: 0.7133 - val_loss: 0.6459 - val_accuracy: 0.7692\n",
      "Epoch 478/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6604 - accuracy: 0.7097 - val_loss: 0.6454 - val_accuracy: 0.7692\n",
      "Epoch 479/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6625 - accuracy: 0.6989 - val_loss: 0.6452 - val_accuracy: 0.7692\n",
      "Epoch 480/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6709 - accuracy: 0.6953 - val_loss: 0.6448 - val_accuracy: 0.7692\n",
      "Epoch 481/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6555 - accuracy: 0.6989 - val_loss: 0.6446 - val_accuracy: 0.7692\n",
      "Epoch 482/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6681 - accuracy: 0.6989 - val_loss: 0.6445 - val_accuracy: 0.7692\n",
      "Epoch 483/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6607 - accuracy: 0.7025 - val_loss: 0.6442 - val_accuracy: 0.7692\n",
      "Epoch 484/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6545 - accuracy: 0.7240 - val_loss: 0.6435 - val_accuracy: 0.7692\n",
      "Epoch 485/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6507 - accuracy: 0.7061 - val_loss: 0.6432 - val_accuracy: 0.7692\n",
      "Epoch 486/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6593 - accuracy: 0.7204 - val_loss: 0.6434 - val_accuracy: 0.7692\n",
      "Epoch 487/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6549 - accuracy: 0.6953 - val_loss: 0.6436 - val_accuracy: 0.7692\n",
      "Epoch 488/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6515 - accuracy: 0.7276 - val_loss: 0.6434 - val_accuracy: 0.7692\n",
      "Epoch 489/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6548 - accuracy: 0.7168 - val_loss: 0.6432 - val_accuracy: 0.7692\n",
      "Epoch 490/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6493 - accuracy: 0.7204 - val_loss: 0.6433 - val_accuracy: 0.7692\n",
      "Epoch 491/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6632 - accuracy: 0.7133 - val_loss: 0.6434 - val_accuracy: 0.7692\n",
      "Epoch 492/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6619 - accuracy: 0.7276 - val_loss: 0.6436 - val_accuracy: 0.7436\n",
      "Epoch 493/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6577 - accuracy: 0.7097 - val_loss: 0.6428 - val_accuracy: 0.7436\n",
      "Epoch 494/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6527 - accuracy: 0.7097 - val_loss: 0.6424 - val_accuracy: 0.7436\n",
      "Epoch 495/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6491 - accuracy: 0.7204 - val_loss: 0.6423 - val_accuracy: 0.7436\n",
      "Epoch 496/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6546 - accuracy: 0.7204 - val_loss: 0.6420 - val_accuracy: 0.7436\n",
      "Epoch 497/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6502 - accuracy: 0.7204 - val_loss: 0.6413 - val_accuracy: 0.7436\n",
      "Epoch 498/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6599 - accuracy: 0.7276 - val_loss: 0.6406 - val_accuracy: 0.7692\n",
      "Epoch 499/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6466 - accuracy: 0.7240 - val_loss: 0.6405 - val_accuracy: 0.7692\n",
      "Epoch 500/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6430 - accuracy: 0.7133 - val_loss: 0.6403 - val_accuracy: 0.7692\n",
      "Epoch 501/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6617 - accuracy: 0.7204 - val_loss: 0.6398 - val_accuracy: 0.7692\n",
      "Epoch 502/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6512 - accuracy: 0.7348 - val_loss: 0.6389 - val_accuracy: 0.7692\n",
      "Epoch 503/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6486 - accuracy: 0.7276 - val_loss: 0.6383 - val_accuracy: 0.7692\n",
      "Epoch 504/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6627 - accuracy: 0.7168 - val_loss: 0.6383 - val_accuracy: 0.7692\n",
      "Epoch 505/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6579 - accuracy: 0.7168 - val_loss: 0.6384 - val_accuracy: 0.7692\n",
      "Epoch 506/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6554 - accuracy: 0.7133 - val_loss: 0.6380 - val_accuracy: 0.7692\n",
      "Epoch 507/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6614 - accuracy: 0.6989 - val_loss: 0.6381 - val_accuracy: 0.7692\n",
      "Epoch 508/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6507 - accuracy: 0.7312 - val_loss: 0.6382 - val_accuracy: 0.7692\n",
      "Epoch 509/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6478 - accuracy: 0.7133 - val_loss: 0.6386 - val_accuracy: 0.7692\n",
      "Epoch 510/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6465 - accuracy: 0.7276 - val_loss: 0.6389 - val_accuracy: 0.7692\n",
      "Epoch 511/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6519 - accuracy: 0.7204 - val_loss: 0.6392 - val_accuracy: 0.7692\n",
      "Epoch 512/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6613 - accuracy: 0.7168 - val_loss: 0.6385 - val_accuracy: 0.7692\n",
      "Epoch 513/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6547 - accuracy: 0.7097 - val_loss: 0.6380 - val_accuracy: 0.7692\n",
      "Epoch 514/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6515 - accuracy: 0.6953 - val_loss: 0.6373 - val_accuracy: 0.7692\n",
      "Epoch 515/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6464 - accuracy: 0.7133 - val_loss: 0.6366 - val_accuracy: 0.7692\n",
      "Epoch 516/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6501 - accuracy: 0.7168 - val_loss: 0.6362 - val_accuracy: 0.7692\n",
      "Epoch 517/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6500 - accuracy: 0.7097 - val_loss: 0.6362 - val_accuracy: 0.7692\n",
      "Epoch 518/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6510 - accuracy: 0.7168 - val_loss: 0.6359 - val_accuracy: 0.7692\n",
      "Epoch 519/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6466 - accuracy: 0.7204 - val_loss: 0.6353 - val_accuracy: 0.7692\n",
      "Epoch 520/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6563 - accuracy: 0.7204 - val_loss: 0.6353 - val_accuracy: 0.7692\n",
      "Epoch 521/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6481 - accuracy: 0.7168 - val_loss: 0.6349 - val_accuracy: 0.7692\n",
      "Epoch 522/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6717 - accuracy: 0.6953 - val_loss: 0.6342 - val_accuracy: 0.7692\n",
      "Epoch 523/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6469 - accuracy: 0.6989 - val_loss: 0.6336 - val_accuracy: 0.7692\n",
      "Epoch 524/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6583 - accuracy: 0.7204 - val_loss: 0.6334 - val_accuracy: 0.7692\n",
      "Epoch 525/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6525 - accuracy: 0.7097 - val_loss: 0.6330 - val_accuracy: 0.7692\n",
      "Epoch 526/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6491 - accuracy: 0.7097 - val_loss: 0.6333 - val_accuracy: 0.7692\n",
      "Epoch 527/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6424 - accuracy: 0.7061 - val_loss: 0.6337 - val_accuracy: 0.7692\n",
      "Epoch 528/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6552 - accuracy: 0.7061 - val_loss: 0.6336 - val_accuracy: 0.7692\n",
      "Epoch 529/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6419 - accuracy: 0.7348 - val_loss: 0.6337 - val_accuracy: 0.7692\n",
      "Epoch 530/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6513 - accuracy: 0.7276 - val_loss: 0.6332 - val_accuracy: 0.7692\n",
      "Epoch 531/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6465 - accuracy: 0.7204 - val_loss: 0.6336 - val_accuracy: 0.7692\n",
      "Epoch 532/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6460 - accuracy: 0.7204 - val_loss: 0.6333 - val_accuracy: 0.7692\n",
      "Epoch 533/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6504 - accuracy: 0.7133 - val_loss: 0.6329 - val_accuracy: 0.7692\n",
      "Epoch 534/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6497 - accuracy: 0.7240 - val_loss: 0.6324 - val_accuracy: 0.7692\n",
      "Epoch 535/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6435 - accuracy: 0.7133 - val_loss: 0.6325 - val_accuracy: 0.7692\n",
      "Epoch 536/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6490 - accuracy: 0.7133 - val_loss: 0.6326 - val_accuracy: 0.7692\n",
      "Epoch 537/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6429 - accuracy: 0.7204 - val_loss: 0.6325 - val_accuracy: 0.7436\n",
      "Epoch 538/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6472 - accuracy: 0.7097 - val_loss: 0.6326 - val_accuracy: 0.7436\n",
      "Epoch 539/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6468 - accuracy: 0.7097 - val_loss: 0.6329 - val_accuracy: 0.7436\n",
      "Epoch 540/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6565 - accuracy: 0.6953 - val_loss: 0.6330 - val_accuracy: 0.7436\n",
      "Epoch 541/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6517 - accuracy: 0.7061 - val_loss: 0.6330 - val_accuracy: 0.7436\n",
      "Epoch 542/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6503 - accuracy: 0.7061 - val_loss: 0.6326 - val_accuracy: 0.7436\n",
      "Epoch 543/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6465 - accuracy: 0.7168 - val_loss: 0.6318 - val_accuracy: 0.7436\n",
      "Epoch 544/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6377 - accuracy: 0.7133 - val_loss: 0.6317 - val_accuracy: 0.7436\n",
      "Epoch 545/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6338 - accuracy: 0.7240 - val_loss: 0.6322 - val_accuracy: 0.7436\n",
      "Epoch 546/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6399 - accuracy: 0.7276 - val_loss: 0.6324 - val_accuracy: 0.7436\n",
      "Epoch 547/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6374 - accuracy: 0.7168 - val_loss: 0.6323 - val_accuracy: 0.7436\n",
      "Epoch 548/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6379 - accuracy: 0.7133 - val_loss: 0.6320 - val_accuracy: 0.7436\n",
      "Epoch 549/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6475 - accuracy: 0.7240 - val_loss: 0.6321 - val_accuracy: 0.7436\n",
      "Epoch 550/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6334 - accuracy: 0.7204 - val_loss: 0.6321 - val_accuracy: 0.7436\n",
      "Epoch 551/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6478 - accuracy: 0.7276 - val_loss: 0.6312 - val_accuracy: 0.7436\n",
      "Epoch 552/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6440 - accuracy: 0.7097 - val_loss: 0.6314 - val_accuracy: 0.7436\n",
      "Epoch 553/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6362 - accuracy: 0.7204 - val_loss: 0.6309 - val_accuracy: 0.7436\n",
      "Epoch 554/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6354 - accuracy: 0.7061 - val_loss: 0.6301 - val_accuracy: 0.7436\n",
      "Epoch 555/750\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6470 - accuracy: 0.7168 - val_loss: 0.6290 - val_accuracy: 0.7692\n",
      "Epoch 556/750\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.6474 - accuracy: 0.7061 - val_loss: 0.6289 - val_accuracy: 0.7692\n",
      "Epoch 557/750\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.6314 - accuracy: 0.7276 - val_loss: 0.6284 - val_accuracy: 0.7692\n",
      "Epoch 558/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6335 - accuracy: 0.7168 - val_loss: 0.6277 - val_accuracy: 0.7692\n",
      "Epoch 559/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6536 - accuracy: 0.7133 - val_loss: 0.6269 - val_accuracy: 0.7692\n",
      "Epoch 560/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6386 - accuracy: 0.7168 - val_loss: 0.6268 - val_accuracy: 0.7692\n",
      "Epoch 561/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6416 - accuracy: 0.7168 - val_loss: 0.6263 - val_accuracy: 0.7692\n",
      "Epoch 562/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6436 - accuracy: 0.7168 - val_loss: 0.6261 - val_accuracy: 0.7692\n",
      "Epoch 563/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6459 - accuracy: 0.7097 - val_loss: 0.6258 - val_accuracy: 0.7692\n",
      "Epoch 564/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6464 - accuracy: 0.7133 - val_loss: 0.6248 - val_accuracy: 0.7692\n",
      "Epoch 565/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6423 - accuracy: 0.7348 - val_loss: 0.6241 - val_accuracy: 0.7692\n",
      "Epoch 566/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6338 - accuracy: 0.7240 - val_loss: 0.6243 - val_accuracy: 0.7692\n",
      "Epoch 567/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6399 - accuracy: 0.7204 - val_loss: 0.6240 - val_accuracy: 0.7692\n",
      "Epoch 568/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6378 - accuracy: 0.7204 - val_loss: 0.6242 - val_accuracy: 0.7692\n",
      "Epoch 569/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6471 - accuracy: 0.7312 - val_loss: 0.6235 - val_accuracy: 0.7692\n",
      "Epoch 570/750\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.6332 - accuracy: 0.7061 - val_loss: 0.6233 - val_accuracy: 0.7692\n",
      "Epoch 571/750\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.6382 - accuracy: 0.7276 - val_loss: 0.6233 - val_accuracy: 0.7692\n",
      "Epoch 572/750\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6426 - accuracy: 0.7133 - val_loss: 0.6227 - val_accuracy: 0.7692\n",
      "Epoch 573/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6512 - accuracy: 0.6989 - val_loss: 0.6228 - val_accuracy: 0.7692\n",
      "Epoch 574/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6498 - accuracy: 0.7204 - val_loss: 0.6230 - val_accuracy: 0.7692\n",
      "Epoch 575/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6345 - accuracy: 0.7276 - val_loss: 0.6224 - val_accuracy: 0.7692\n",
      "Epoch 576/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6468 - accuracy: 0.7240 - val_loss: 0.6217 - val_accuracy: 0.7692\n",
      "Epoch 577/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6335 - accuracy: 0.7240 - val_loss: 0.6213 - val_accuracy: 0.7692\n",
      "Epoch 578/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6333 - accuracy: 0.7061 - val_loss: 0.6210 - val_accuracy: 0.7692\n",
      "Epoch 579/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6428 - accuracy: 0.7133 - val_loss: 0.6204 - val_accuracy: 0.7692\n",
      "Epoch 580/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6312 - accuracy: 0.7240 - val_loss: 0.6205 - val_accuracy: 0.7692\n",
      "Epoch 581/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6568 - accuracy: 0.6918 - val_loss: 0.6196 - val_accuracy: 0.7692\n",
      "Epoch 582/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6338 - accuracy: 0.7276 - val_loss: 0.6193 - val_accuracy: 0.7692\n",
      "Epoch 583/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6362 - accuracy: 0.7312 - val_loss: 0.6186 - val_accuracy: 0.7692\n",
      "Epoch 584/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6380 - accuracy: 0.7312 - val_loss: 0.6181 - val_accuracy: 0.7692\n",
      "Epoch 585/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6413 - accuracy: 0.7204 - val_loss: 0.6178 - val_accuracy: 0.7692\n",
      "Epoch 586/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6341 - accuracy: 0.7097 - val_loss: 0.6178 - val_accuracy: 0.7692\n",
      "Epoch 587/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6351 - accuracy: 0.7312 - val_loss: 0.6178 - val_accuracy: 0.7692\n",
      "Epoch 588/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6268 - accuracy: 0.7312 - val_loss: 0.6180 - val_accuracy: 0.7692\n",
      "Epoch 589/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6406 - accuracy: 0.7168 - val_loss: 0.6182 - val_accuracy: 0.7692\n",
      "Epoch 590/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6390 - accuracy: 0.7168 - val_loss: 0.6181 - val_accuracy: 0.7692\n",
      "Epoch 591/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6436 - accuracy: 0.7025 - val_loss: 0.6181 - val_accuracy: 0.7692\n",
      "Epoch 592/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6395 - accuracy: 0.6953 - val_loss: 0.6182 - val_accuracy: 0.7692\n",
      "Epoch 593/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6317 - accuracy: 0.7276 - val_loss: 0.6180 - val_accuracy: 0.7692\n",
      "Epoch 594/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6303 - accuracy: 0.7133 - val_loss: 0.6178 - val_accuracy: 0.7692\n",
      "Epoch 595/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6430 - accuracy: 0.6989 - val_loss: 0.6175 - val_accuracy: 0.7692\n",
      "Epoch 596/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6324 - accuracy: 0.7419 - val_loss: 0.6170 - val_accuracy: 0.7692\n",
      "Epoch 597/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6245 - accuracy: 0.7240 - val_loss: 0.6171 - val_accuracy: 0.7692\n",
      "Epoch 598/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6295 - accuracy: 0.7276 - val_loss: 0.6170 - val_accuracy: 0.7692\n",
      "Epoch 599/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6471 - accuracy: 0.7061 - val_loss: 0.6171 - val_accuracy: 0.7692\n",
      "Epoch 600/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6334 - accuracy: 0.7204 - val_loss: 0.6169 - val_accuracy: 0.7692\n",
      "Epoch 601/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6353 - accuracy: 0.7097 - val_loss: 0.6164 - val_accuracy: 0.7692\n",
      "Epoch 602/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6389 - accuracy: 0.7312 - val_loss: 0.6159 - val_accuracy: 0.7692\n",
      "Epoch 603/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6391 - accuracy: 0.7061 - val_loss: 0.6160 - val_accuracy: 0.7692\n",
      "Epoch 604/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6401 - accuracy: 0.7276 - val_loss: 0.6157 - val_accuracy: 0.7692\n",
      "Epoch 605/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6276 - accuracy: 0.7204 - val_loss: 0.6157 - val_accuracy: 0.7692\n",
      "Epoch 606/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6353 - accuracy: 0.7133 - val_loss: 0.6151 - val_accuracy: 0.7692\n",
      "Epoch 607/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6288 - accuracy: 0.7204 - val_loss: 0.6154 - val_accuracy: 0.7692\n",
      "Epoch 608/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6283 - accuracy: 0.7276 - val_loss: 0.6151 - val_accuracy: 0.7692\n",
      "Epoch 609/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6376 - accuracy: 0.7168 - val_loss: 0.6146 - val_accuracy: 0.7692\n",
      "Epoch 610/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6356 - accuracy: 0.7204 - val_loss: 0.6141 - val_accuracy: 0.7692\n",
      "Epoch 611/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6232 - accuracy: 0.7348 - val_loss: 0.6138 - val_accuracy: 0.7692\n",
      "Epoch 612/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6261 - accuracy: 0.7276 - val_loss: 0.6139 - val_accuracy: 0.7692\n",
      "Epoch 613/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6304 - accuracy: 0.7348 - val_loss: 0.6142 - val_accuracy: 0.7692\n",
      "Epoch 614/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6406 - accuracy: 0.7133 - val_loss: 0.6148 - val_accuracy: 0.7692\n",
      "Epoch 615/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6245 - accuracy: 0.7204 - val_loss: 0.6148 - val_accuracy: 0.7692\n",
      "Epoch 616/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6277 - accuracy: 0.7276 - val_loss: 0.6139 - val_accuracy: 0.7692\n",
      "Epoch 617/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6291 - accuracy: 0.7204 - val_loss: 0.6137 - val_accuracy: 0.7692\n",
      "Epoch 618/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6442 - accuracy: 0.7240 - val_loss: 0.6136 - val_accuracy: 0.7692\n",
      "Epoch 619/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6337 - accuracy: 0.7312 - val_loss: 0.6137 - val_accuracy: 0.7692\n",
      "Epoch 620/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6431 - accuracy: 0.6953 - val_loss: 0.6135 - val_accuracy: 0.7692\n",
      "Epoch 621/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6355 - accuracy: 0.7204 - val_loss: 0.6136 - val_accuracy: 0.7692\n",
      "Epoch 622/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6207 - accuracy: 0.7168 - val_loss: 0.6133 - val_accuracy: 0.7692\n",
      "Epoch 623/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6319 - accuracy: 0.7168 - val_loss: 0.6134 - val_accuracy: 0.7692\n",
      "Epoch 624/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6318 - accuracy: 0.7204 - val_loss: 0.6135 - val_accuracy: 0.7692\n",
      "Epoch 625/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6221 - accuracy: 0.7384 - val_loss: 0.6136 - val_accuracy: 0.7692\n",
      "Epoch 626/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6428 - accuracy: 0.7204 - val_loss: 0.6139 - val_accuracy: 0.7692\n",
      "Epoch 627/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6388 - accuracy: 0.7204 - val_loss: 0.6139 - val_accuracy: 0.7692\n",
      "Epoch 628/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6220 - accuracy: 0.7312 - val_loss: 0.6144 - val_accuracy: 0.7692\n",
      "Epoch 629/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6309 - accuracy: 0.7204 - val_loss: 0.6141 - val_accuracy: 0.7692\n",
      "Epoch 630/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6346 - accuracy: 0.7097 - val_loss: 0.6142 - val_accuracy: 0.7692\n",
      "Epoch 631/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6291 - accuracy: 0.7240 - val_loss: 0.6141 - val_accuracy: 0.7692\n",
      "Epoch 632/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6308 - accuracy: 0.7133 - val_loss: 0.6139 - val_accuracy: 0.7692\n",
      "Epoch 633/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6296 - accuracy: 0.7204 - val_loss: 0.6140 - val_accuracy: 0.7692\n",
      "Epoch 634/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6244 - accuracy: 0.7168 - val_loss: 0.6144 - val_accuracy: 0.7692\n",
      "Epoch 635/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6252 - accuracy: 0.7276 - val_loss: 0.6141 - val_accuracy: 0.7692\n",
      "Epoch 636/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6306 - accuracy: 0.7097 - val_loss: 0.6133 - val_accuracy: 0.7692\n",
      "Epoch 637/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6362 - accuracy: 0.7133 - val_loss: 0.6127 - val_accuracy: 0.7692\n",
      "Epoch 638/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6258 - accuracy: 0.7168 - val_loss: 0.6123 - val_accuracy: 0.7692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 639/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6292 - accuracy: 0.7276 - val_loss: 0.6125 - val_accuracy: 0.7692\n",
      "Epoch 640/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6371 - accuracy: 0.7240 - val_loss: 0.6130 - val_accuracy: 0.7692\n",
      "Epoch 641/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6280 - accuracy: 0.7276 - val_loss: 0.6127 - val_accuracy: 0.7692\n",
      "Epoch 642/750\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6214 - accuracy: 0.7276 - val_loss: 0.6127 - val_accuracy: 0.7692\n",
      "Epoch 643/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6242 - accuracy: 0.7348 - val_loss: 0.6124 - val_accuracy: 0.7692\n",
      "Epoch 644/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6212 - accuracy: 0.7204 - val_loss: 0.6125 - val_accuracy: 0.7692\n",
      "Epoch 645/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6352 - accuracy: 0.7133 - val_loss: 0.6122 - val_accuracy: 0.7692\n",
      "Epoch 646/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6211 - accuracy: 0.7384 - val_loss: 0.6125 - val_accuracy: 0.7436\n",
      "Epoch 647/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6267 - accuracy: 0.7276 - val_loss: 0.6122 - val_accuracy: 0.7436\n",
      "Epoch 648/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6186 - accuracy: 0.7276 - val_loss: 0.6124 - val_accuracy: 0.7436\n",
      "Epoch 649/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6260 - accuracy: 0.7168 - val_loss: 0.6116 - val_accuracy: 0.7436\n",
      "Epoch 650/750\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6296 - accuracy: 0.7312 - val_loss: 0.6107 - val_accuracy: 0.7436\n",
      "Epoch 651/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6522 - accuracy: 0.7061 - val_loss: 0.6104 - val_accuracy: 0.7436\n",
      "Epoch 652/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6306 - accuracy: 0.7133 - val_loss: 0.6096 - val_accuracy: 0.7436\n",
      "Epoch 653/750\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.6311 - accuracy: 0.7133 - val_loss: 0.6094 - val_accuracy: 0.7436\n",
      "Epoch 654/750\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.6085 - accuracy: 0.7348 - val_loss: 0.6091 - val_accuracy: 0.7436\n",
      "Epoch 655/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6280 - accuracy: 0.7312 - val_loss: 0.6087 - val_accuracy: 0.7436\n",
      "Epoch 656/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6308 - accuracy: 0.7240 - val_loss: 0.6079 - val_accuracy: 0.7692\n",
      "Epoch 657/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6281 - accuracy: 0.7240 - val_loss: 0.6079 - val_accuracy: 0.7692\n",
      "Epoch 658/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6422 - accuracy: 0.7133 - val_loss: 0.6084 - val_accuracy: 0.7436\n",
      "Epoch 659/750\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.6250 - accuracy: 0.7133 - val_loss: 0.6077 - val_accuracy: 0.7692\n",
      "Epoch 660/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6300 - accuracy: 0.7097 - val_loss: 0.6069 - val_accuracy: 0.7692\n",
      "Epoch 661/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6292 - accuracy: 0.7276 - val_loss: 0.6066 - val_accuracy: 0.7692\n",
      "Epoch 662/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6324 - accuracy: 0.7276 - val_loss: 0.6067 - val_accuracy: 0.7692\n",
      "Epoch 663/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6210 - accuracy: 0.7276 - val_loss: 0.6070 - val_accuracy: 0.7692\n",
      "Epoch 664/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6161 - accuracy: 0.7312 - val_loss: 0.6064 - val_accuracy: 0.7692\n",
      "Epoch 665/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6175 - accuracy: 0.7168 - val_loss: 0.6063 - val_accuracy: 0.7692\n",
      "Epoch 666/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6246 - accuracy: 0.7097 - val_loss: 0.6066 - val_accuracy: 0.7692\n",
      "Epoch 667/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6265 - accuracy: 0.7240 - val_loss: 0.6063 - val_accuracy: 0.7692\n",
      "Epoch 668/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6239 - accuracy: 0.7061 - val_loss: 0.6064 - val_accuracy: 0.7692\n",
      "Epoch 669/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6114 - accuracy: 0.7419 - val_loss: 0.6068 - val_accuracy: 0.7692\n",
      "Epoch 670/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6301 - accuracy: 0.7204 - val_loss: 0.6071 - val_accuracy: 0.7692\n",
      "Epoch 671/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6228 - accuracy: 0.7204 - val_loss: 0.6069 - val_accuracy: 0.7692\n",
      "Epoch 672/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6184 - accuracy: 0.7276 - val_loss: 0.6067 - val_accuracy: 0.7692\n",
      "Epoch 673/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6190 - accuracy: 0.7133 - val_loss: 0.6069 - val_accuracy: 0.7692\n",
      "Epoch 674/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6432 - accuracy: 0.7133 - val_loss: 0.6067 - val_accuracy: 0.7692\n",
      "Epoch 675/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6410 - accuracy: 0.7097 - val_loss: 0.6067 - val_accuracy: 0.7692\n",
      "Epoch 676/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6200 - accuracy: 0.7204 - val_loss: 0.6063 - val_accuracy: 0.7692\n",
      "Epoch 677/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6170 - accuracy: 0.7384 - val_loss: 0.6065 - val_accuracy: 0.7692\n",
      "Epoch 678/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6312 - accuracy: 0.7168 - val_loss: 0.6072 - val_accuracy: 0.7692\n",
      "Epoch 679/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6211 - accuracy: 0.7312 - val_loss: 0.6076 - val_accuracy: 0.7692\n",
      "Epoch 680/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6212 - accuracy: 0.7168 - val_loss: 0.6074 - val_accuracy: 0.7692\n",
      "Epoch 681/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6187 - accuracy: 0.7168 - val_loss: 0.6073 - val_accuracy: 0.7436\n",
      "Epoch 682/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6220 - accuracy: 0.7240 - val_loss: 0.6068 - val_accuracy: 0.7692\n",
      "Epoch 683/750\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.6180 - accuracy: 0.7276 - val_loss: 0.6069 - val_accuracy: 0.7692\n",
      "Epoch 684/750\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.6131 - accuracy: 0.7276 - val_loss: 0.6078 - val_accuracy: 0.7436\n",
      "Epoch 685/750\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6177 - accuracy: 0.7384 - val_loss: 0.6084 - val_accuracy: 0.7436\n",
      "Epoch 686/750\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.6160 - accuracy: 0.7455 - val_loss: 0.6085 - val_accuracy: 0.7436\n",
      "Epoch 687/750\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6290 - accuracy: 0.7204 - val_loss: 0.6086 - val_accuracy: 0.7436\n",
      "Epoch 688/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6193 - accuracy: 0.7168 - val_loss: 0.6087 - val_accuracy: 0.7436\n",
      "Epoch 689/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6168 - accuracy: 0.7348 - val_loss: 0.6088 - val_accuracy: 0.7436\n",
      "Epoch 690/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6275 - accuracy: 0.6989 - val_loss: 0.6084 - val_accuracy: 0.7436\n",
      "Epoch 691/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6321 - accuracy: 0.7133 - val_loss: 0.6077 - val_accuracy: 0.7436\n",
      "Epoch 692/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6428 - accuracy: 0.7097 - val_loss: 0.6074 - val_accuracy: 0.7436\n",
      "Epoch 693/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6189 - accuracy: 0.7204 - val_loss: 0.6071 - val_accuracy: 0.7692\n",
      "Epoch 694/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6157 - accuracy: 0.7061 - val_loss: 0.6070 - val_accuracy: 0.7692\n",
      "Epoch 695/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6151 - accuracy: 0.7312 - val_loss: 0.6067 - val_accuracy: 0.7692\n",
      "Epoch 696/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6084 - accuracy: 0.7384 - val_loss: 0.6067 - val_accuracy: 0.7692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 697/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6093 - accuracy: 0.7240 - val_loss: 0.6065 - val_accuracy: 0.7692\n",
      "Epoch 698/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6250 - accuracy: 0.7133 - val_loss: 0.6061 - val_accuracy: 0.7692\n",
      "Epoch 699/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6372 - accuracy: 0.6989 - val_loss: 0.6064 - val_accuracy: 0.7692\n",
      "Epoch 700/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6220 - accuracy: 0.6989 - val_loss: 0.6059 - val_accuracy: 0.7692\n",
      "Epoch 701/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6293 - accuracy: 0.7168 - val_loss: 0.6058 - val_accuracy: 0.7692\n",
      "Epoch 702/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6179 - accuracy: 0.7168 - val_loss: 0.6053 - val_accuracy: 0.7692\n",
      "Epoch 703/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6280 - accuracy: 0.7133 - val_loss: 0.6057 - val_accuracy: 0.7436\n",
      "Epoch 704/750\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.6227 - accuracy: 0.7168 - val_loss: 0.6054 - val_accuracy: 0.7692\n",
      "Epoch 705/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6188 - accuracy: 0.7312 - val_loss: 0.6049 - val_accuracy: 0.7692\n",
      "Epoch 706/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6273 - accuracy: 0.7061 - val_loss: 0.6047 - val_accuracy: 0.7692\n",
      "Epoch 707/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6279 - accuracy: 0.7133 - val_loss: 0.6043 - val_accuracy: 0.7692\n",
      "Epoch 708/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6168 - accuracy: 0.7240 - val_loss: 0.6046 - val_accuracy: 0.7436\n",
      "Epoch 709/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6188 - accuracy: 0.7025 - val_loss: 0.6052 - val_accuracy: 0.7436\n",
      "Epoch 710/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6224 - accuracy: 0.7133 - val_loss: 0.6060 - val_accuracy: 0.7436\n",
      "Epoch 711/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6127 - accuracy: 0.7312 - val_loss: 0.6062 - val_accuracy: 0.7436\n",
      "Epoch 712/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6172 - accuracy: 0.7168 - val_loss: 0.6062 - val_accuracy: 0.7436\n",
      "Epoch 713/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6067 - accuracy: 0.7133 - val_loss: 0.6069 - val_accuracy: 0.7436\n",
      "Epoch 714/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6155 - accuracy: 0.7168 - val_loss: 0.6074 - val_accuracy: 0.7436\n",
      "Epoch 715/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6164 - accuracy: 0.7204 - val_loss: 0.6071 - val_accuracy: 0.7436\n",
      "Epoch 716/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6116 - accuracy: 0.7204 - val_loss: 0.6074 - val_accuracy: 0.7436\n",
      "Epoch 717/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6253 - accuracy: 0.7168 - val_loss: 0.6076 - val_accuracy: 0.7436\n",
      "Epoch 718/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6409 - accuracy: 0.7061 - val_loss: 0.6073 - val_accuracy: 0.7436\n",
      "Epoch 719/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6239 - accuracy: 0.7168 - val_loss: 0.6067 - val_accuracy: 0.7436\n",
      "Epoch 720/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6276 - accuracy: 0.7025 - val_loss: 0.6063 - val_accuracy: 0.7436\n",
      "Epoch 721/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6070 - accuracy: 0.7312 - val_loss: 0.6062 - val_accuracy: 0.7436\n",
      "Epoch 722/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6089 - accuracy: 0.7491 - val_loss: 0.6057 - val_accuracy: 0.7436\n",
      "Epoch 723/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6075 - accuracy: 0.7312 - val_loss: 0.6050 - val_accuracy: 0.7436\n",
      "Epoch 724/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6095 - accuracy: 0.7276 - val_loss: 0.6044 - val_accuracy: 0.7436\n",
      "Epoch 725/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6212 - accuracy: 0.7312 - val_loss: 0.6045 - val_accuracy: 0.7436\n",
      "Epoch 726/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6183 - accuracy: 0.7204 - val_loss: 0.6049 - val_accuracy: 0.7436\n",
      "Epoch 727/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6211 - accuracy: 0.7312 - val_loss: 0.6044 - val_accuracy: 0.7436\n",
      "Epoch 728/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6159 - accuracy: 0.7097 - val_loss: 0.6038 - val_accuracy: 0.7436\n",
      "Epoch 729/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6353 - accuracy: 0.7168 - val_loss: 0.6038 - val_accuracy: 0.7436\n",
      "Epoch 730/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6313 - accuracy: 0.7168 - val_loss: 0.6037 - val_accuracy: 0.7436\n",
      "Epoch 731/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6218 - accuracy: 0.7204 - val_loss: 0.6034 - val_accuracy: 0.7436\n",
      "Epoch 732/750\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.6208 - accuracy: 0.7240 - val_loss: 0.6035 - val_accuracy: 0.7436\n",
      "Epoch 733/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6144 - accuracy: 0.7204 - val_loss: 0.6029 - val_accuracy: 0.7436\n",
      "Epoch 734/750\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6056 - accuracy: 0.7384 - val_loss: 0.6022 - val_accuracy: 0.7436\n",
      "Epoch 735/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6085 - accuracy: 0.7276 - val_loss: 0.6016 - val_accuracy: 0.7436\n",
      "Epoch 736/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6135 - accuracy: 0.7240 - val_loss: 0.6009 - val_accuracy: 0.7436\n",
      "Epoch 737/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6079 - accuracy: 0.7204 - val_loss: 0.6006 - val_accuracy: 0.7436\n",
      "Epoch 738/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6068 - accuracy: 0.7133 - val_loss: 0.6004 - val_accuracy: 0.7436\n",
      "Epoch 739/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6154 - accuracy: 0.7312 - val_loss: 0.6008 - val_accuracy: 0.7436\n",
      "Epoch 740/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6182 - accuracy: 0.7061 - val_loss: 0.6005 - val_accuracy: 0.7436\n",
      "Epoch 741/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6149 - accuracy: 0.7276 - val_loss: 0.5998 - val_accuracy: 0.7436\n",
      "Epoch 742/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6289 - accuracy: 0.7240 - val_loss: 0.5993 - val_accuracy: 0.7436\n",
      "Epoch 743/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6232 - accuracy: 0.7061 - val_loss: 0.5986 - val_accuracy: 0.7692\n",
      "Epoch 744/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6296 - accuracy: 0.7133 - val_loss: 0.5984 - val_accuracy: 0.7692\n",
      "Epoch 745/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6091 - accuracy: 0.7276 - val_loss: 0.5977 - val_accuracy: 0.7692\n",
      "Epoch 746/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6105 - accuracy: 0.7204 - val_loss: 0.5974 - val_accuracy: 0.7692\n",
      "Epoch 747/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6000 - accuracy: 0.7168 - val_loss: 0.5970 - val_accuracy: 0.7692\n",
      "Epoch 748/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6170 - accuracy: 0.7168 - val_loss: 0.5966 - val_accuracy: 0.7692\n",
      "Epoch 749/750\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6121 - accuracy: 0.7276 - val_loss: 0.5971 - val_accuracy: 0.7692\n",
      "Epoch 750/750\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6082 - accuracy: 0.7384 - val_loss: 0.5967 - val_accuracy: 0.7692\n",
      "\n",
      "\n",
      "Test loss: 0.5966659188270569\n",
      "Test accuracy: 0.7692307829856873\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Building the RNN ##\n",
    "print()\n",
    "print(\"length of train data: \", len(train_x))\n",
    "print(\"length of validation data: \", len(validation_x))\n",
    "print()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(train_x.shape[1:]), activation='tanh', return_sequences=True))\n",
    "# model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(LSTM(64, activation='tanh'))\n",
    "# model.add(Dropout(0.3))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(64, activation='tanh'))\n",
    "# model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.00001, decay=1e-6)\n",
    "# opt = tf.keras.optimizers.Adam(learning_rate=0.0001, decay=1e-6)\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=opt,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_x, train_y,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(validation_x, validation_y)\n",
    ")\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "# Score model\n",
    "score = model.evaluate(validation_x, validation_y, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.5966659188270569\n",
      "Test accuracy: 0.7692307829856873\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(10,7))\n",
    "plt.xlabel('epoch')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_test_buys(tickers, SEQ_LEN, SHIFT):\n",
    "    Sequential_data = []\n",
    "    for ticker in tickers:\n",
    "        df = set_data(ticker)[-SHIFT:]\n",
    "\n",
    "        sequential_data = []  # this is a list that will CONTAIN the sequences\n",
    "        prev_days = deque(maxlen=SEQ_LEN)  # These will be our actual sequences. They are made with deque, which keeps the maximum length by popping out older values as new ones come in\n",
    "        \n",
    "        for i in df.values:  # iterate over the values\n",
    "            prev_days.append([n for n in i[:-2]])  # store all but the target\n",
    "            if len(prev_days) == SEQ_LEN:  # make sure we have 60 sequences!\n",
    "                sequential_data.append([np.array(prev_days), i[-2], i[-1]])  # append those bad boys!\n",
    "        \n",
    "        Sequential_data = Sequential_data + sequential_data\n",
    "        \n",
    "    X = []; y = []; z = []\n",
    "    for seq, target, actual in Sequential_data:  # going over our new sequential data\n",
    "        X.append(seq)  # X is the sequences\n",
    "        y.append(target)  # y is the targets/labels (buys vs sell/notbuy)\n",
    "        z.append(actual)\n",
    "\n",
    "    return np.array(X).astype(\"float64\"), np.array(y).astype(\"uint8\"), np.array(z).astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = set_data(ticker)\n",
    "\n",
    "sequential_data = []  # this is a list that will CONTAIN the sequences\n",
    "prev_days = deque(maxlen=SEQ_LEN)  # These will be our actual sequences. They are made with deque, which keeps the maximum length by popping out older values as new ones come in\n",
    "\n",
    "for i in df.values:  # iterate over the values\n",
    "    prev_days.append([n for n in i[:-2]])  # store all but the target\n",
    "    if len(prev_days) == SEQ_LEN:  # make sure we have 60 sequences!\n",
    "        sequential_data.append([np.array(prev_days), i[-2], i[-1]])  # append those bad boys!\n",
    "\n",
    "        \n",
    "buy = []; notbuy = []; maybe = []\n",
    "\n",
    "for seq, target, actual in sequential_data:  # iterate over the sequential data\n",
    "    if target == 0:\n",
    "        maybe.append([seq, target, actual])\n",
    "    elif target == 1:\n",
    "        notbuy.append([seq, target, actual]) \n",
    "    elif target == 2:\n",
    "        buy.append([seq, target, actual])  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_trading_days = 100\n",
    "test_x, test_y, test_z = process_test_buys(tickers_test, SEQ_LEN, last_trading_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []; total = 0\n",
    "for i, j in zip(output, test_z):\n",
    "    if np.argmax(i) == 2:\n",
    "        total += 1\n",
    "#         results.append([i,j])\n",
    "        results.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trading period. The last 100 trading days.\n",
      "Average daily return: 2.329015 percent, over 31 trades.\n",
      "You started with $5000 and finished with $10091 after 31 trades.\n"
     ]
    }
   ],
   "source": [
    "print('Trading period. The last %d trading days.' % (last_trading_days))\n",
    "print('Average daily return: %f percent, over %d trades.' % (np.average(results), len(results)))\n",
    "start = 5000\n",
    "finish = start\n",
    "for i in results:\n",
    "    finish = finish + (i/100) * finish\n",
    "    \n",
    "print('You started with $%d and finished with $%d after %d trades.' % (start, finish, len(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.347376935288459, 2.112395057860783, 3.188869735746591, -1.5694116217555676, 1.0874764161835415, -2.2103989018587344, -0.5628833462154925, -0.5422291794853207, 4.26302747306484, 7.179760700093607, 4.368515841678211, 5.41504115382172, 5.001216213592574, 4.204014801309497, 0.10475245871657268, 0.8335003685586262, 0.6304627786145156, -1.2897125600689563, 4.043363727909655, 4.305987434505565, 1.04535839203721, -3.2955254715018367, 8.421855178188121, 3.8091279399722566, 5.167216721138401, 0.3401550511611173, 1.9410466601869292, 0.8462584169203646, 2.8748993450455895, 6.239069927025254, 1.8988795854689489]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []; total = 0\n",
    "for i, j in zip(output, test_z):\n",
    "    if i[2] > 0.6:\n",
    "        total += 1\n",
    "#         results.append([i,j])\n",
    "        results.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trading period. The last 100 trading days.\n",
      "Average daily return: 4.236571 percent, over 16 trades.\n",
      "You started with $5000 and finished with $9685 after 16 trades.\n"
     ]
    }
   ],
   "source": [
    "print('Trading period. The last %d trading days.' % (last_trading_days))\n",
    "print('Average daily return: %f percent, over %d trades.' % (np.average(results), len(results)))\n",
    "start = 5000\n",
    "finish = start\n",
    "for i in results:\n",
    "    finish = finish + (i/100) * finish\n",
    "    \n",
    "print('You started with $%d and finished with $%d after %d trades.' % (start, finish, len(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.188869735746591, 4.26302747306484, 7.179760700093607, 4.368515841678211, 5.41504115382172, 5.001216213592574, 4.204014801309497, 0.6304627786145156, 4.043363727909655, 4.305987434505565, 8.421855178188121, 3.8091279399722566, 1.9410466601869292, 2.8748993450455895, 6.239069927025254, 1.8988795854689489]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.00312643, -0.18769857,  0.0380633 ,  0.0722277 ,  0.05058531,\n",
       "          0.03609235, -0.09786587, -0.18948594,  0.08622011, -0.08056463,\n",
       "          0.18902671,  0.16548006, -0.18880107, -0.01695134,  0.08615918,\n",
       "         -0.00163658, -0.13285983,  0.19308513,  0.05517261, -0.00224075,\n",
       "         -0.1022841 ,  0.18436533,  0.2188085 ,  0.1760114 , -0.0074158 ,\n",
       "          0.03185357,  0.21743545,  0.22136943, -0.19212668, -0.03917618,\n",
       "          0.13469195, -0.09434514,  0.05589853, -0.05378037, -0.19692928,\n",
       "          0.02270586, -0.0365977 ,  0.12564209,  0.08942094,  0.18988153,\n",
       "          0.0690225 ,  0.01604605,  0.1429162 ,  0.19095956,  0.11380467,\n",
       "         -0.2027902 ,  0.1375719 , -0.0689759 ,  0.12338183, -0.05350982,\n",
       "          0.06561334,  0.17109035, -0.16426174,  0.12083419,  0.10378926,\n",
       "         -0.18805209,  0.07786953, -0.16585672,  0.05414619, -0.11606155,\n",
       "         -0.08931287,  0.0936529 , -0.09009225, -0.09815032, -0.16557518,\n",
       "          0.1472611 ,  0.19725555,  0.01803498, -0.1184849 , -0.05151945,\n",
       "         -0.01498069,  0.06469698, -0.0291974 , -0.1949649 ,  0.17806856,\n",
       "          0.08083003, -0.15647782, -0.2195628 , -0.13449658,  0.04573552,\n",
       "         -0.00358101, -0.09747846, -0.03567389,  0.07998811, -0.05985326,\n",
       "         -0.04558263, -0.16375333, -0.12832695,  0.03716719,  0.02404147,\n",
       "          0.07156183,  0.18949752, -0.15274762,  0.14734721, -0.06912665,\n",
       "         -0.05366255,  0.07961202, -0.07577288,  0.08149881,  0.1955975 ,\n",
       "         -0.12483811, -0.00611664, -0.10706586,  0.04938925,  0.00563698,\n",
       "         -0.06223384,  0.09597535, -0.17053139,  0.16782781, -0.06293302,\n",
       "          0.01248699, -0.04950023, -0.02555482, -0.12347258, -0.19855036,\n",
       "         -0.00586005, -0.06254587,  0.05811946, -0.16427459,  0.06209105,\n",
       "         -0.12304839,  0.18751115, -0.04076054,  0.05269979,  0.17086397,\n",
       "         -0.02094041,  0.1343887 , -0.00868019],\n",
       "        [-0.12686631, -0.05991039,  0.09261312,  0.15850225,  0.01551757,\n",
       "          0.02151437,  0.0006269 ,  0.09308005,  0.05434837,  0.09526602,\n",
       "          0.14436613, -0.10514788,  0.07283283,  0.06406976,  0.07457788,\n",
       "         -0.05105167,  0.1583915 , -0.02929694,  0.19978982,  0.12140419,\n",
       "          0.0976223 ,  0.02379363,  0.05592041, -0.20075348, -0.0143074 ,\n",
       "          0.14138927, -0.20443833, -0.1279288 , -0.0008473 , -0.15659311,\n",
       "          0.09713208,  0.2075942 , -0.15323801, -0.20432888,  0.1683226 ,\n",
       "          0.14751387, -0.20843248,  0.11499131, -0.06330646,  0.14355814,\n",
       "          0.21352917,  0.17419244, -0.17649409,  0.13990438,  0.14849101,\n",
       "          0.05079585,  0.13041003, -0.13853428, -0.02554207,  0.21732254,\n",
       "          0.21915886, -0.10097349, -0.19981752,  0.14960688, -0.03834248,\n",
       "          0.14960702, -0.09230021,  0.18596157,  0.15007272, -0.03084089,\n",
       "          0.09663603, -0.13804013, -0.0056133 , -0.10428941,  0.179846  ,\n",
       "          0.18694213, -0.21388733,  0.19724078,  0.15864253, -0.12035708,\n",
       "         -0.17465946, -0.0775182 , -0.13251145,  0.20312728,  0.10250577,\n",
       "         -0.14570601, -0.11164851,  0.00576302, -0.06620524,  0.17357273,\n",
       "          0.11254249,  0.26165625, -0.12900473,  0.0425782 ,  0.17445983,\n",
       "         -0.11847009,  0.06461962, -0.19160597, -0.09708065,  0.09055718,\n",
       "         -0.1162821 ,  0.0250404 ,  0.18939061, -0.01926407, -0.12288965,\n",
       "          0.16037177, -0.04546153,  0.05993035, -0.04024486, -0.15072587,\n",
       "         -0.16162017, -0.22316678,  0.10241747,  0.12581722, -0.12275817,\n",
       "          0.04811613,  0.13940768,  0.10405909, -0.09507117,  0.07747545,\n",
       "          0.02381424, -0.16583332, -0.08261501, -0.09840432,  0.07658096,\n",
       "          0.02966226,  0.14618817, -0.03362031,  0.10894418, -0.02069774,\n",
       "         -0.0199171 , -0.11542651, -0.1865498 , -0.05594101,  0.07971018,\n",
       "         -0.00146501,  0.190618  ,  0.17049065],\n",
       "        [-0.17670915,  0.04827275,  0.1619887 , -0.09668168,  0.14557993,\n",
       "         -0.16567077, -0.18422516,  0.0745503 , -0.20692806,  0.00154526,\n",
       "         -0.16097513,  0.15582024, -0.18310152,  0.10975634,  0.09758402,\n",
       "          0.13338016, -0.06597497, -0.07953213,  0.08117902, -0.06145   ,\n",
       "          0.22372928, -0.04800655,  0.1747809 , -0.10007829, -0.04454473,\n",
       "          0.17318092, -0.15449889, -0.11480231,  0.12816846, -0.08230518,\n",
       "         -0.06568802, -0.06795697, -0.04814418,  0.02162955,  0.17640528,\n",
       "         -0.18862681, -0.08069585, -0.02906987,  0.01225777,  0.06788076,\n",
       "         -0.1703803 , -0.19076419, -0.05489341,  0.12555736,  0.20447668,\n",
       "         -0.0285585 , -0.12942584,  0.18264416,  0.18667977, -0.1415279 ,\n",
       "         -0.05373743, -0.14390084,  0.18497187, -0.00390814,  0.00272444,\n",
       "          0.11326747, -0.16131778,  0.04096108,  0.02965281, -0.05988593,\n",
       "          0.04805259,  0.16944206, -0.08729667, -0.14608581, -0.05920009,\n",
       "          0.11488646,  0.03978502,  0.17097253,  0.10448197, -0.16612571,\n",
       "         -0.16461766,  0.13727562, -0.13740708, -0.12981744, -0.15292895,\n",
       "          0.01785154, -0.15033816,  0.18764852, -0.00478734,  0.03971572,\n",
       "          0.18631104,  0.18216735,  0.17071854, -0.1541188 ,  0.06751558,\n",
       "          0.21116713,  0.00715382,  0.1912871 ,  0.05671901,  0.08609796,\n",
       "          0.08097056,  0.06758917, -0.18742831, -0.19145046,  0.00258021,\n",
       "          0.12053272, -0.18683666, -0.15790926,  0.22448316, -0.10839736,\n",
       "         -0.15367082, -0.02443332,  0.02836128, -0.16616789,  0.16642836,\n",
       "          0.00655541,  0.17951354,  0.12021612, -0.16650695, -0.11249129,\n",
       "          0.17270587, -0.15971786,  0.04153971,  0.19774877,  0.02645675,\n",
       "          0.04900718,  0.13667557, -0.2028147 ,  0.18618219, -0.10136695,\n",
       "         -0.06469227, -0.09976763,  0.01327552,  0.13846809,  0.15348625,\n",
       "          0.16011564, -0.12519768, -0.03984984]], dtype=float32),\n",
       " array([[ 0.07040122, -0.0165008 ,  0.02752613, ...,  0.03206605,\n",
       "         -0.11313558,  0.01053534],\n",
       "        [-0.19310279, -0.09179968,  0.07585271, ...,  0.1652719 ,\n",
       "         -0.10012358, -0.00276671],\n",
       "        [ 0.1222802 ,  0.08461558, -0.0710137 , ..., -0.03354182,\n",
       "          0.0464283 , -0.05878286],\n",
       "        ...,\n",
       "        [ 0.17821658, -0.03794872, -0.1372566 , ..., -0.08037641,\n",
       "         -0.09172291,  0.11336135],\n",
       "        [ 0.08383521,  0.0283241 ,  0.02099125, ...,  0.12672122,\n",
       "          0.01495308, -0.04238388],\n",
       "        [-0.14891471, -0.05336422,  0.05647508, ...,  0.03842521,\n",
       "         -0.0025791 ,  0.08897124]], dtype=float32),\n",
       " array([ 2.0723565e-02,  4.4887938e-02,  6.9027901e-02,  4.7615874e-03,\n",
       "         3.2755584e-02,  2.5505987e-03,  1.2064919e-02,  1.2002396e-02,\n",
       "         1.6988458e-02,  3.0990571e-02,  1.6405717e-02,  3.3605054e-02,\n",
       "         1.6276153e-02, -1.2554668e-03,  6.4984621e-03,  2.3925740e-02,\n",
       "         1.0536969e-02,  3.6437050e-02, -4.3863914e-05, -3.0616289e-03,\n",
       "         6.4209881e-03,  2.1326775e-03,  3.1042807e-02,  6.0132211e-03,\n",
       "        -5.1282225e-03,  2.8519053e-02,  1.1219930e-02,  1.6690951e-03,\n",
       "         2.1174470e-02,  9.0079317e-03,  1.5528350e-02,  2.5387611e-02,\n",
       "         1.0509962e+00,  9.8378217e-01,  9.2769170e-01,  1.0328264e+00,\n",
       "         9.6379608e-01,  1.0012605e+00,  1.0101744e+00,  1.0337038e+00,\n",
       "         9.7456276e-01,  1.0456237e+00,  9.6737003e-01,  9.5067996e-01,\n",
       "         9.4386345e-01,  1.0106403e+00,  9.7367460e-01,  9.7243577e-01,\n",
       "         1.0271788e+00,  9.6401197e-01,  9.9867094e-01,  1.0000646e+00,\n",
       "         1.0127999e+00,  9.8625815e-01,  1.0467510e+00,  9.9324048e-01,\n",
       "         9.8695642e-01,  9.7022140e-01,  9.4893390e-01,  9.6009350e-01,\n",
       "         1.0153053e+00,  9.6046144e-01,  9.9874717e-01,  9.8717618e-01,\n",
       "         2.7497329e-02,  2.5362203e-02,  3.0311977e-03,  2.0374713e-02,\n",
       "         5.2178886e-02, -2.9484421e-02, -1.6887117e-02,  1.1258130e-02,\n",
       "        -4.0776008e-03, -2.6886052e-02, -8.4037874e-03, -3.1752110e-02,\n",
       "        -1.0246914e-02,  3.5747830e-02,  2.6749377e-03,  2.1262784e-02,\n",
       "         1.3099445e-02, -1.6307579e-02,  1.3280185e-02, -3.7510443e-02,\n",
       "        -2.5543353e-02,  7.0983656e-03,  8.8101486e-03, -2.3172891e-02,\n",
       "        -2.7119881e-02, -1.2111858e-02, -7.9090251e-03,  2.7653396e-02,\n",
       "        -1.1292396e-02, -4.2322703e-02,  1.8452056e-02,  3.3928405e-02,\n",
       "         1.8125815e-02,  3.1621922e-02,  4.8631441e-02, -3.1703424e-03,\n",
       "         2.5072964e-02, -2.7162535e-03,  1.1496342e-02,  8.4434086e-03,\n",
       "         2.1646043e-02,  2.7268929e-02,  1.7764382e-02,  2.7777413e-02,\n",
       "         1.5391033e-02, -2.5723132e-04,  6.9898213e-03,  1.3187764e-02,\n",
       "         1.3374597e-02,  3.7117302e-02, -7.5752353e-03, -1.2910307e-03,\n",
       "         1.4418993e-02,  2.4199539e-03,  3.2607883e-02,  6.5224404e-03,\n",
       "        -6.0231825e-03,  2.6507750e-02,  1.2847839e-02,  7.9762032e-03,\n",
       "         1.7069958e-02,  9.9049238e-03,  1.4236936e-02,  2.3423338e-02],\n",
       "       dtype=float32),\n",
       " array([1.0045298 , 1.0269138 , 1.011641  , 1.0065551 , 1.0139397 ,\n",
       "        1.0023535 , 1.0017308 , 1.0092274 , 1.0216727 , 1.0025151 ,\n",
       "        1.0186657 , 1.0135014 , 1.0145171 , 0.9932124 , 1.0049971 ,\n",
       "        1.0182087 , 1.009087  , 1.0136865 , 0.99924266, 0.98183346,\n",
       "        1.0065554 , 1.0030156 , 1.0176798 , 1.0072472 , 0.9978195 ,\n",
       "        1.023945  , 1.0018017 , 1.0044084 , 1.0141418 , 1.0072279 ,\n",
       "        1.0163896 , 1.0014251 ], dtype=float32),\n",
       " array([ 0.01761839,  0.03422633, -0.00803565, -0.00392146,  0.01961373,\n",
       "         0.00255796,  0.00571852, -0.0234495 , -0.02534503,  0.00374506,\n",
       "        -0.01495127, -0.01438864,  0.00998333,  0.0054919 , -0.00543462,\n",
       "         0.02367013,  0.00548997, -0.01094003,  0.00577789, -0.00476479,\n",
       "        -0.00530966,  0.00740505,  0.01302913,  0.00314684,  0.02388726,\n",
       "         0.00994661,  0.00729999, -0.01450144, -0.03098204, -0.01019612,\n",
       "        -0.00211377, -0.00877573], dtype=float32),\n",
       " array([ 0.02466239,  0.05594246, -0.0300382 ,  0.06635245,  0.05631052,\n",
       "        -0.05407359, -0.06732376,  0.00795772, -0.04135842,  0.01575575,\n",
       "        -0.00845525, -0.03227522, -0.04234768,  0.05491623, -0.00848021,\n",
       "         0.04067458,  0.06453639,  0.06421072,  0.01669284, -0.03681384,\n",
       "         0.04455988,  0.02269568,  0.0237317 , -0.00374195, -0.01555624,\n",
       "         0.02686044, -0.00106105,  0.02927334, -0.00337046, -0.05036864,\n",
       "        -0.01705861,  0.06994104], dtype=float32),\n",
       " array([0.00350266, 0.00062129, 0.0073589 , 0.00151459, 0.00266942,\n",
       "        0.00066533, 0.00179528, 0.00118029, 0.00051686, 0.00760722,\n",
       "        0.00173923, 0.00159288, 0.00067761, 0.00531685, 0.00096712,\n",
       "        0.00035963, 0.00213906, 0.0049369 , 0.00074089, 0.00100243,\n",
       "        0.00306148, 0.00083449, 0.00426042, 0.00095206, 0.00049484,\n",
       "        0.000289  , 0.000594  , 0.00188641, 0.00448021, 0.00254591,\n",
       "        0.00021428, 0.00295106], dtype=float32),\n",
       " array([[ 0.09893038,  0.04867451, -0.115394  , ..., -0.06823919,\n",
       "         -0.05472312, -0.07048035],\n",
       "        [ 0.01220073,  0.03967336, -0.15729648, ..., -0.08727297,\n",
       "         -0.04968246, -0.00845569],\n",
       "        [-0.13464831, -0.14642993,  0.13951525, ..., -0.05956592,\n",
       "         -0.05359393,  0.02667134],\n",
       "        ...,\n",
       "        [ 0.13934217,  0.05386412, -0.00877465, ..., -0.0607422 ,\n",
       "          0.09471163, -0.04372771],\n",
       "        [-0.05011915, -0.06006752, -0.03126079, ...,  0.1320694 ,\n",
       "         -0.06704298, -0.09287032],\n",
       "        [ 0.01984727,  0.13031578, -0.14733422, ...,  0.09533245,\n",
       "          0.05025988,  0.09539825]], dtype=float32),\n",
       " array([[ 0.15974315,  0.02116827, -0.05779935, ...,  0.08916853,\n",
       "          0.09400767, -0.0282031 ],\n",
       "        [-0.01019955, -0.07027774, -0.09251101, ..., -0.12721053,\n",
       "          0.00672759,  0.0084084 ],\n",
       "        [-0.05557458, -0.01005035, -0.03483566, ...,  0.12729824,\n",
       "          0.05087355, -0.01696235],\n",
       "        ...,\n",
       "        [ 0.13462047,  0.0652725 ,  0.009694  , ...,  0.03829272,\n",
       "          0.06549073, -0.06210581],\n",
       "        [ 0.14717525,  0.04127352,  0.01892701, ...,  0.05181705,\n",
       "         -0.05750524,  0.01915863],\n",
       "        [-0.03663584,  0.03376428, -0.10487318, ..., -0.12898414,\n",
       "         -0.03137251, -0.00283516]], dtype=float32),\n",
       " array([-1.69637520e-02, -2.77663041e-02,  5.92485163e-03,  9.32159554e-03,\n",
       "         5.36803193e-02,  2.43526064e-02,  4.20330353e-02,  1.08122164e-02,\n",
       "         1.82909484e-03,  8.07144213e-03, -8.17724504e-04,  1.17237754e-02,\n",
       "         4.79078665e-02,  3.53675224e-02,  3.36821452e-02,  3.38218920e-02,\n",
       "         2.80096140e-02,  4.47381809e-02,  5.47520164e-03,  6.07315870e-03,\n",
       "         1.79181155e-02, -1.08665796e-02,  1.45536847e-02,  2.75185704e-02,\n",
       "        -1.19451415e-02,  4.32246290e-02,  1.59378517e-02,  6.72973171e-02,\n",
       "        -1.18156681e-02,  2.10419390e-02,  2.27903333e-02,  2.75729597e-02,\n",
       "        -2.76730265e-02, -1.74515285e-02,  3.56762186e-02, -4.24396805e-03,\n",
       "         4.57736850e-02,  4.05687168e-02,  2.94012185e-02,  2.15106159e-02,\n",
       "         3.67925949e-02,  2.34770272e-02,  2.81173848e-02,  1.41092399e-02,\n",
       "         3.56388316e-02,  2.74094660e-02, -5.14674524e-04,  4.16039377e-02,\n",
       "         2.27588452e-02,  3.86399627e-02,  2.20890008e-02, -6.70340378e-03,\n",
       "         5.03283879e-03,  4.80085425e-02,  2.10918020e-02,  3.99806201e-02,\n",
       "         6.31202832e-02,  2.23384891e-02, -7.88221136e-03,  2.33831033e-02,\n",
       "         2.63514835e-02, -1.05916336e-02, -1.04287490e-02,  2.95610931e-02,\n",
       "         1.01579905e+00,  9.55776393e-01,  9.75998342e-01,  1.02699959e+00,\n",
       "         9.51289296e-01,  9.80514407e-01,  9.46099639e-01,  9.96944606e-01,\n",
       "         9.92885888e-01,  9.40613925e-01,  9.22906041e-01,  9.97523844e-01,\n",
       "         9.66948509e-01,  9.10557389e-01,  1.02627897e+00,  9.40810919e-01,\n",
       "         9.86390412e-01,  9.70132589e-01,  9.66195583e-01,  9.67695296e-01,\n",
       "         9.97377753e-01,  1.02590179e+00,  9.77156222e-01,  1.02025914e+00,\n",
       "         1.00580704e+00,  9.86630857e-01,  1.02287078e+00,  9.46647882e-01,\n",
       "         1.01341140e+00,  9.84111428e-01,  9.75500882e-01,  9.66144800e-01,\n",
       "         9.52606201e-01,  1.00988960e+00,  9.41816449e-01,  9.47368383e-01,\n",
       "         9.48641956e-01,  9.53401208e-01,  9.70972717e-01,  9.61991727e-01,\n",
       "         9.64356184e-01,  9.86436009e-01,  9.50299382e-01,  9.62819576e-01,\n",
       "         9.59941745e-01,  1.01202512e+00,  1.01787710e+00,  9.62456346e-01,\n",
       "         1.02473819e+00,  9.72679257e-01,  9.90034461e-01,  9.67031717e-01,\n",
       "         9.85504270e-01,  9.28848565e-01,  1.00689828e+00,  9.73949790e-01,\n",
       "         9.58731294e-01,  9.66055334e-01,  9.93277848e-01,  9.57462668e-01,\n",
       "         1.00047684e+00,  9.49469626e-01,  9.56985414e-01,  9.87529337e-01,\n",
       "        -1.51635371e-02, -4.59952094e-03,  4.19182004e-03,  1.45585304e-02,\n",
       "        -3.01212035e-02, -1.19609740e-02,  3.67910229e-03, -6.40551560e-04,\n",
       "         7.59061053e-03,  1.14248050e-02,  2.01770235e-02,  1.16438735e-02,\n",
       "        -4.33625281e-03,  1.43255359e-02, -2.59626042e-02, -9.89181828e-03,\n",
       "        -1.63500812e-02,  1.37242991e-02, -6.19580131e-03, -3.60728167e-02,\n",
       "        -1.62531231e-02,  2.42896215e-03,  3.16570979e-04, -1.49512114e-02,\n",
       "         4.71810363e-02,  1.00472961e-02,  1.12635968e-02,  1.30686571e-03,\n",
       "        -1.53260594e-02, -2.02436023e-03, -1.39986090e-02,  2.32504755e-02,\n",
       "        -1.00125875e-02,  1.74000058e-02,  1.62402671e-02, -1.14803836e-02,\n",
       "         1.76750112e-03,  2.70566363e-02, -2.38134852e-03,  1.12903249e-02,\n",
       "         1.51159065e-02,  2.07387488e-02, -9.52936988e-03, -1.01043209e-02,\n",
       "        -6.98935590e-04,  1.61512487e-03, -1.38999112e-02, -1.42013198e-02,\n",
       "         1.31555973e-02,  3.43548171e-02,  2.80315913e-02,  1.40004873e-03,\n",
       "         9.32253245e-03,  1.28302479e-03, -8.48662574e-03,  2.92334799e-02,\n",
       "         3.13214469e-03,  1.75410812e-03,  1.39694829e-02,  6.69496413e-03,\n",
       "         1.78406443e-02, -1.92045525e-03,  1.97466835e-03,  4.43389565e-02,\n",
       "        -2.16461569e-02,  2.88909357e-02, -4.34696954e-03, -6.86613191e-03,\n",
       "         6.06504679e-02,  2.47905180e-02,  5.09574115e-02,  1.38463248e-02,\n",
       "         2.96334140e-02, -2.22142576e-03,  7.94724375e-03,  2.21522767e-02,\n",
       "         5.06654829e-02,  2.43890099e-02,  2.13257354e-02,  2.76021939e-02,\n",
       "         2.66320873e-02,  6.38598725e-02,  5.96899865e-03,  2.23116539e-02,\n",
       "         4.67925426e-03,  1.24391168e-02,  2.18405053e-02,  2.66886428e-02,\n",
       "         6.38809812e-04,  3.15756723e-02,  1.06235454e-02,  6.48366287e-02,\n",
       "        -5.99437207e-03, -4.35140653e-04,  2.31463518e-02,  4.38396782e-02,\n",
       "         3.05455178e-02,  9.82319284e-03,  1.95951387e-02,  1.41509362e-02,\n",
       "         4.84482534e-02,  7.32088313e-02,  2.47404259e-02,  2.61631645e-02,\n",
       "         3.30857784e-02, -1.87949762e-02,  2.83638984e-02, -7.18811760e-03,\n",
       "         3.03416420e-02,  2.73471102e-02,  1.36421965e-02,  2.15545204e-02,\n",
       "         1.38169457e-03,  1.67836417e-02,  1.56609919e-02,  3.03732534e-03,\n",
       "         1.46071855e-02,  4.15918827e-02,  7.00740202e-04,  4.08236496e-03,\n",
       "         4.25892472e-02,  2.13209838e-02, -1.53939081e-02,  2.50440966e-02,\n",
       "         3.58134322e-02, -1.37030799e-02, -8.94131546e-04, -2.21359474e-03],\n",
       "       dtype=float32),\n",
       " array([1.0237248 , 1.0335897 , 1.0133479 , 1.0074173 , 1.054903  ,\n",
       "        1.0112913 , 1.0157453 , 1.001864  , 1.0051268 , 1.0058677 ,\n",
       "        1.0346651 , 1.0095645 , 1.0565937 , 1.0593271 , 1.0078825 ,\n",
       "        1.0219278 , 1.0279195 , 1.0586355 , 1.0218176 , 1.0103825 ,\n",
       "        1.0075336 , 0.9897559 , 1.0204066 , 0.9994495 , 0.99903697,\n",
       "        1.0484723 , 1.000821  , 1.0228084 , 1.0169855 , 1.0064452 ,\n",
       "        1.0286796 , 1.0376488 , 1.0454012 , 1.0435607 , 0.99833536,\n",
       "        1.0385299 , 1.0660081 , 1.0660616 , 0.9989024 , 1.0089321 ,\n",
       "        1.0357552 , 1.0248078 , 0.99661803, 0.9912182 , 1.0431448 ,\n",
       "        1.0204123 , 1.0115707 , 1.0031248 , 0.9987541 , 1.0245303 ,\n",
       "        1.0277557 , 0.9836086 , 0.9957123 , 1.0075763 , 1.0024033 ,\n",
       "        1.0319483 , 1.0797906 , 1.016902  , 0.99803305, 1.0160549 ,\n",
       "        0.99219525, 1.0062855 , 1.0402343 , 1.0252775 ], dtype=float32),\n",
       " array([ 0.03607797,  0.02721978,  0.03377694, -0.01233607,  0.03035714,\n",
       "        -0.01954665,  0.00324992,  0.01008906,  0.03412088, -0.01726569,\n",
       "         0.04265579,  0.02320098, -0.00506447,  0.01792704,  0.02981218,\n",
       "         0.03539541,  0.00224177,  0.01584513, -0.00504696, -0.05809347,\n",
       "         0.01695522, -0.00225773, -0.02629648,  0.00268024, -0.01147092,\n",
       "         0.01337695,  0.00842683, -0.02107428, -0.02654308,  0.00297097,\n",
       "        -0.0150539 , -0.01426886,  0.00226904,  0.00790439,  0.01423042,\n",
       "        -0.00581015, -0.02898883, -0.00168571,  0.01322421, -0.01613486,\n",
       "         0.0227571 , -0.01747894, -0.0322213 ,  0.03841317, -0.00108983,\n",
       "        -0.03148111, -0.01430203,  0.02454586, -0.03439258, -0.00106762,\n",
       "         0.01013733,  0.03359502, -0.00859668,  0.02829864, -0.03248185,\n",
       "        -0.02987465,  0.0017566 , -0.02913324, -0.00109046,  0.0019254 ,\n",
       "        -0.02267901,  0.01433761, -0.00791646, -0.01721329], dtype=float32),\n",
       " array([ 0.02530257, -0.00537169,  0.00726948, -0.00681768, -0.00180603,\n",
       "         0.03046253,  0.01299201, -0.0045656 , -0.00998436, -0.0080445 ,\n",
       "        -0.05396311, -0.02565073, -0.01606544, -0.00212614,  0.02961765,\n",
       "        -0.09160766, -0.00834799,  0.01478531,  0.03036354,  0.03773025,\n",
       "        -0.0272498 , -0.01648096,  0.03302611,  0.06924688, -0.10870794,\n",
       "         0.01849591,  0.01784707,  0.02654945, -0.02325585, -0.06123659,\n",
       "         0.01417973,  0.002448  , -0.00302468, -0.00686711,  0.00876134,\n",
       "         0.05675112, -0.02177871, -0.00450994, -0.03623353,  0.04035975,\n",
       "         0.02996038,  0.01531964, -0.03025778, -0.04805893, -0.00055154,\n",
       "         0.03961984,  0.04818118, -0.02382073,  0.00207939,  0.02616461,\n",
       "         0.01650812,  0.01435843, -0.00367046,  0.04055671,  0.00171383,\n",
       "        -0.00202287, -0.00175107, -0.03807736,  0.00155705,  0.03313771,\n",
       "        -0.06099026,  0.03372632, -0.01276851,  0.03822001], dtype=float32),\n",
       " array([0.00902985, 0.00670403, 0.00317488, 0.00831341, 0.00276243,\n",
       "        0.05805247, 0.00327411, 0.00645587, 0.02568999, 0.00252613,\n",
       "        0.03205082, 0.03986819, 0.00138613, 0.00482963, 0.06379199,\n",
       "        0.03152577, 0.00132468, 0.00126988, 0.01074193, 0.01699404,\n",
       "        0.01279966, 0.01360616, 0.00697056, 0.05084053, 0.05080125,\n",
       "        0.00259919, 0.03030798, 0.01108094, 0.0053384 , 0.02513302,\n",
       "        0.02767878, 0.00116371, 0.00533562, 0.00711018, 0.00327607,\n",
       "        0.04208413, 0.00207011, 0.00303285, 0.05859787, 0.02738411,\n",
       "        0.001418  , 0.00616072, 0.05570311, 0.01553965, 0.00094015,\n",
       "        0.06608461, 0.02357844, 0.03470612, 0.01546709, 0.00147558,\n",
       "        0.00130598, 0.01207276, 0.02102426, 0.02563452, 0.00966366,\n",
       "        0.00841927, 0.00213435, 0.02866175, 0.00347962, 0.00717385,\n",
       "        0.0550461 , 0.01478912, 0.00447669, 0.00476005], dtype=float32),\n",
       " array([[-0.03479358,  0.11201561,  0.09000414, ...,  0.22308642,\n",
       "         -0.04452906,  0.09716231],\n",
       "        [ 0.05056616, -0.05388826, -0.10337251, ...,  0.00394242,\n",
       "          0.09094757,  0.22098882],\n",
       "        [ 0.04981133,  0.20618299, -0.08457468, ...,  0.17101642,\n",
       "          0.04994562,  0.05202099],\n",
       "        ...,\n",
       "        [ 0.08458615, -0.16531403,  0.18597123, ..., -0.11516953,\n",
       "         -0.17112456, -0.01060012],\n",
       "        [-0.11308888,  0.05660366,  0.15510929, ...,  0.0592677 ,\n",
       "          0.14096081, -0.18546672],\n",
       "        [-0.17174049,  0.01751591,  0.01802912, ..., -0.09513935,\n",
       "         -0.06800645,  0.08139502]], dtype=float32),\n",
       " array([-4.92866151e-03, -7.67147774e-03, -3.14521082e-02,  1.72737967e-02,\n",
       "        -2.58504250e-03,  2.55530626e-02,  4.08334751e-03,  2.44019125e-02,\n",
       "         2.82049850e-02,  4.11879783e-03,  3.92063111e-02,  2.39981664e-03,\n",
       "         8.07925779e-03,  6.62406310e-02,  9.20099556e-05, -2.97647025e-02,\n",
       "         2.64478978e-02,  3.72325033e-02, -1.79993678e-02, -3.38418828e-03,\n",
       "        -2.14942303e-02,  1.23663442e-02, -8.65607697e-04, -2.28298083e-02,\n",
       "         2.35797204e-02,  1.27305742e-02,  2.72658616e-02,  3.20510520e-03,\n",
       "         2.40141489e-02, -3.13745588e-02, -1.37633029e-02, -1.63264654e-03,\n",
       "        -1.18501550e-02,  2.98116822e-03,  2.54601217e-03, -1.47513514e-02,\n",
       "        -4.55136830e-03, -3.00391391e-02, -7.78672239e-03, -3.76401911e-03,\n",
       "        -3.24824676e-02, -1.13177095e-02,  2.01911796e-02, -2.35918611e-02,\n",
       "         2.35097352e-02, -3.06572649e-03, -1.00871185e-02,  3.36097069e-02,\n",
       "        -3.26748975e-02, -4.80496511e-03, -2.05806587e-02, -1.94943196e-03,\n",
       "        -1.67565607e-02,  3.15114446e-02, -3.85002159e-02,  1.99424978e-02,\n",
       "         2.82937959e-02, -1.21995416e-02,  3.77999060e-02, -1.03297050e-03,\n",
       "        -3.89188342e-02,  3.01611144e-02,  2.64127422e-02,  1.27652166e-02],\n",
       "       dtype=float32),\n",
       " array([[-0.22890095, -0.23144846,  0.01207507],\n",
       "        [-0.26243073, -0.13431346, -0.04923192],\n",
       "        [-0.07398652,  0.22549835,  0.3086968 ],\n",
       "        [-0.04180292, -0.31375772,  0.06800255],\n",
       "        [-0.03199549, -0.09904381,  0.24074799],\n",
       "        [ 0.27488035, -0.08092143, -0.285011  ],\n",
       "        [ 0.02840672,  0.0281675 , -0.09803051],\n",
       "        [ 0.24250776, -0.0804217 , -0.2312347 ],\n",
       "        [ 0.02084977, -0.07570098, -0.16041741],\n",
       "        [-0.14570796,  0.22192432,  0.19190978],\n",
       "        [ 0.22327562, -0.26899308, -0.06411932],\n",
       "        [-0.1441286 , -0.17496075,  0.27819923],\n",
       "        [ 0.13085006,  0.01889588,  0.29922014],\n",
       "        [ 0.3114588 , -0.16706859,  0.11764565],\n",
       "        [ 0.05844942,  0.24053304, -0.1962627 ],\n",
       "        [-0.01826048,  0.27075604,  0.03971606],\n",
       "        [ 0.23499775, -0.21216744,  0.04488977],\n",
       "        [ 0.2288198 , -0.12598966, -0.26602173],\n",
       "        [-0.05277871,  0.03405618,  0.20628093],\n",
       "        [-0.14848942, -0.21359514,  0.3102751 ],\n",
       "        [-0.21600232,  0.12686673, -0.22974621],\n",
       "        [ 0.1159891 , -0.00340136, -0.26658314],\n",
       "        [-0.24339555, -0.27244985, -0.05700791],\n",
       "        [-0.07815224,  0.20782955,  0.10582972],\n",
       "        [ 0.11005588, -0.02929579,  0.17254063],\n",
       "        [-0.07573652, -0.09393021, -0.2293183 ],\n",
       "        [-0.06628026, -0.23296936, -0.09989068],\n",
       "        [ 0.2613402 ,  0.19700226, -0.31008595],\n",
       "        [-0.02042684, -0.13823755, -0.28914607],\n",
       "        [-0.22104387, -0.06405115, -0.14888251],\n",
       "        [-0.1569295 , -0.12009763,  0.08133375],\n",
       "        [-0.16346993, -0.16332878, -0.03991882],\n",
       "        [-0.25648013, -0.20590071, -0.3053493 ],\n",
       "        [ 0.12628454, -0.06530403, -0.06027967],\n",
       "        [ 0.047117  ,  0.1278166 , -0.18151508],\n",
       "        [ 0.08822609,  0.18939222,  0.04213616],\n",
       "        [-0.08985063, -0.01724871, -0.13935968],\n",
       "        [-0.13165885,  0.03627391, -0.09774374],\n",
       "        [-0.17283279, -0.16585399,  0.0641857 ],\n",
       "        [ 0.00405107,  0.17339787, -0.17658213],\n",
       "        [ 0.07998786,  0.23919328,  0.07875785],\n",
       "        [-0.08889727,  0.00189502,  0.13139737],\n",
       "        [ 0.2790766 , -0.30164677, -0.17859071],\n",
       "        [-0.00521792,  0.13884199,  0.24529321],\n",
       "        [ 0.21171044, -0.01923884, -0.13507207],\n",
       "        [ 0.00943357,  0.06647349, -0.07721824],\n",
       "        [-0.26122683, -0.1484668 ,  0.29710355],\n",
       "        [ 0.24020912, -0.03710582,  0.00492791],\n",
       "        [-0.19253542,  0.18690567,  0.09295812],\n",
       "        [-0.16234174, -0.11530834,  0.05324309],\n",
       "        [ 0.09649321,  0.17866814,  0.10621813],\n",
       "        [-0.08973064, -0.13157842,  0.18038368],\n",
       "        [-0.04241013,  0.29693025, -0.29461655],\n",
       "        [ 0.07747743, -0.20689042, -0.25275877],\n",
       "        [-0.08062713,  0.11525892, -0.08464759],\n",
       "        [-0.17711912, -0.23274098, -0.08003683],\n",
       "        [ 0.12397879, -0.24743225,  0.0706145 ],\n",
       "        [-0.32561928,  0.21503316,  0.16041158],\n",
       "        [ 0.13119505, -0.13877675, -0.29845315],\n",
       "        [-0.09684002, -0.05098617,  0.22511248],\n",
       "        [-0.10214587,  0.01556595,  0.00443919],\n",
       "        [ 0.30516642, -0.2635387 , -0.00492048],\n",
       "        [-0.10124972, -0.29417938, -0.3071124 ],\n",
       "        [ 0.15434214,  0.08175381, -0.23330355]], dtype=float32),\n",
       " array([ 0.03690656, -0.03006154, -0.00956596], dtype=float32)]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if os.path.isfile('FAS_modle.h5') is False:\n",
    "    model.save('FAS_modle.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = load_model('FAS_modle.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_8 (LSTM)                (None, 2, 32)             4608      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 2, 32)             128       \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 64)                24832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 34,179\n",
      "Trainable params: 33,987\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
